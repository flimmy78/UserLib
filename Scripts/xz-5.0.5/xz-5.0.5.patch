diff -ru ..\..\Library\xz-5.0.5\src/common/tuklib_integer.h src/common/tuklib_integer.h
--- ..\..\Library\xz-5.0.5\src/common/tuklib_integer.h	2013-06-30 14:49:46.000000000 +0200
+++ src/common/tuklib_integer.h	2014-04-25 18:29:35.275047300 +0200
@@ -97,6 +97,9 @@
 #	endif
 #endif
 
+#ifdef _MSC_VER
+#define inline __inline
+#endif
 
 ///////////////////
 // Byte swapping //
@@ -379,13 +382,6 @@
 	__asm__("bsrl %1, %0" : "=r" (i) : "rm" (n));
 	return i;
 
-#elif defined(_MSC_VER) && _MSC_VER >= 1400
-	// MSVC isn't supported by tuklib, but since this code exists,
-	// it doesn't hurt to have it here anyway.
-	uint32_t i;
-	_BitScanReverse((DWORD *)&i, n);
-	return i;
-
 #else
 	uint32_t i = 31;
 
@@ -433,11 +429,6 @@
 		: "=r" (i) : "rm" (n));
 	return i;
 
-#elif defined(_MSC_VER) && _MSC_VER >= 1400
-	uint32_t i;
-	_BitScanReverse((DWORD *)&i, n);
-	return i ^ 31U;
-
 #else
 	uint32_t i = 0;
 
@@ -483,11 +474,6 @@
 	__asm__("bsfl %1, %0" : "=r" (i) : "rm" (n));
 	return i;
 
-#elif defined(_MSC_VER) && _MSC_VER >= 1400
-	uint32_t i;
-	_BitScanForward((DWORD *)&i, n);
-	return i;
-
 #else
 	uint32_t i = 0;
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/check/check.c src/liblzma/check/check.c
--- ..\..\Library\xz-5.0.5\src/liblzma/check/check.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/check/check.c	2014-04-25 18:40:58.685346700 +0200
@@ -16,9 +16,6 @@
 extern LZMA_API(lzma_bool)
 lzma_check_is_supported(lzma_check type)
 {
-	if ((unsigned int)(type) > LZMA_CHECK_ID_MAX)
-		return false;
-
 	static const lzma_bool available_checks[LZMA_CHECK_ID_MAX + 1] = {
 		true,   // LZMA_CHECK_NONE
 
@@ -56,6 +53,9 @@
 		false,  // Reserved
 	};
 
+	if ((unsigned int)(type) > LZMA_CHECK_ID_MAX)
+		return false;
+
 	return available_checks[(unsigned int)(type)];
 }
 
@@ -63,9 +63,6 @@
 extern LZMA_API(uint32_t)
 lzma_check_size(lzma_check type)
 {
-	if ((unsigned int)(type) > LZMA_CHECK_ID_MAX)
-		return UINT32_MAX;
-
 	// See file-format.txt section 2.1.1.2.
 	static const uint8_t check_sizes[LZMA_CHECK_ID_MAX + 1] = {
 		0,
@@ -76,6 +73,9 @@
 		64, 64, 64
 	};
 
+	if ((unsigned int)(type) > LZMA_CHECK_ID_MAX)
+		return UINT32_MAX;
+
 	return check_sizes[(unsigned int)(type)];
 }
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/check/crc32_fast.c src/liblzma/check/crc32_fast.c
--- ..\..\Library\xz-5.0.5\src/liblzma/check/crc32_fast.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/check/crc32_fast.c	2014-05-03 14:44:38.595739400 +0200
@@ -26,6 +26,9 @@
 extern LZMA_API(uint32_t)
 lzma_crc32(const uint8_t *buf, size_t size, uint32_t crc)
 {
+	const uint8_t *limit;
+	uint32_t tmp;
+	
 	crc = ~crc;
 
 #ifdef WORDS_BIGENDIAN
@@ -41,7 +44,7 @@
 		}
 
 		// Calculate the position where to stop.
-		const uint8_t *const limit = buf + (size & ~(size_t)(7));
+		limit = buf + (size & ~(size_t)(7));
 
 		// Calculate how many bytes must be calculated separately
 		// before returning the result.
@@ -57,7 +60,7 @@
 			    ^ lzma_crc32_table[5][C(crc)]
 			    ^ lzma_crc32_table[4][D(crc)];
 
-			const uint32_t tmp = *(const uint32_t *)(buf);
+			tmp = *(const uint32_t *)(buf);
 			buf += 4;
 
 			// At least with some compilers, it is critical for
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/check/crc64_fast.c src/liblzma/check/crc64_fast.c
--- ..\..\Library\xz-5.0.5\src/liblzma/check/crc64_fast.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/check/crc64_fast.c	2014-05-03 14:45:43.317751100 +0200
@@ -29,6 +29,9 @@
 extern LZMA_API(uint64_t)
 lzma_crc64(const uint8_t *buf, size_t size, uint64_t crc)
 {
+	const uint8_t *limit;
+	uint32_t tmp;
+
 	crc = ~crc;
 
 #ifdef WORDS_BIGENDIAN
@@ -41,15 +44,15 @@
 			--size;
 		}
 
-		const uint8_t *const limit = buf + (size & ~(size_t)(3));
+		limit = buf + (size & ~(size_t)(3));
 		size &= (size_t)(3);
 
 		while (buf < limit) {
 #ifdef WORDS_BIGENDIAN
-			const uint32_t tmp = (crc >> 32)
+			tmp = (crc >> 32)
 					^ *(const uint32_t *)(buf);
 #else
-			const uint32_t tmp = crc ^ *(const uint32_t *)(buf);
+			tmp = crc ^ *(const uint32_t *)(buf);
 #endif
 			buf += 4;
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/check/sha256.c src/liblzma/check/sha256.c
--- ..\..\Library\xz-5.0.5\src/liblzma/check/sha256.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/check/sha256.c	2014-05-03 14:48:04.153012100 +0200
@@ -80,16 +80,17 @@
 
 
 static void
-transform(uint32_t state[static 8], const uint32_t data[static 16])
+transform(uint32_t state[8], const uint32_t data[16])
 {
 	uint32_t W[16];
 	uint32_t T[8];
+	unsigned int j;
 
 	// Copy state[] to working vars.
 	memcpy(T, state, sizeof(T));
 
 	// 64 operations, partially loop unrolled
-	for (unsigned int j = 0; j < 64; j += 16) {
+	for (j = 0; j < 64; j += 16) {
 		R( 0); R( 1); R( 2); R( 3);
 		R( 4); R( 5); R( 6); R( 7);
 		R( 8); R( 9); R(10); R(11);
@@ -116,8 +117,9 @@
 
 #else
 	uint32_t data[16];
+	size_t i;
 
-	for (size_t i = 0; i < 16; ++i)
+	for (i = 0; i < 16; ++i)
 		data[i] = bswap32(check->buffer.u32[i]);
 
 	transform(check->state.sha256.state, data);
@@ -172,6 +174,8 @@
 extern void
 lzma_sha256_finish(lzma_check_state *check)
 {
+	size_t i;
+	
 	// Add padding as described in RFC 3174 (it describes SHA-1 but
 	// the same padding style is used for SHA-256 too).
 	size_t pos = check->state.sha256.size & 0x3F;
@@ -193,7 +197,7 @@
 
 	process(check);
 
-	for (size_t i = 0; i < 8; ++i)
+	for (i = 0; i < 8; ++i)
 		check->buffer.u32[i] = conv32be(check->state.sha256.state[i]);
 
 	return;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/alone_decoder.c src/liblzma/common/alone_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/alone_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/alone_decoder.c	2014-05-03 15:35:01.772688400 +0200
@@ -16,7 +16,7 @@
 
 
 struct lzma_coder_s {
-	lzma_next_coder next;
+	struct lzma_next_coder_s next;
 
 	enum {
 		SEQ_PROPERTIES,
@@ -50,11 +50,11 @@
 
 
 static lzma_ret
-alone_decode(lzma_coder *coder,
-		lzma_allocator *allocator lzma_attribute((__unused__)),
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size,
+alone_decode(struct lzma_coder_s *coder,
+		lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size,
 		lzma_action action)
 {
 	while (*out_pos < out_size
@@ -126,19 +126,24 @@
 	// Fall through
 
 	case SEQ_CODER_INIT: {
-		if (coder->memusage > coder->memlimit)
-			return LZMA_MEMLIMIT_ERROR;
-
-		lzma_filter_info filters[2] = {
+		struct lzma_filter_info_s filters[2] = {
 			{
-				.init = &lzma_lzma_decoder_init,
-				.options = &coder->options,
+				0LL,
+				&lzma_lzma_decoder_init,
+				&coder->options
 			}, {
-				.init = NULL,
+				0LL,
+				NULL,
+				NULL
 			}
 		};
+		lzma_ret ret;
+
+		if (coder->memusage > coder->memlimit)
+			return LZMA_MEMLIMIT_ERROR;
+
 
-		const lzma_ret ret = lzma_next_filter_init(&coder->next,
+		ret = lzma_next_filter_init(&coder->next,
 				allocator, filters);
 		if (ret != LZMA_OK)
 			return ret;
@@ -166,7 +171,7 @@
 
 
 static void
-alone_decoder_end(lzma_coder *coder, lzma_allocator *allocator)
+alone_decoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_next_end(&coder->next, allocator);
 	lzma_free(coder, allocator);
@@ -175,7 +180,7 @@
 
 
 static lzma_ret
-alone_decoder_memconfig(lzma_coder *coder, uint64_t *memusage,
+alone_decoder_memconfig(struct lzma_coder_s *coder, uint64_t *memusage,
 		uint64_t *old_memlimit, uint64_t new_memlimit)
 {
 	*memusage = coder->memusage;
@@ -202,14 +207,16 @@
 		return LZMA_PROG_ERROR;
 
 	if (next->coder == NULL) {
-		next->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
 
 		next->code = &alone_decode;
 		next->end = &alone_decoder_end;
 		next->memconfig = &alone_decoder_memconfig;
-		next->coder->next = LZMA_NEXT_CODER_INIT;
+		next->coder->next = v;
 	}
 
 	next->coder->sequence = SEQ_PROPERTIES;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/alone_decoder.h src/liblzma/common/alone_decoder.h
--- ..\..\Library\xz-5.0.5\src/liblzma/common/alone_decoder.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/alone_decoder.h	2013-12-01 16:25:26.185795700 +0100
@@ -17,7 +17,7 @@
 
 
 extern lzma_ret lzma_alone_decoder_init(
-		lzma_next_coder *next, lzma_allocator *allocator,
+		struct lzma_next_coder_s *next, lzma_allocator *allocator,
 		uint64_t memlimit, bool picky);
 
 #endif
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/alone_encoder.c src/liblzma/common/alone_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/alone_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/alone_encoder.c	2014-05-03 15:46:09.519914000 +0200
@@ -31,11 +31,11 @@
 
 
 static lzma_ret
-alone_encode(lzma_coder *coder,
+alone_encode(struct lzma_coder_s *coder,
 		lzma_allocator *allocator lzma_attribute((__unused__)),
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size,
 		lzma_action action)
 {
 	while (*out_pos < out_size)
@@ -65,7 +65,7 @@
 
 
 static void
-alone_encoder_end(lzma_coder *coder, lzma_allocator *allocator)
+alone_encoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_next_end(&coder->next, allocator);
 	lzma_free(coder, allocator);
@@ -78,16 +78,31 @@
 alone_encoder_init(lzma_next_coder *next, lzma_allocator *allocator,
 		const lzma_options_lzma *options)
 {
+	// Initialize the LZMA encoder.
+	const lzma_filter_info filters[2] = {
+		{
+			0LL,
+			&lzma_lzma_encoder_init,
+			(void *)(options)
+		}, {
+			0LL,
+			NULL,
+			NULL
+		}
+	};
+	uint32_t d;
 	lzma_next_coder_init(&alone_encoder_init, next, allocator);
 
 	if (next->coder == NULL) {
-		next->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
 
 		next->code = &alone_encode;
 		next->end = &alone_encoder_end;
-		next->coder->next = LZMA_NEXT_CODER_INIT;
+		next->coder->next = v;
 	}
 
 	// Basic initializations
@@ -107,7 +122,7 @@
 	// one is the next unless it is UINT32_MAX. While the header would
 	// allow any 32-bit integer, we do this to keep the decoder of liblzma
 	// accepting the resulting files.
-	uint32_t d = options->dict_size - 1;
+	d = options->dict_size - 1;
 	d |= d >> 2;
 	d |= d >> 3;
 	d |= d >> 4;
@@ -121,16 +136,6 @@
 	// - Uncompressed size (always unknown and using EOPM)
 	memset(next->coder->header + 1 + 4, 0xFF, 8);
 
-	// Initialize the LZMA encoder.
-	const lzma_filter_info filters[2] = {
-		{
-			.init = &lzma_lzma_encoder_init,
-			.options = (void *)(options),
-		}, {
-			.init = NULL,
-		}
-	};
-
 	return lzma_next_filter_init(&next->coder->next, allocator, filters);
 }
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/auto_decoder.c src/liblzma/common/auto_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/auto_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/auto_decoder.c	2014-05-03 15:47:48.212417100 +0200
@@ -30,10 +30,10 @@
 
 
 static lzma_ret
-auto_decode(lzma_coder *coder, lzma_allocator *allocator,
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size, lzma_action action)
+auto_decode(struct lzma_coder_s *coder, lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size, lzma_action action)
 {
 	switch (coder->sequence) {
 	case SEQ_INIT:
@@ -100,7 +100,7 @@
 
 
 static void
-auto_decoder_end(lzma_coder *coder, lzma_allocator *allocator)
+auto_decoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_next_end(&coder->next, allocator);
 	lzma_free(coder, allocator);
@@ -109,7 +109,7 @@
 
 
 static lzma_check
-auto_decoder_get_check(const lzma_coder *coder)
+auto_decoder_get_check(const struct lzma_coder_s *coder)
 {
 	// It is LZMA_Alone if get_check is NULL.
 	return coder->next.get_check == NULL ? LZMA_CHECK_NONE
@@ -118,7 +118,7 @@
 
 
 static lzma_ret
-auto_decoder_memconfig(lzma_coder *coder, uint64_t *memusage,
+auto_decoder_memconfig(struct lzma_coder_s *coder, uint64_t *memusage,
 		uint64_t *old_memlimit, uint64_t new_memlimit)
 {
 	lzma_ret ret;
@@ -155,7 +155,9 @@
 		return LZMA_OPTIONS_ERROR;
 
 	if (next->coder == NULL) {
-		next->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
 
@@ -163,7 +165,7 @@
 		next->end = &auto_decoder_end;
 		next->get_check = &auto_decoder_get_check;
 		next->memconfig = &auto_decoder_memconfig;
-		next->coder->next = LZMA_NEXT_CODER_INIT;
+		next->coder->next = v;
 	}
 
 	next->coder->memlimit = memlimit;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/block_buffer_decoder.c src/liblzma/common/block_buffer_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/block_buffer_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/block_buffer_decoder.c	2014-05-03 15:48:55.418938500 +0200
@@ -18,6 +18,9 @@
 		const uint8_t *in, size_t *in_pos, size_t in_size,
 		uint8_t *out, size_t *out_pos, size_t out_size)
 {
+	lzma_next_coder block_decoder = LZMA_NEXT_CODER_INIT;
+	lzma_ret ret;
+
 	if (in_pos == NULL || (in == NULL && *in_pos != in_size)
 			|| *in_pos > in_size || out_pos == NULL
 			|| (out == NULL && *out_pos != out_size)
@@ -25,8 +28,7 @@
 		return LZMA_PROG_ERROR;
 
 	// Initialize the Block decoder.
-	lzma_next_coder block_decoder = LZMA_NEXT_CODER_INIT;
-	lzma_ret ret = lzma_block_decoder_init(
+	ret = lzma_block_decoder_init(
 			&block_decoder, allocator, block);
 
 	if (ret == LZMA_OK) {
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/block_buffer_encoder.c src/liblzma/common/block_buffer_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/block_buffer_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/block_buffer_encoder.c	2014-05-03 15:56:39.732205200 +0200
@@ -31,6 +31,8 @@
 static lzma_vli
 lzma2_bound(lzma_vli uncompressed_size)
 {
+	lzma_vli overhead;
+
 	// Prevent integer overflow in overhead calculation.
 	if (uncompressed_size > COMPRESSED_SIZE_MAX)
 		return 0;
@@ -39,7 +41,7 @@
 	// uncompressed_size up to the next multiple of LZMA2_CHUNK_MAX,
 	// multiply by the size of per-chunk header, and add one byte for
 	// the end marker.
-	const lzma_vli overhead = ((uncompressed_size + LZMA2_CHUNK_MAX - 1)
+	overhead = ((uncompressed_size + LZMA2_CHUNK_MAX - 1)
 				/ LZMA2_CHUNK_MAX)
 			* LZMA2_HEADER_UNCOMPRESSED + 1;
 
@@ -89,17 +91,21 @@
 	// all, but LZMA2 always requires a dictionary, so use the minimum
 	// value to minimize memory usage of the decoder.
 	lzma_options_lzma lzma2 = {
-		.dict_size = LZMA_DICT_SIZE_MIN,
+		LZMA_DICT_SIZE_MIN,
+		0
 	};
-
 	lzma_filter filters[2];
+	lzma_filter *filters_orig;
+	size_t in_pos = 0;
+	uint8_t control = 0x01; // Dictionary reset
+	
 	filters[0].id = LZMA_FILTER_LZMA2;
 	filters[0].options = &lzma2;
 	filters[1].id = LZMA_VLI_UNKNOWN;
 
 	// Set the above filter options to *block temporarily so that we can
 	// encode the Block Header.
-	lzma_filter *filters_orig = block->filters;
+	filters_orig = block->filters;
 	block->filters = filters;
 
 	if (lzma_block_header_size(block) != LZMA_OK) {
@@ -128,17 +134,15 @@
 	*out_pos += block->header_size;
 
 	// Encode the data using LZMA2 uncompressed chunks.
-	size_t in_pos = 0;
-	uint8_t control = 0x01; // Dictionary reset
-
 	while (in_pos < in_size) {
+		size_t copy_size;
 		// Control byte: Indicate uncompressed chunk, of which
 		// the first resets the dictionary.
 		out[(*out_pos)++] = control;
 		control = 0x02; // No dictionary reset
 
 		// Size of the uncompressed chunk
-		const size_t copy_size
+		copy_size
 				= my_min(in_size - in_pos, LZMA2_CHUNK_MAX);
 		out[(*out_pos)++] = (copy_size - 1) >> 8;
 		out[(*out_pos)++] = (copy_size - 1) & 0xFF;
@@ -164,6 +168,10 @@
 		const uint8_t *in, size_t in_size,
 		uint8_t *out, size_t *out_pos, size_t out_size)
 {
+	size_t out_start;
+	lzma_next_coder raw_encoder = LZMA_NEXT_CODER_INIT;
+	lzma_ret ret;
+
 	// Find out the size of the Block Header.
 	block->compressed_size = lzma2_bound(in_size);
 	if (block->compressed_size == 0)
@@ -176,7 +184,7 @@
 	if (out_size - *out_pos <= block->header_size)
 		return LZMA_BUF_ERROR;
 
-	const size_t out_start = *out_pos;
+	out_start = *out_pos;
 	*out_pos += block->header_size;
 
 	// Limit out_size so that we stop encoding if the output would grow
@@ -186,8 +194,7 @@
 
 	// TODO: In many common cases this could be optimized to use
 	// significantly less memory.
-	lzma_next_coder raw_encoder = LZMA_NEXT_CODER_INIT;
-	lzma_ret ret = lzma_raw_encoder_init(
+	ret = lzma_raw_encoder_init(
 			&raw_encoder, allocator, block->filters);
 
 	if (ret == LZMA_OK) {
@@ -226,6 +233,10 @@
 		const uint8_t *in, size_t in_size,
 		uint8_t *out, size_t *out_pos, size_t out_size)
 {
+	size_t check_size;
+	lzma_ret ret;
+	size_t i;
+	
 	// Validate the arguments.
 	if (block == NULL || (in == NULL && in_size != 0) || out == NULL
 			|| out_pos == NULL || *out_pos > out_size)
@@ -249,7 +260,7 @@
 	out_size -= (out_size - *out_pos) & 3;
 
 	// Get the size of the Check field.
-	const size_t check_size = lzma_check_size(block->check);
+	check_size = lzma_check_size(block->check);
 	assert(check_size != UINT32_MAX);
 
 	// Reserve space for the Check field.
@@ -259,7 +270,7 @@
 	out_size -= check_size;
 
 	// Do the actual compression.
-	const lzma_ret ret = block_encode_normal(block, allocator,
+	ret = block_encode_normal(block, allocator,
 			in, in_size, out, out_pos, out_size);
 	if (ret != LZMA_OK) {
 		// If the error was something else than output buffer
@@ -281,7 +292,7 @@
 	// Block Padding. No buffer overflow here, because we already adjusted
 	// out_size so that (out_size - out_start) is a multiple of four.
 	// Thus, if the buffer is full, the loop body can never run.
-	for (size_t i = (size_t)(block->compressed_size); i & 3; ++i) {
+	for (i = (size_t)(block->compressed_size); i & 3; ++i) {
 		assert(*out_pos < out_size);
 		out[(*out_pos)++] = 0x00;
 	}
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/block_decoder.c src/liblzma/common/block_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/block_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/block_decoder.c	2014-05-03 15:57:46.344946600 +0200
@@ -48,7 +48,7 @@
 };
 
 
-static inline bool
+static __inline bool
 update_size(lzma_vli *size, lzma_vli add, lzma_vli limit)
 {
 	if (limit > LZMA_VLI_MAX)
@@ -63,7 +63,7 @@
 }
 
 
-static inline bool
+static __inline bool
 is_size_valid(lzma_vli size, lzma_vli reference)
 {
 	return reference == LZMA_VLI_UNKNOWN || reference == size;
@@ -71,10 +71,10 @@
 
 
 static lzma_ret
-block_decode(lzma_coder *coder, lzma_allocator *allocator,
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size, lzma_action action)
+block_decode(struct lzma_coder_s *coder, lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size, lzma_action action)
 {
 	switch (coder->sequence) {
 	case SEQ_CODE: {
@@ -170,7 +170,7 @@
 
 
 static void
-block_decoder_end(lzma_coder *coder, lzma_allocator *allocator)
+block_decoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_next_end(&coder->next, allocator);
 	lzma_free(coder, allocator);
@@ -193,13 +193,15 @@
 
 	// Allocate and initialize *next->coder if needed.
 	if (next->coder == NULL) {
-		next->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
 
 		next->code = &block_decode;
 		next->end = &block_decoder_end;
-		next->coder->next = LZMA_NEXT_CODER_INIT;
+		next->coder->next = v;
 	}
 
 	// Basic initializations
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/block_encoder.c src/liblzma/common/block_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/block_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/block_encoder.c	2014-05-03 15:58:36.144338300 +0200
@@ -45,10 +45,10 @@
 
 
 static lzma_ret
-block_encode(lzma_coder *coder, lzma_allocator *allocator,
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size, lzma_action action)
+block_encode(struct lzma_coder_s *coder, lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size, lzma_action action)
 {
 	// Check that our amount of input stays in proper limits.
 	if (LZMA_VLI_MAX - coder->uncompressed_size < in_size - *in_pos)
@@ -134,7 +134,7 @@
 
 
 static void
-block_encoder_end(lzma_coder *coder, lzma_allocator *allocator)
+block_encoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_next_end(&coder->next, allocator);
 	lzma_free(coder, allocator);
@@ -143,7 +143,7 @@
 
 
 static lzma_ret
-block_encoder_update(lzma_coder *coder, lzma_allocator *allocator,
+block_encoder_update(struct lzma_coder_s *coder, lzma_allocator *allocator,
 		const lzma_filter *filters lzma_attribute((__unused__)),
 		const lzma_filter *reversed_filters)
 {
@@ -179,14 +179,16 @@
 
 	// Allocate and initialize *next->coder if needed.
 	if (next->coder == NULL) {
-		next->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
 
 		next->code = &block_encode;
 		next->end = &block_encoder_end;
 		next->update = &block_encoder_update;
-		next->coder->next = LZMA_NEXT_CODER_INIT;
+		next->coder->next = v;
 	}
 
 	// Basic initializations
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/block_header_decoder.c src/liblzma/common/block_header_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/block_header_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/block_header_decoder.c	2014-05-03 16:00:29.108112600 +0200
@@ -17,10 +17,11 @@
 static void
 free_properties(lzma_block *block, lzma_allocator *allocator)
 {
+	size_t i;
 	// Free allocated filter options. The last array member is not
 	// touched after the initialization in the beginning of
 	// lzma_block_header_decode(), so we don't need to touch that here.
-	for (size_t i = 0; i < LZMA_FILTERS_MAX; ++i) {
+	for (i = 0; i < LZMA_FILTERS_MAX; ++i) {
 		lzma_free(block->filters[i].options, allocator);
 		block->filters[i].id = LZMA_VLI_UNKNOWN;
 		block->filters[i].options = NULL;
@@ -34,6 +35,11 @@
 lzma_block_header_decode(lzma_block *block,
 		lzma_allocator *allocator, const uint8_t *in)
 {
+	size_t in_pos;
+	size_t in_size;
+	size_t i;
+	size_t filter_count;
+	
 	// NOTE: We consider the header to be corrupt not only when the
 	// CRC32 doesn't match, but also when variable-length integers
 	// are invalid or over 63 bits, or if the header is too small
@@ -41,7 +47,7 @@
 
 	// Initialize the filter options array. This way the caller can
 	// safely free() the options even if an error occurs in this function.
-	for (size_t i = 0; i <= LZMA_FILTERS_MAX; ++i) {
+	for (i = 0; i <= LZMA_FILTERS_MAX; ++i) {
 		block->filters[i].id = LZMA_VLI_UNKNOWN;
 		block->filters[i].options = NULL;
 	}
@@ -56,7 +62,7 @@
 		return LZMA_PROG_ERROR;
 
 	// Exclude the CRC32 field.
-	const size_t in_size = block->header_size - 4;
+	in_size = block->header_size - 4;
 
 	// Verify CRC32
 	if (lzma_crc32(in, in_size, 0) != unaligned_read32le(in + in_size))
@@ -67,7 +73,7 @@
 		return LZMA_OPTIONS_ERROR;
 
 	// Start after the Block Header Size and Block Flags fields.
-	size_t in_pos = 2;
+	in_pos = 2;
 
 	// Compressed Size
 	if (in[1] & 0x40) {
@@ -90,8 +96,8 @@
 		block->uncompressed_size = LZMA_VLI_UNKNOWN;
 
 	// Filter Flags
-	const size_t filter_count = (in[1] & 3) + 1;
-	for (size_t i = 0; i < filter_count; ++i) {
+	filter_count = (in[1] & 3) + 1;
+	for (i = 0; i < filter_count; ++i) {
 		const lzma_ret ret = lzma_filter_flags_decode(
 				&block->filters[i], allocator,
 				in, &in_pos, in_size);
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/block_header_encoder.c src/liblzma/common/block_header_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/block_header_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/block_header_encoder.c	2014-05-03 16:01:42.580575700 +0200
@@ -17,11 +17,12 @@
 extern LZMA_API(lzma_ret)
 lzma_block_header_size(lzma_block *block)
 {
-	if (block->version != 0)
-		return LZMA_OPTIONS_ERROR;
-
 	// Block Header Size + Block Flags + CRC32.
 	uint32_t size = 1 + 1 + 4;
+	size_t i;
+	
+	if (block->version != 0)
+		return LZMA_OPTIONS_ERROR;
 
 	// Compressed Size
 	if (block->compressed_size != LZMA_VLI_UNKNOWN) {
@@ -45,12 +46,13 @@
 	if (block->filters == NULL || block->filters[0].id == LZMA_VLI_UNKNOWN)
 		return LZMA_PROG_ERROR;
 
-	for (size_t i = 0; block->filters[i].id != LZMA_VLI_UNKNOWN; ++i) {
+	for (i = 0; block->filters[i].id != LZMA_VLI_UNKNOWN; ++i) {
+		uint32_t add;
+
 		// Don't allow too many filters.
 		if (i == LZMA_FILTERS_MAX)
 			return LZMA_PROG_ERROR;
 
-		uint32_t add;
 		return_if_error(lzma_filter_flags_size(&add,
 				block->filters + i));
 
@@ -73,20 +75,23 @@
 extern LZMA_API(lzma_ret)
 lzma_block_header_encode(const lzma_block *block, uint8_t *out)
 {
+	size_t filter_count;
+	size_t out_size;
+	size_t out_pos = 2;
+
 	// Validate everything but filters.
 	if (lzma_block_unpadded_size(block) == 0
 			|| !lzma_vli_is_valid(block->uncompressed_size))
 		return LZMA_PROG_ERROR;
 
 	// Indicate the size of the buffer _excluding_ the CRC32 field.
-	const size_t out_size = block->header_size - 4;
+	out_size = block->header_size - 4;
 
 	// Store the Block Header Size.
 	out[0] = out_size / 4;
 
 	// We write Block Flags in pieces.
 	out[1] = 0x00;
-	size_t out_pos = 2;
 
 	// Compressed Size
 	if (block->compressed_size != LZMA_VLI_UNKNOWN) {
@@ -108,7 +113,7 @@
 	if (block->filters == NULL || block->filters[0].id == LZMA_VLI_UNKNOWN)
 		return LZMA_PROG_ERROR;
 
-	size_t filter_count = 0;
+	filter_count = 0;
 	do {
 		// There can be a maximum of four filters.
 		if (filter_count == LZMA_FILTERS_MAX)
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/block_util.c src/liblzma/common/block_util.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/block_util.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/block_util.c	2013-12-01 17:31:01.516387200 +0100
@@ -17,11 +17,14 @@
 extern LZMA_API(lzma_ret)
 lzma_block_compressed_size(lzma_block *block, lzma_vli unpadded_size)
 {
+	lzma_vli compressed_size;
+	uint32_t container_size;
+
 	// Validate everything but Uncompressed Size and filters.
 	if (lzma_block_unpadded_size(block) == 0)
 		return LZMA_PROG_ERROR;
 
-	const uint32_t container_size = block->header_size
+	container_size = block->header_size
 			+ lzma_check_size(block->check);
 
 	// Validate that Compressed Size will be greater than zero.
@@ -31,7 +34,7 @@
 	// Calculate what Compressed Size is supposed to be.
 	// If Compressed Size was present in Block Header,
 	// compare that the new value matches it.
-	const lzma_vli compressed_size = unpadded_size - container_size;
+	compressed_size = unpadded_size - container_size;
 	if (block->compressed_size != LZMA_VLI_UNKNOWN
 			&& block->compressed_size != compressed_size)
 		return LZMA_DATA_ERROR;
@@ -45,6 +48,8 @@
 extern LZMA_API(lzma_vli)
 lzma_block_unpadded_size(const lzma_block *block)
 {
+	lzma_vli unpadded_size;
+
 	// Validate the values that we are interested in i.e. all but
 	// Uncompressed Size and the filters.
 	//
@@ -66,7 +71,7 @@
 		return LZMA_VLI_UNKNOWN;
 
 	// Calculate Unpadded Size and validate it.
-	const lzma_vli unpadded_size = block->compressed_size
+	unpadded_size = block->compressed_size
 				+ block->header_size
 				+ lzma_check_size(block->check);
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/common.c src/liblzma/common/common.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/common.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/common.c	2014-05-03 16:05:02.715691400 +0200
@@ -38,12 +38,12 @@
 extern void * lzma_attribute((__malloc__)) lzma_attr_alloc_size(1)
 lzma_alloc(size_t size, lzma_allocator *allocator)
 {
+	void *ptr;
+
 	// Some malloc() variants return NULL if called with size == 0.
 	if (size == 0)
 		size = 1;
 
-	void *ptr;
-
 	if (allocator != NULL && allocator->alloc != NULL)
 		ptr = allocator->alloc(allocator->opaque, 1, size);
 	else
@@ -70,9 +70,9 @@
 //////////
 
 extern size_t
-lzma_bufcpy(const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size)
+lzma_bufcpy(const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size)
 {
 	const size_t in_avail = in_size - *in_pos;
 	const size_t out_avail = out_size - *out_pos;
@@ -120,6 +120,8 @@
 lzma_next_end(lzma_next_coder *next, lzma_allocator *allocator)
 {
 	if (next->init != (uintptr_t)(NULL)) {
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		
 		// To avoid tiny end functions that simply call
 		// lzma_free(coder, allocator), we allow leaving next->end
 		// NULL and call lzma_free() here.
@@ -130,7 +132,7 @@
 
 		// Reset the variables so the we don't accidentally think
 		// that it is an already initialized coder.
-		*next = LZMA_NEXT_CODER_INIT;
+		*next = v;
 	}
 
 	return;
@@ -148,12 +150,14 @@
 		return LZMA_PROG_ERROR;
 
 	if (strm->internal == NULL) {
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		
 		strm->internal = lzma_alloc(sizeof(lzma_internal),
 				strm->allocator);
 		if (strm->internal == NULL)
 			return LZMA_MEM_ERROR;
 
-		strm->internal->next = LZMA_NEXT_CODER_INIT;
+		strm->internal->next = v;
 	}
 
 	strm->internal->supported_actions[LZMA_RUN] = false;
@@ -173,6 +177,10 @@
 extern LZMA_API(lzma_ret)
 lzma_code(lzma_stream *strm, lzma_action action)
 {
+	size_t in_pos = 0;
+	size_t out_pos = 0;
+	lzma_ret ret;
+	
 	// Sanity checks
 	if ((strm->next_in == NULL && strm->avail_in != 0)
 			|| (strm->next_out == NULL && strm->avail_out != 0)
@@ -248,9 +256,7 @@
 		return LZMA_PROG_ERROR;
 	}
 
-	size_t in_pos = 0;
-	size_t out_pos = 0;
-	lzma_ret ret = strm->internal->next.code(
+	ret = strm->internal->next.code(
 			strm->internal->next.coder, strm->allocator,
 			strm->next_in, &in_pos, strm->avail_in,
 			strm->next_out, &out_pos, strm->avail_out, action);
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/common.h src/liblzma/common/common.h
--- ..\..\Library\xz-5.0.5\src/liblzma/common/common.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/common.h	2014-05-03 15:41:34.997292600 +0200
@@ -71,38 +71,35 @@
 
 /// Type of encoder/decoder specific data; the actual structure is defined
 /// differently in different coders.
-typedef struct lzma_coder_s lzma_coder;
-
-typedef struct lzma_next_coder_s lzma_next_coder;
-
-typedef struct lzma_filter_info_s lzma_filter_info;
-
+struct lzma_coder_s;
+struct lzma_next_coder_s;
+struct lzma_filter_info_s;
 
 /// Type of a function used to initialize a filter encoder or decoder
 typedef lzma_ret (*lzma_init_function)(
-		lzma_next_coder *next, lzma_allocator *allocator,
-		const lzma_filter_info *filters);
+		struct lzma_next_coder_s *next, lzma_allocator *allocator,
+			const struct lzma_filter_info_s *filters);
 
 /// Type of a function to do some kind of coding work (filters, Stream,
 /// Block encoders/decoders etc.). Some special coders use don't use both
 /// input and output buffers, but for simplicity they still use this same
 /// function prototype.
 typedef lzma_ret (*lzma_code_function)(
-		lzma_coder *coder, lzma_allocator *allocator,
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size,
+		struct lzma_coder_s *coder, lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size,
 		lzma_action action);
 
 /// Type of a function to free the memory allocated for the coder
 typedef void (*lzma_end_function)(
-		lzma_coder *coder, lzma_allocator *allocator);
+		struct lzma_coder_s *coder, lzma_allocator *allocator);
 
 
 /// Raw coder validates and converts an array of lzma_filter structures to
 /// an array of lzma_filter_info structures. This array is used with
 /// lzma_next_filter_init to initialize the filter chain.
-struct lzma_filter_info_s {
+typedef struct lzma_filter_info_s {
 	/// Filter ID. This is used only by the encoder
 	/// with lzma_filters_update().
 	lzma_vli id;
@@ -113,13 +110,13 @@
 
 	/// Pointer to filter's options structure
 	void *options;
-};
+} lzma_filter_info;
 
 
 /// Hold data and function pointers of the next filter in the chain.
-struct lzma_next_coder_s {
+typedef struct lzma_next_coder_s {
 	/// Pointer to coder-specific data
-	lzma_coder *coder;
+	struct lzma_coder_s *coder;
 
 	/// Filter ID. This is LZMA_VLI_UNKNOWN when this structure doesn't
 	/// point to a filter coder.
@@ -141,32 +138,32 @@
 
 	/// Pointer to function to return the type of the integrity check.
 	/// Most coders won't support this.
-	lzma_check (*get_check)(const lzma_coder *coder);
+	lzma_check(*get_check)(const struct lzma_coder_s *coder);
 
 	/// Pointer to function to get and/or change the memory usage limit.
 	/// If new_memlimit == 0, the limit is not changed.
-	lzma_ret (*memconfig)(lzma_coder *coder, uint64_t *memusage,
+	lzma_ret(*memconfig)(struct lzma_coder_s *coder, uint64_t *memusage,
 			uint64_t *old_memlimit, uint64_t new_memlimit);
 
 	/// Update the filter-specific options or the whole filter chain
 	/// in the encoder.
-	lzma_ret (*update)(lzma_coder *coder, lzma_allocator *allocator,
+	lzma_ret(*update)(struct lzma_coder_s *coder, lzma_allocator *allocator,
 			const lzma_filter *filters,
 			const lzma_filter *reversed_filters);
-};
+} lzma_next_coder;
 
 
 /// Macro to initialize lzma_next_coder structure
 #define LZMA_NEXT_CODER_INIT \
-	(lzma_next_coder){ \
-		.coder = NULL, \
-		.init = (uintptr_t)(NULL), \
-		.id = LZMA_VLI_UNKNOWN, \
-		.code = NULL, \
-		.end = NULL, \
-		.get_check = NULL, \
-		.memconfig = NULL, \
-		.update = NULL, \
+	{ \
+		NULL, \
+		LZMA_VLI_UNKNOWN, \
+		(uintptr_t)(NULL), \
+		NULL, \
+		NULL, \
+		NULL, \
+		NULL, \
+		NULL \
 	}
 
 
@@ -174,7 +171,7 @@
 /// this is stored in lzma_stream.
 struct lzma_internal_s {
 	/// The actual coder that should do something useful
-	lzma_next_coder next;
+	struct lzma_next_coder_s next;
 
 	/// Track the state of the coder. This is used to validate arguments
 	/// so that the actual coders can rely on e.g. that LZMA_SYNC_FLUSH
@@ -219,25 +216,25 @@
 /// freeing the memory of previously initialized filter if it is different
 /// than the filter being initialized now. This way the actual filter
 /// initialization functions don't need to use lzma_next_coder_init macro.
-extern lzma_ret lzma_next_filter_init(lzma_next_coder *next,
+extern lzma_ret lzma_next_filter_init(struct lzma_next_coder_s *next,
 		lzma_allocator *allocator, const lzma_filter_info *filters);
 
 /// Update the next filter in the chain, if any. This checks that
 /// the application is not trying to change the Filter IDs.
 extern lzma_ret lzma_next_filter_update(
-		lzma_next_coder *next, lzma_allocator *allocator,
+		struct lzma_next_coder_s *next, lzma_allocator *allocator,
 		const lzma_filter *reversed_filters);
 
 /// Frees the memory allocated for next->coder either using next->end or,
 /// if next->end is NULL, using lzma_free.
-extern void lzma_next_end(lzma_next_coder *next, lzma_allocator *allocator);
+extern void lzma_next_end(struct lzma_next_coder_s *next, lzma_allocator *allocator);
 
 
 /// Copy as much data as possible from in[] to out[] and update *in_pos
 /// and *out_pos accordingly. Returns the number of bytes copied.
-extern size_t lzma_bufcpy(const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size);
+extern size_t lzma_bufcpy(const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size);
 
 
 /// \brief      Return if expression doesn't evaluate to LZMA_OK
@@ -272,8 +269,9 @@
 /// along strm->internal.
 #define lzma_next_strm_init(func, strm, ...) \
 do { \
+	lzma_ret ret_; \
 	return_if_error(lzma_strm_init(strm)); \
-	const lzma_ret ret_ = func(&(strm)->internal->next, \
+	ret_ = func(&(strm)->internal->next, \
 			(strm)->allocator, __VA_ARGS__); \
 	if (ret_ != LZMA_OK) { \
 		lzma_end(strm); \
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/filter_buffer_decoder.c src/liblzma/common/filter_buffer_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/filter_buffer_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/filter_buffer_decoder.c	2014-05-03 16:06:47.017844700 +0200
@@ -18,22 +18,24 @@
 		const uint8_t *in, size_t *in_pos, size_t in_size,
 		uint8_t *out, size_t *out_pos, size_t out_size)
 {
+	lzma_next_coder next = LZMA_NEXT_CODER_INIT;
+	// Store the positions so that we can restore them if something
+	// goes wrong.
+	const size_t in_start = *in_pos;
+	const size_t out_start = *out_pos;
+	
+	lzma_ret ret;
+
 	// Validate what isn't validated later in filter_common.c.
 	if (in == NULL || in_pos == NULL || *in_pos > in_size || out == NULL
 			|| out_pos == NULL || *out_pos > out_size)
 		return LZMA_PROG_ERROR;
 
 	// Initialize the decoer.
-	lzma_next_coder next = LZMA_NEXT_CODER_INIT;
 	return_if_error(lzma_raw_decoder_init(&next, allocator, filters));
 
-	// Store the positions so that we can restore them if something
-	// goes wrong.
-	const size_t in_start = *in_pos;
-	const size_t out_start = *out_pos;
-
 	// Do the actual decoding and free decoder's memory.
-	lzma_ret ret = next.code(next.coder, allocator, in, in_pos, in_size,
+	ret = next.code(next.coder, allocator, in, in_pos, in_size,
 			out, out_pos, out_size, LZMA_FINISH);
 
 	if (ret == LZMA_STREAM_END) {
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/filter_buffer_encoder.c src/liblzma/common/filter_buffer_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/filter_buffer_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/filter_buffer_encoder.c	2014-05-03 16:07:54.779647600 +0200
@@ -18,22 +18,23 @@
 		const uint8_t *in, size_t in_size, uint8_t *out,
 		size_t *out_pos, size_t out_size)
 {
+	lzma_next_coder next = LZMA_NEXT_CODER_INIT;
+	// Store the output position so that we can restore it if
+	// something goes wrong.
+	const size_t out_start = *out_pos;
+	size_t in_pos = 0;
+	lzma_ret ret;
+	
 	// Validate what isn't validated later in filter_common.c.
 	if ((in == NULL && in_size != 0) || out == NULL
 			|| out_pos == NULL || *out_pos > out_size)
 		return LZMA_PROG_ERROR;
 
 	// Initialize the encoder
-	lzma_next_coder next = LZMA_NEXT_CODER_INIT;
 	return_if_error(lzma_raw_encoder_init(&next, allocator, filters));
 
-	// Store the output position so that we can restore it if
-	// something goes wrong.
-	const size_t out_start = *out_pos;
-
 	// Do the actual encoding and free coder's memory.
-	size_t in_pos = 0;
-	lzma_ret ret = next.code(next.coder, allocator, in, &in_pos, in_size,
+	ret = next.code(next.coder, allocator, in, &in_pos, in_size,
 			out, out_pos, out_size, LZMA_FINISH);
 	lzma_next_end(&next, allocator);
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/filter_common.c src/liblzma/common/filter_common.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/filter_common.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/filter_common.c	2014-05-03 16:15:11.629851600 +0200
@@ -36,87 +36,88 @@
 } features[] = {
 #if defined (HAVE_ENCODER_LZMA1) || defined(HAVE_DECODER_LZMA1)
 	{
-		.id = LZMA_FILTER_LZMA1,
-		.options_size = sizeof(lzma_options_lzma),
-		.non_last_ok = false,
-		.last_ok = true,
-		.changes_size = true,
+		LZMA_FILTER_LZMA1,
+		sizeof(lzma_options_lzma),
+		false,
+		true,
+		true
 	},
 #endif
 #if defined(HAVE_ENCODER_LZMA2) || defined(HAVE_DECODER_LZMA2)
 	{
-		.id = LZMA_FILTER_LZMA2,
-		.options_size = sizeof(lzma_options_lzma),
-		.non_last_ok = false,
-		.last_ok = true,
-		.changes_size = true,
+		LZMA_FILTER_LZMA2,
+		sizeof(lzma_options_lzma),
+		false,
+		true,
+		true
 	},
 #endif
 #if defined(HAVE_ENCODER_X86) || defined(HAVE_DECODER_X86)
 	{
-		.id = LZMA_FILTER_X86,
-		.options_size = sizeof(lzma_options_bcj),
-		.non_last_ok = true,
-		.last_ok = false,
-		.changes_size = false,
+		LZMA_FILTER_X86,
+		sizeof(lzma_options_bcj),
+		true,
+		false,
+		false
 	},
 #endif
 #if defined(HAVE_ENCODER_POWERPC) || defined(HAVE_DECODER_POWERPC)
 	{
-		.id = LZMA_FILTER_POWERPC,
-		.options_size = sizeof(lzma_options_bcj),
-		.non_last_ok = true,
-		.last_ok = false,
-		.changes_size = false,
+		LZMA_FILTER_POWERPC,
+		sizeof(lzma_options_bcj),
+		true,
+		false,
+		false
 	},
 #endif
 #if defined(HAVE_ENCODER_IA64) || defined(HAVE_DECODER_IA64)
 	{
-		.id = LZMA_FILTER_IA64,
-		.options_size = sizeof(lzma_options_bcj),
-		.non_last_ok = true,
-		.last_ok = false,
-		.changes_size = false,
+		LZMA_FILTER_IA64,
+		sizeof(lzma_options_bcj),
+		true,
+		false,
+		false
 	},
 #endif
 #if defined(HAVE_ENCODER_ARM) || defined(HAVE_DECODER_ARM)
 	{
-		.id = LZMA_FILTER_ARM,
-		.options_size = sizeof(lzma_options_bcj),
-		.non_last_ok = true,
-		.last_ok = false,
-		.changes_size = false,
+		LZMA_FILTER_ARM,
+		sizeof(lzma_options_bcj),
+		true,
+		false,
+		false
 	},
 #endif
 #if defined(HAVE_ENCODER_ARMTHUMB) || defined(HAVE_DECODER_ARMTHUMB)
 	{
-		.id = LZMA_FILTER_ARMTHUMB,
-		.options_size = sizeof(lzma_options_bcj),
-		.non_last_ok = true,
-		.last_ok = false,
-		.changes_size = false,
+		LZMA_FILTER_ARMTHUMB,
+		sizeof(lzma_options_bcj),
+		true,
+		false,
+		false
 	},
 #endif
 #if defined(HAVE_ENCODER_SPARC) || defined(HAVE_DECODER_SPARC)
 	{
-		.id = LZMA_FILTER_SPARC,
-		.options_size = sizeof(lzma_options_bcj),
-		.non_last_ok = true,
-		.last_ok = false,
-		.changes_size = false,
+		LZMA_FILTER_SPARC,
+		sizeof(lzma_options_bcj),
+		true,
+		false,
+		false
 	},
 #endif
 #if defined(HAVE_ENCODER_DELTA) || defined(HAVE_DECODER_DELTA)
 	{
-		.id = LZMA_FILTER_DELTA,
-		.options_size = sizeof(lzma_options_delta),
-		.non_last_ok = true,
-		.last_ok = false,
-		.changes_size = false,
+		LZMA_FILTER_DELTA,
+		sizeof(lzma_options_delta),
+		true,
+		false,
+		false
 	},
 #endif
 	{
-		.id = LZMA_VLI_UNKNOWN
+		LZMA_VLI_UNKNOWN,
+		0
 	}
 };
 
@@ -125,11 +126,12 @@
 lzma_filters_copy(const lzma_filter *src, lzma_filter *dest,
 		lzma_allocator *allocator)
 {
+	lzma_ret ret;
+	size_t i;
+
 	if (src == NULL || dest == NULL)
 		return LZMA_PROG_ERROR;
 
-	lzma_ret ret;
-	size_t i;
 	for (i = 0; src[i].id != LZMA_VLI_UNKNOWN; ++i) {
 		// There must be a maximum of four filters plus
 		// the array terminator.
@@ -192,15 +194,9 @@
 
 static lzma_ret
 validate_chain(const lzma_filter *filters, size_t *count)
-{
-	// There must be at least one filter.
-	if (filters == NULL || filters[0].id == LZMA_VLI_UNKNOWN)
-		return LZMA_PROG_ERROR;
-
-	// Number of non-last filters that may change the size of the data
-	// significantly (that is, more than 1-2 % or so).
-	size_t changes_size_count = 0;
-
+{ 
+	size_t changes_size_count;
+	
 	// True if it is OK to add a new filter after the current filter.
 	bool non_last_ok = true;
 
@@ -210,8 +206,18 @@
 	bool last_ok = false;
 
 	size_t i = 0;
+
+	// There must be at least one filter.
+	if (filters == NULL || filters[0].id == LZMA_VLI_UNKNOWN)
+		return LZMA_PROG_ERROR;
+
+	// Number of non-last filters that may change the size of the data
+	// significantly (that is, more than 1-2 % or so).
+	changes_size_count = 0;
+
 	do {
 		size_t j;
+		
 		for (j = 0; filters[i].id != features[j].id; ++j)
 			if (features[j].id == LZMA_VLI_UNKNOWN)
 				return LZMA_OPTIONS_ERROR;
@@ -245,12 +251,15 @@
 {
 	// Do some basic validation and get the number of filters.
 	size_t count;
-	return_if_error(validate_chain(options, &count));
-
 	// Set the filter functions and copy the options pointer.
 	lzma_filter_info filters[LZMA_FILTERS_MAX + 1];
+	size_t i;
+	lzma_ret ret;
+	
+	return_if_error(validate_chain(options, &count));
+
 	if (is_encoder) {
-		for (size_t i = 0; i < count; ++i) {
+		for (i = 0; i < count; ++i) {
 			// The order of the filters is reversed in the
 			// encoder. It allows more efficient handling
 			// of the uncompressed data.
@@ -266,7 +275,7 @@
 			filters[j].options = options[i].options;
 		}
 	} else {
-		for (size_t i = 0; i < count; ++i) {
+		for (i = 0; i < count; ++i) {
 			const lzma_filter_coder *const fc
 					= coder_find(options[i].id);
 			if (fc == NULL || fc->init == NULL)
@@ -283,7 +292,7 @@
 	filters[count].init = NULL;
 
 	// Initialize the filters.
-	const lzma_ret ret = lzma_next_filter_init(next, allocator, filters);
+	ret = lzma_next_filter_init(next, allocator, filters);
 	if (ret != LZMA_OK)
 		lzma_next_end(next, allocator);
 
@@ -295,6 +304,9 @@
 lzma_raw_coder_memusage(lzma_filter_find coder_find,
 		const lzma_filter *filters)
 {
+	uint64_t total = 0;
+	size_t i = 0;
+
 	// The chain has to have at least one filter.
 	{
 		size_t tmp;
@@ -302,9 +314,6 @@
 			return UINT64_MAX;
 	}
 
-	uint64_t total = 0;
-	size_t i = 0;
-
 	do {
 		const lzma_filter_coder *const fc
 				 = coder_find(filters[i].id);
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/filter_decoder.c src/liblzma/common/filter_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/filter_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/filter_decoder.c	2014-05-03 16:18:14.257066200 +0200
@@ -44,74 +44,74 @@
 static const lzma_filter_decoder decoders[] = {
 #ifdef HAVE_DECODER_LZMA1
 	{
-		.id = LZMA_FILTER_LZMA1,
-		.init = &lzma_lzma_decoder_init,
-		.memusage = &lzma_lzma_decoder_memusage,
-		.props_decode = &lzma_lzma_props_decode,
+		LZMA_FILTER_LZMA1,
+		&lzma_lzma_decoder_init,
+		&lzma_lzma_decoder_memusage,
+		&lzma_lzma_props_decode
 	},
 #endif
 #ifdef HAVE_DECODER_LZMA2
 	{
-		.id = LZMA_FILTER_LZMA2,
-		.init = &lzma_lzma2_decoder_init,
-		.memusage = &lzma_lzma2_decoder_memusage,
-		.props_decode = &lzma_lzma2_props_decode,
+		LZMA_FILTER_LZMA2,
+		&lzma_lzma2_decoder_init,
+		&lzma_lzma2_decoder_memusage,
+		&lzma_lzma2_props_decode
 	},
 #endif
 #ifdef HAVE_DECODER_X86
 	{
-		.id = LZMA_FILTER_X86,
-		.init = &lzma_simple_x86_decoder_init,
-		.memusage = NULL,
-		.props_decode = &lzma_simple_props_decode,
+		LZMA_FILTER_X86,
+		&lzma_simple_x86_decoder_init,
+		NULL,
+		&lzma_simple_props_decode
 	},
 #endif
 #ifdef HAVE_DECODER_POWERPC
 	{
-		.id = LZMA_FILTER_POWERPC,
-		.init = &lzma_simple_powerpc_decoder_init,
-		.memusage = NULL,
-		.props_decode = &lzma_simple_props_decode,
+		LZMA_FILTER_POWERPC,
+		&lzma_simple_powerpc_decoder_init,
+		NULL,
+		&lzma_simple_props_decode
 	},
 #endif
 #ifdef HAVE_DECODER_IA64
 	{
-		.id = LZMA_FILTER_IA64,
-		.init = &lzma_simple_ia64_decoder_init,
-		.memusage = NULL,
-		.props_decode = &lzma_simple_props_decode,
+		LZMA_FILTER_IA64,
+		&lzma_simple_ia64_decoder_init,
+		NULL,
+		&lzma_simple_props_decode
 	},
 #endif
 #ifdef HAVE_DECODER_ARM
 	{
-		.id = LZMA_FILTER_ARM,
-		.init = &lzma_simple_arm_decoder_init,
-		.memusage = NULL,
-		.props_decode = &lzma_simple_props_decode,
+		LZMA_FILTER_ARM,
+		&lzma_simple_arm_decoder_init,
+		NULL,
+		&lzma_simple_props_decode
 	},
 #endif
 #ifdef HAVE_DECODER_ARMTHUMB
 	{
-		.id = LZMA_FILTER_ARMTHUMB,
-		.init = &lzma_simple_armthumb_decoder_init,
-		.memusage = NULL,
-		.props_decode = &lzma_simple_props_decode,
+		LZMA_FILTER_ARMTHUMB,
+		&lzma_simple_armthumb_decoder_init,
+		NULL,
+		&lzma_simple_props_decode
 	},
 #endif
 #ifdef HAVE_DECODER_SPARC
 	{
-		.id = LZMA_FILTER_SPARC,
-		.init = &lzma_simple_sparc_decoder_init,
-		.memusage = NULL,
-		.props_decode = &lzma_simple_props_decode,
+		LZMA_FILTER_SPARC,
+		&lzma_simple_sparc_decoder_init,
+		NULL,
+		&lzma_simple_props_decode
 	},
 #endif
 #ifdef HAVE_DECODER_DELTA
 	{
-		.id = LZMA_FILTER_DELTA,
-		.init = &lzma_delta_decoder_init,
-		.memusage = &lzma_delta_coder_memusage,
-		.props_decode = &lzma_delta_props_decode,
+		LZMA_FILTER_DELTA,
+		&lzma_delta_decoder_init,
+		&lzma_delta_coder_memusage,
+		&lzma_delta_props_decode
 	},
 #endif
 };
@@ -120,7 +120,9 @@
 static const lzma_filter_decoder *
 decoder_find(lzma_vli id)
 {
-	for (size_t i = 0; i < ARRAY_SIZE(decoders); ++i)
+	size_t i;
+	
+	for (i = 0; i < ARRAY_SIZE(decoders); ++i)
 		if (decoders[i].id == id)
 			return decoders + i;
 
@@ -168,10 +170,12 @@
 lzma_properties_decode(lzma_filter *filter, lzma_allocator *allocator,
 		const uint8_t *props, size_t props_size)
 {
+	lzma_filter_decoder *fd;
+	
 	// Make it always NULL so that the caller can always safely free() it.
 	filter->options = NULL;
 
-	const lzma_filter_decoder *const fd = decoder_find(filter->id);
+	fd = decoder_find(filter->id);
 	if (fd == NULL)
 		return LZMA_OPTIONS_ERROR;
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/filter_encoder.c src/liblzma/common/filter_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/filter_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/filter_encoder.c	2014-05-03 16:25:18.950386000 +0200
@@ -56,95 +56,101 @@
 static const lzma_filter_encoder encoders[] = {
 #ifdef HAVE_ENCODER_LZMA1
 	{
-		.id = LZMA_FILTER_LZMA1,
-		.init = &lzma_lzma_encoder_init,
-		.memusage = &lzma_lzma_encoder_memusage,
-		.chunk_size = NULL, // FIXME
-		.props_size_get = NULL,
-		.props_size_fixed = 5,
-		.props_encode = &lzma_lzma_props_encode,
+		LZMA_FILTER_LZMA1,
+		&lzma_lzma_encoder_init,
+		&lzma_lzma_encoder_memusage,
+		NULL, // FIXME
+		NULL,
+		5,
+		&lzma_lzma_props_encode
 	},
 #endif
 #ifdef HAVE_ENCODER_LZMA2
 	{
-		.id = LZMA_FILTER_LZMA2,
-		.init = &lzma_lzma2_encoder_init,
-		.memusage = &lzma_lzma2_encoder_memusage,
-		.chunk_size = NULL, // FIXME
-		.props_size_get = NULL,
-		.props_size_fixed = 1,
-		.props_encode = &lzma_lzma2_props_encode,
+		LZMA_FILTER_LZMA2,
+		&lzma_lzma2_encoder_init,
+		&lzma_lzma2_encoder_memusage,
+		NULL, // FIXME
+		NULL,
+		1,
+		&lzma_lzma2_props_encode
 	},
 #endif
 #ifdef HAVE_ENCODER_X86
 	{
-		.id = LZMA_FILTER_X86,
-		.init = &lzma_simple_x86_encoder_init,
-		.memusage = NULL,
-		.chunk_size = NULL,
-		.props_size_get = &lzma_simple_props_size,
-		.props_encode = &lzma_simple_props_encode,
+		LZMA_FILTER_X86,
+		&lzma_simple_x86_encoder_init,
+		NULL,
+		NULL,
+		&lzma_simple_props_size,
+		0,
+		&lzma_simple_props_encode
 	},
 #endif
 #ifdef HAVE_ENCODER_POWERPC
 	{
-		.id = LZMA_FILTER_POWERPC,
-		.init = &lzma_simple_powerpc_encoder_init,
-		.memusage = NULL,
-		.chunk_size = NULL,
-		.props_size_get = &lzma_simple_props_size,
-		.props_encode = &lzma_simple_props_encode,
+		LZMA_FILTER_POWERPC,
+		&lzma_simple_powerpc_encoder_init,
+		NULL,
+		NULL,
+		&lzma_simple_props_size,
+		0,
+		&lzma_simple_props_encode
 	},
 #endif
 #ifdef HAVE_ENCODER_IA64
 	{
-		.id = LZMA_FILTER_IA64,
-		.init = &lzma_simple_ia64_encoder_init,
-		.memusage = NULL,
-		.chunk_size = NULL,
-		.props_size_get = &lzma_simple_props_size,
-		.props_encode = &lzma_simple_props_encode,
+		LZMA_FILTER_IA64,
+		&lzma_simple_ia64_encoder_init,
+		NULL,
+		NULL,
+		&lzma_simple_props_size,
+		0,
+		&lzma_simple_props_encode
 	},
 #endif
 #ifdef HAVE_ENCODER_ARM
 	{
-		.id = LZMA_FILTER_ARM,
-		.init = &lzma_simple_arm_encoder_init,
-		.memusage = NULL,
-		.chunk_size = NULL,
-		.props_size_get = &lzma_simple_props_size,
-		.props_encode = &lzma_simple_props_encode,
+		LZMA_FILTER_ARM,
+		&lzma_simple_arm_encoder_init,
+		NULL,
+		NULL,
+		&lzma_simple_props_size,
+		0,
+		&lzma_simple_props_encode
 	},
 #endif
 #ifdef HAVE_ENCODER_ARMTHUMB
 	{
-		.id = LZMA_FILTER_ARMTHUMB,
-		.init = &lzma_simple_armthumb_encoder_init,
-		.memusage = NULL,
-		.chunk_size = NULL,
-		.props_size_get = &lzma_simple_props_size,
-		.props_encode = &lzma_simple_props_encode,
+		LZMA_FILTER_ARMTHUMB,
+		&lzma_simple_armthumb_encoder_init,
+		NULL,
+		NULL,
+		&lzma_simple_props_size,
+		0,
+		&lzma_simple_props_encode
 	},
 #endif
 #ifdef HAVE_ENCODER_SPARC
 	{
-		.id = LZMA_FILTER_SPARC,
-		.init = &lzma_simple_sparc_encoder_init,
-		.memusage = NULL,
-		.chunk_size = NULL,
-		.props_size_get = &lzma_simple_props_size,
-		.props_encode = &lzma_simple_props_encode,
+		LZMA_FILTER_SPARC,
+		&lzma_simple_sparc_encoder_init,
+		NULL,
+		NULL,
+		&lzma_simple_props_size,
+		0,
+		&lzma_simple_props_encode
 	},
 #endif
 #ifdef HAVE_ENCODER_DELTA
 	{
-		.id = LZMA_FILTER_DELTA,
-		.init = &lzma_delta_encoder_init,
-		.memusage = &lzma_delta_coder_memusage,
-		.chunk_size = NULL,
-		.props_size_get = NULL,
-		.props_size_fixed = 1,
-		.props_encode = &lzma_delta_props_encode,
+		LZMA_FILTER_DELTA,
+		&lzma_delta_encoder_init,
+		&lzma_delta_coder_memusage,
+		NULL,
+		NULL,
+		1,
+		&lzma_delta_props_encode
 	},
 #endif
 };
@@ -153,7 +159,9 @@
 static const lzma_filter_encoder *
 encoder_find(lzma_vli id)
 {
-	for (size_t i = 0; i < ARRAY_SIZE(encoders); ++i)
+	size_t i;
+	
+	for (i = 0; i < ARRAY_SIZE(encoders); ++i)
 		if (encoders[i].id == id)
 			return encoders + i;
 
@@ -171,6 +179,10 @@
 extern LZMA_API(lzma_ret)
 lzma_filters_update(lzma_stream *strm, const lzma_filter *filters)
 {
+	size_t count;
+	size_t i;
+	lzma_filter reversed_filters[LZMA_FILTERS_MAX + 1];
+
 	if (strm->internal->next.update == NULL)
 		return LZMA_PROG_ERROR;
 
@@ -180,12 +192,11 @@
 
 	// The actual filter chain in the encoder is reversed. Some things
 	// still want the normal order chain, so we provide both.
-	size_t count = 1;
+	count = 1;
 	while (filters[count].id != LZMA_VLI_UNKNOWN)
 		++count;
 
-	lzma_filter reversed_filters[LZMA_FILTERS_MAX + 1];
-	for (size_t i = 0; i < count; ++i)
+	for (i = 0; i < count; ++i)
 		reversed_filters[count - i - 1] = filters[i];
 
 	reversed_filters[count].id = LZMA_VLI_UNKNOWN;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/filter_flags_decoder.c src/liblzma/common/filter_flags_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/filter_flags_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/filter_flags_decoder.c	2013-12-01 17:31:01.500762600 +0100
@@ -18,6 +18,9 @@
 		lzma_filter *filter, lzma_allocator *allocator,
 		const uint8_t *in, size_t *in_pos, size_t in_size)
 {
+	lzma_vli props_size;
+	lzma_ret ret;
+
 	// Set the pointer to NULL so the caller can always safely free it.
 	filter->options = NULL;
 
@@ -29,7 +32,6 @@
 		return LZMA_DATA_ERROR;
 
 	// Size of Properties
-	lzma_vli props_size;
 	return_if_error(lzma_vli_decode(&props_size, NULL,
 			in, in_pos, in_size));
 
@@ -37,7 +39,7 @@
 	if (in_size - *in_pos < props_size)
 		return LZMA_DATA_ERROR;
 
-	const lzma_ret ret = lzma_properties_decode(
+	ret = lzma_properties_decode(
 			filter, allocator, in + *in_pos, props_size);
 
 	*in_pos += props_size;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/filter_flags_encoder.c src/liblzma/common/filter_flags_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/filter_flags_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/filter_flags_encoder.c	2014-05-03 16:25:51.342651400 +0200
@@ -31,6 +31,7 @@
 lzma_filter_flags_encode(const lzma_filter *filter,
 		uint8_t *out, size_t *out_pos, size_t out_size)
 {
+	uint32_t props_size;
 	// Filter ID
 	if (filter->id >= LZMA_FILTER_RESERVED_START)
 		return LZMA_PROG_ERROR;
@@ -39,7 +40,6 @@
 			out, out_pos, out_size));
 
 	// Size of Properties
-	uint32_t props_size;
 	return_if_error(lzma_properties_size(&props_size, filter));
 	return_if_error(lzma_vli_encode(props_size, NULL,
 			out, out_pos, out_size));
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/index.c src/liblzma/common/index.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/index.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/index.c	2014-05-04 09:18:47.995841500 +0200
@@ -25,7 +25,7 @@
 #define PREALLOC_MAX ((SIZE_MAX - sizeof(index_group)) / sizeof(index_record))
 
 
-/// \brief      Base structure for index_stream and index_group structures
+/// \brief      Base structure for struct index_stream_s and index_group structures
 typedef struct index_tree_node_s index_tree_node;
 struct index_tree_node_s {
 	/// Uncompressed start offset of this Stream (relative to the
@@ -42,7 +42,7 @@
 };
 
 
-/// \brief      AVL tree to hold index_stream or index_group structures
+/// \brief      AVL tree to hold struct index_stream_s or index_group structures
 typedef struct {
 	/// Root node
 	index_tree_node *root;
@@ -69,7 +69,7 @@
 
 
 typedef struct {
-	/// Every Record group is part of index_stream.groups tree.
+	/// Every Record group is part of struct index_stream_s.groups tree.
 	index_tree_node node;
 
 	/// Number of Blocks in this Stream before this group.
@@ -104,8 +104,8 @@
 } index_group;
 
 
-typedef struct {
-	/// Every index_stream is a node in the tree of Sreams.
+struct index_stream_s {
+	/// Every struct index_stream_s is a node in the tree of Sreams.
 	index_tree_node node;
 
 	/// Number of this Stream (first one is 1)
@@ -139,7 +139,7 @@
 	/// zero and can be set with lzma_index_stream_padding().
 	lzma_vli stream_padding;
 
-} index_stream;
+};
 
 
 struct lzma_index_s {
@@ -212,8 +212,8 @@
 
 /// Free the meory allocated for a tree. If free_func is not NULL,
 /// it is called on each node before freeing the node. This is used
-/// to free the Record groups from each index_stream before freeing
-/// the index_stream itself.
+/// to free the Record groups from each struct index_stream_s before freeing
+/// the struct index_stream_s itself.
 static void
 index_tree_end(index_tree *tree, lzma_allocator *allocator,
 		void (*free_func)(void *node, lzma_allocator *allocator))
@@ -230,6 +230,8 @@
 static void
 index_tree_append(index_tree *tree, index_tree_node *node)
 {
+	uint32_t up;
+	
 	node->parent = tree->rightmost;
 	node->left = NULL;
 	node->right = NULL;
@@ -258,8 +260,10 @@
 	// and thus know the state of the tree just by looking at the node
 	// count. From the node count we can calculate how many steps to go
 	// up in the tree to find the rotation root.
-	uint32_t up = tree->count ^ (UINT32_C(1) << bsr32(tree->count));
+	up = tree->count ^ (UINT32_C(1) << bsr32(tree->count));
 	if (up != 0) {
+		index_tree_node *pivot;
+		
 		// Locate the root node for the rotation.
 		up = ctz32(tree->count) + 2;
 		do {
@@ -267,7 +271,7 @@
 		} while (--up > 0);
 
 		// Rotate left using node as the rotation root.
-		index_tree_node *pivot = node->right;
+		pivot = node->right;
 
 		if (node->parent == NULL) {
 			tree->root = pivot;
@@ -337,12 +341,12 @@
 
 
 /// Allocate and initialize a new Stream using the given base offsets.
-static index_stream *
+static struct index_stream_s *
 index_stream_init(lzma_vli compressed_base, lzma_vli uncompressed_base,
 		lzma_vli stream_number, lzma_vli block_number_base,
 		lzma_allocator *allocator)
 {
-	index_stream *s = lzma_alloc(sizeof(index_stream), allocator);
+	struct index_stream_s *s = lzma_alloc(sizeof(struct index_stream_s), allocator);
 	if (s == NULL)
 		return NULL;
 
@@ -370,7 +374,7 @@
 static void
 index_stream_end(void *node, lzma_allocator *allocator)
 {
-	index_stream *s = node;
+	struct index_stream_s *s = node;
 	index_tree_end(&s->groups, allocator, NULL);
 	return;
 }
@@ -397,11 +401,12 @@
 extern LZMA_API(lzma_index *)
 lzma_index_init(lzma_allocator *allocator)
 {
+	struct index_stream_s *s;
 	lzma_index *i = index_init_plain(allocator);
 	if (i == NULL)
 		return NULL;
 
-	index_stream *s = index_stream_init(0, 0, 1, 0, allocator);
+	s = index_stream_init(0, 0, 1, 0, allocator);
 	if (s == NULL) {
 		lzma_free(i, allocator);
 		return NULL;
@@ -453,7 +458,7 @@
 	// Amount of memory needed for each Stream base structures.
 	// We assume that every Stream has at least one Block and
 	// thus at least one group.
-	const size_t stream_base = sizeof(index_stream)
+	const size_t stream_base = sizeof(struct index_stream_s)
 			+ sizeof(index_group) + 2 * alloc_overhead;
 
 	// Amount of memory needed per group.
@@ -466,7 +471,7 @@
 	const lzma_vli groups
 			= (blocks + INDEX_GROUP_SIZE - 1) / INDEX_GROUP_SIZE;
 
-	// Memory used by index_stream and index_group structures.
+	// Memory used by struct index_stream_s and index_group structures.
 	const uint64_t streams_mem = streams * stream_base;
 	const uint64_t groups_mem = groups * group_base;
 
@@ -559,7 +564,7 @@
 extern LZMA_API(lzma_vli)
 lzma_index_file_size(const lzma_index *i)
 {
-	const index_stream *s = (const index_stream *)(i->streams.rightmost);
+	const struct index_stream_s *s = (const struct index_stream_s *)(i->streams.rightmost);
 	const index_group *g = (const index_group *)(s->groups.rightmost);
 	return index_file_size(s->node.compressed_base,
 			g == NULL ? 0 : g->records[g->last].unpadded_sum,
@@ -581,7 +586,7 @@
 	uint32_t checks = i->checks;
 
 	// Get the type of the Check of the last Stream too.
-	const index_stream *s = (const index_stream *)(i->streams.rightmost);
+	const struct index_stream_s *s = (const struct index_stream_s *)(i->streams.rightmost);
 	if (s->stream_flags.version != UINT32_MAX)
 		checks |= UINT32_C(1) << s->stream_flags.check;
 
@@ -600,6 +605,8 @@
 extern LZMA_API(lzma_ret)
 lzma_index_stream_flags(lzma_index *i, const lzma_stream_flags *stream_flags)
 {
+	struct index_stream_s *s;
+	
 	if (i == NULL || stream_flags == NULL)
 		return LZMA_PROG_ERROR;
 
@@ -607,7 +614,7 @@
 	return_if_error(lzma_stream_flags_compare(
 			stream_flags, stream_flags));
 
-	index_stream *s = (index_stream *)(i->streams.rightmost);
+	s = (struct index_stream_s *)(i->streams.rightmost);
 	s->stream_flags = *stream_flags;
 
 	return LZMA_OK;
@@ -617,14 +624,17 @@
 extern LZMA_API(lzma_ret)
 lzma_index_stream_padding(lzma_index *i, lzma_vli stream_padding)
 {
+	struct index_stream_s *s;
+	lzma_vli old_stream_padding;
+	
 	if (i == NULL || stream_padding > LZMA_VLI_MAX
 			|| (stream_padding & 3) != 0)
 		return LZMA_PROG_ERROR;
 
-	index_stream *s = (index_stream *)(i->streams.rightmost);
+	s = (struct index_stream_s *)(i->streams.rightmost);
 
 	// Check that the new value won't make the file grow too big.
-	const lzma_vli old_stream_padding = s->stream_padding;
+	old_stream_padding = s->stream_padding;
 	s->stream_padding = 0;
 	if (lzma_index_file_size(i) + stream_padding > LZMA_VLI_MAX) {
 		s->stream_padding = old_stream_padding;
@@ -640,20 +650,26 @@
 lzma_index_append(lzma_index *i, lzma_allocator *allocator,
 		lzma_vli unpadded_size, lzma_vli uncompressed_size)
 {
+	struct index_stream_s *s;
+	index_group *g;
+	lzma_vli compressed_base;
+	lzma_vli uncompressed_base;
+	uint32_t index_list_size_add;
+
 	// Validate.
 	if (i == NULL || unpadded_size < UNPADDED_SIZE_MIN
 			|| unpadded_size > UNPADDED_SIZE_MAX
 			|| uncompressed_size > LZMA_VLI_MAX)
 		return LZMA_PROG_ERROR;
 
-	index_stream *s = (index_stream *)(i->streams.rightmost);
-	index_group *g = (index_group *)(s->groups.rightmost);
+	s = (struct index_stream_s *)(i->streams.rightmost);
+	g = (index_group *)(s->groups.rightmost);
 
-	const lzma_vli compressed_base = g == NULL ? 0
+	compressed_base = g == NULL ? 0
 			: vli_ceil4(g->records[g->last].unpadded_sum);
-	const lzma_vli uncompressed_base = g == NULL ? 0
+	uncompressed_base = g == NULL ? 0
 			: g->records[g->last].uncompressed_sum;
-	const uint32_t index_list_size_add = lzma_vli_size(unpadded_size)
+	index_list_size_add = lzma_vli_size(unpadded_size)
 			+ lzma_vli_size(uncompressed_size);
 
 	// Check that the file size will stay within limits.
@@ -742,10 +758,10 @@
 /// Simplest iterative traversal of the source tree wouldn't work, because
 /// we update the pointers in nodes when moving them to the destination tree.
 static void
-index_cat_helper(const index_cat_info *info, index_stream *this)
+index_cat_helper(const index_cat_info *info, struct index_stream_s *this)
 {
-	index_stream *left = (index_stream *)(this->node.left);
-	index_stream *right = (index_stream *)(this->node.right);
+	struct index_stream_s *left = (struct index_stream_s *)(this->node.left);
+	struct index_stream_s *right = (struct index_stream_s *)(this->node.right);
 
 	if (left != NULL)
 		index_cat_helper(info, left);
@@ -764,10 +780,11 @@
 
 
 extern LZMA_API(lzma_ret)
-lzma_index_cat(lzma_index *restrict dest, lzma_index *restrict src,
+lzma_index_cat(lzma_index * dest, lzma_index * src,
 		lzma_allocator *allocator)
 {
 	const lzma_vli dest_file_size = lzma_index_file_size(dest);
+	index_cat_info info;
 
 	// Check that we don't exceed the file size limits.
 	if (dest_file_size + lzma_index_file_size(src) > LZMA_VLI_MAX
@@ -793,13 +810,15 @@
 	// Optimize the last group to minimize memory usage. Allocation has
 	// to be done before modifying dest or src.
 	{
-		index_stream *s = (index_stream *)(dest->streams.rightmost);
+		struct index_stream_s *s = (struct index_stream_s *)(dest->streams.rightmost);
 		index_group *g = (index_group *)(s->groups.rightmost);
 		if (g != NULL && g->last + 1 < g->allocated) {
+			index_group *newg;
+			
 			assert(g->node.left == NULL);
 			assert(g->node.right == NULL);
 
-			index_group *newg = lzma_alloc(sizeof(index_group)
+			newg = lzma_alloc(sizeof(index_group)
 					+ (g->last + 1)
 					* sizeof(index_record),
 					allocator);
@@ -834,14 +853,14 @@
 
 	// Add all the Streams from src to dest. Update the base offsets
 	// of each Stream from src.
-	const index_cat_info info = {
-		.uncompressed_size = dest->uncompressed_size,
-		.file_size = dest_file_size,
-		.stream_number_add = dest->streams.count,
-		.block_number_add = dest->record_count,
-		.streams = &dest->streams,
-	};
-	index_cat_helper(&info, (index_stream *)(src->streams.root));
+	memset(&info, 0, sizeof(index_cat_info));
+	info.uncompressed_size = dest->uncompressed_size,
+	info.file_size = dest_file_size,
+	info.block_number_add = dest->record_count,
+	info.stream_number_add = dest->streams.count,
+	info.streams = &dest->streams,
+
+	index_cat_helper(&info, (struct index_stream_s *)(src->streams.root));
 
 	// Update info about all the combined Streams.
 	dest->uncompressed_size += src->uncompressed_size;
@@ -857,16 +876,21 @@
 }
 
 
-/// Duplicate an index_stream.
-static index_stream *
-index_dup_stream(const index_stream *src, lzma_allocator *allocator)
-{
+/// Duplicate an struct index_stream_s.
+static struct index_stream_s *
+index_dup_stream(const struct index_stream_s *src, lzma_allocator *allocator)
+{
+	struct index_stream_s *dest;
+	index_group *destg;
+	index_group *srcg;
+	size_t i = 0;
+
 	// Catch a somewhat theoretical integer overflow.
 	if (src->record_count > PREALLOC_MAX)
 		return NULL;
 
 	// Allocate and initialize a new Stream.
-	index_stream *dest = index_stream_init(src->node.compressed_base,
+	dest = index_stream_init(src->node.compressed_base,
 			src->node.uncompressed_base, src->number,
 			src->block_number_base, allocator);
 
@@ -884,7 +908,7 @@
 	// Allocate memory for the Records. We put all the Records into
 	// a single group. It's simplest and also tends to make
 	// lzma_index_locate() a little bit faster with very big Indexes.
-	index_group *destg = lzma_alloc(sizeof(index_group)
+	destg = lzma_alloc(sizeof(index_group)
 			+ src->record_count * sizeof(index_record),
 			allocator);
 	if (destg == NULL) {
@@ -900,8 +924,7 @@
 	destg->last = src->record_count - 1;
 
 	// Go through all the groups in src and copy the Records into destg.
-	const index_group *srcg = (const index_group *)(src->groups.leftmost);
-	size_t i = 0;
+	srcg = (index_group *)(src->groups.leftmost);
 	do {
 		memcpy(destg->records + i, srcg->records,
 				(srcg->last + 1) * sizeof(index_record));
@@ -921,6 +944,7 @@
 extern LZMA_API(lzma_index *)
 lzma_index_dup(const lzma_index *src, lzma_allocator *allocator)
 {
+	struct index_stream_s *srcstream;
 	// Allocate the base structure (no initial Stream).
 	lzma_index *dest = index_init_plain(allocator);
 	if (dest == NULL)
@@ -933,10 +957,9 @@
 	dest->index_list_size = src->index_list_size;
 
 	// Copy the Streams and the groups in them.
-	const index_stream *srcstream
-			= (const index_stream *)(src->streams.leftmost);
+	srcstream = (struct index_stream_s *)(src->streams.leftmost);
 	do {
-		index_stream *deststream = index_dup_stream(
+		struct index_stream_s *deststream = index_dup_stream(
 				srcstream, allocator);
 		if (deststream == NULL) {
 			lzma_index_end(dest, allocator);
@@ -974,7 +997,7 @@
 iter_set_info(lzma_index_iter *iter)
 {
 	const lzma_index *i = iter->internal[ITER_INDEX].p;
-	const index_stream *stream = iter->internal[ITER_STREAM].p;
+	const struct index_stream_s *stream = iter->internal[ITER_STREAM].p;
 	const index_group *group = iter->internal[ITER_GROUP].p;
 	const size_t record = iter->internal[ITER_RECORD].s;
 
@@ -1096,15 +1119,15 @@
 extern LZMA_API(lzma_bool)
 lzma_index_iter_next(lzma_index_iter *iter, lzma_index_iter_mode mode)
 {
-	// Catch unsupported mode values.
-	if ((unsigned int)(mode) > LZMA_INDEX_ITER_NONEMPTY_BLOCK)
-		return true;
-
 	const lzma_index *i = iter->internal[ITER_INDEX].p;
-	const index_stream *stream = iter->internal[ITER_STREAM].p;
+	const struct index_stream_s *stream = iter->internal[ITER_STREAM].p;
 	const index_group *group = NULL;
 	size_t record = iter->internal[ITER_RECORD].s;
 
+	// Catch unsupported mode values.
+	if ((unsigned int)(mode) > LZMA_INDEX_ITER_NONEMPTY_BLOCK)
+		return true;
+
 	// If we are being asked for the next Stream, leave group to NULL
 	// so that the rest of the this function thinks that this Stream
 	// has no groups and will thus go to the next Stream.
@@ -1131,7 +1154,7 @@
 	if (stream == NULL) {
 		// We at the beginning of the lzma_index.
 		// Locate the first Stream.
-		stream = (const index_stream *)(i->streams.leftmost);
+		stream = (const struct index_stream_s *)(i->streams.leftmost);
 		if (mode >= LZMA_INDEX_ITER_BLOCK) {
 			// Since we are being asked to return information
 			// about the first a Block, skip Streams that have
@@ -1203,19 +1226,23 @@
 extern LZMA_API(lzma_bool)
 lzma_index_iter_locate(lzma_index_iter *iter, lzma_vli target)
 {
+	struct index_stream_s *stream;
 	const lzma_index *i = iter->internal[ITER_INDEX].p;
+	index_group *group;
+	size_t left;
+	size_t right;
 
 	// If the target is past the end of the file, return immediately.
 	if (i->uncompressed_size <= target)
 		return true;
 
 	// Locate the Stream containing the target offset.
-	const index_stream *stream = index_tree_locate(&i->streams, target);
+	stream = index_tree_locate(&i->streams, target);
 	assert(stream != NULL);
 	target -= stream->node.uncompressed_base;
 
 	// Locate the group containing the target offset.
-	const index_group *group = index_tree_locate(&stream->groups, target);
+	group = index_tree_locate(&stream->groups, target);
 	assert(group != NULL);
 
 	// Use binary search to locate the exact Record. It is the first
@@ -1223,8 +1250,8 @@
 	// This is because we want the rightmost Record that fullfills the
 	// search criterion. It is possible that there are empty Blocks;
 	// we don't want to return them.
-	size_t left = 0;
-	size_t right = group->last;
+	left = 0;
+	right = group->last;
 
 	while (left < right) {
 		const size_t pos = left + (right - left) / 2;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/index.h src/liblzma/common/index.h
--- ..\..\Library\xz-5.0.5\src/liblzma/common/index.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/index.h	2013-12-01 14:59:20.064580100 +0100
@@ -35,7 +35,7 @@
 
 
 /// Round the variable-length integer to the next multiple of four.
-static inline lzma_vli
+static __inline lzma_vli
 vli_ceil4(lzma_vli vli)
 {
 	assert(vli <= LZMA_VLI_MAX);
@@ -44,7 +44,7 @@
 
 
 /// Calculate the size of the Index field excluding Index Padding
-static inline lzma_vli
+static __inline lzma_vli
 index_size_unpadded(lzma_vli count, lzma_vli index_list_size)
 {
 	// Index Indicator + Number of Records + List of Records + CRC32
@@ -53,7 +53,7 @@
 
 
 /// Calculate the size of the Index field including Index Padding
-static inline lzma_vli
+static __inline lzma_vli
 index_size(lzma_vli count, lzma_vli index_list_size)
 {
 	return vli_ceil4(index_size_unpadded(count, index_list_size));
@@ -61,7 +61,7 @@
 
 
 /// Calculate the total size of the Stream
-static inline lzma_vli
+static __inline lzma_vli
 index_stream_size(lzma_vli blocks_size,
 		lzma_vli count, lzma_vli index_list_size)
 {
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/index_decoder.c src/liblzma/common/index_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/index_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/index_decoder.c	2014-05-03 16:37:04.626677100 +0200
@@ -54,11 +54,11 @@
 
 
 static lzma_ret
-index_decode(lzma_coder *coder, lzma_allocator *allocator,
-		const uint8_t *restrict in, size_t *restrict in_pos,
+index_decode(struct lzma_coder_s *coder, lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
 		size_t in_size,
-		uint8_t *restrict out lzma_attribute((__unused__)),
-		size_t *restrict out_pos lzma_attribute((__unused__)),
+		uint8_t * out lzma_attribute((__unused__)),
+		size_t * out_pos lzma_attribute((__unused__)),
 		size_t out_size lzma_attribute((__unused__)),
 		lzma_action action lzma_attribute((__unused__)))
 {
@@ -207,7 +207,7 @@
 
 
 static void
-index_decoder_end(lzma_coder *coder, lzma_allocator *allocator)
+index_decoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_index_end(coder->index, allocator);
 	lzma_free(coder, allocator);
@@ -216,7 +216,7 @@
 
 
 static lzma_ret
-index_decoder_memconfig(lzma_coder *coder, uint64_t *memusage,
+index_decoder_memconfig(struct lzma_coder_s *coder, uint64_t *memusage,
 		uint64_t *old_memlimit, uint64_t new_memlimit)
 {
 	*memusage = lzma_index_memusage(1, coder->count);
@@ -234,7 +234,7 @@
 
 
 static lzma_ret
-index_decoder_reset(lzma_coder *coder, lzma_allocator *allocator,
+index_decoder_reset(struct lzma_coder_s *coder, lzma_allocator *allocator,
 		lzma_index **i, uint64_t memlimit)
 {
 	// Remember the pointer given by the application. We will set it
@@ -270,7 +270,7 @@
 		return LZMA_PROG_ERROR;
 
 	if (next->coder == NULL) {
-		next->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
 
@@ -303,21 +303,24 @@
 		lzma_index **i, uint64_t *memlimit, lzma_allocator *allocator,
 		const uint8_t *in, size_t *in_pos, size_t in_size)
 {
+	struct lzma_coder_s coder;
+	size_t in_start;
+	lzma_ret ret;
+	
 	// Sanity checks
 	if (i == NULL || memlimit == NULL
 			|| in == NULL || in_pos == NULL || *in_pos > in_size)
 		return LZMA_PROG_ERROR;
 
 	// Initialize the decoder.
-	lzma_coder coder;
 	return_if_error(index_decoder_reset(&coder, allocator, i, *memlimit));
 
 	// Store the input start position so that we can restore it in case
 	// of an error.
-	const size_t in_start = *in_pos;
+	in_start = *in_pos;
 
 	// Do the actual decoding.
-	lzma_ret ret = index_decode(&coder, allocator, in, in_pos, in_size,
+	ret = index_decode(&coder, allocator, in, in_pos, in_size,
 			NULL, NULL, 0, LZMA_RUN);
 
 	if (ret == LZMA_STREAM_END) {
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/index_encoder.c src/liblzma/common/index_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/index_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/index_encoder.c	2014-05-03 16:38:04.504719100 +0200
@@ -41,12 +41,12 @@
 
 
 static lzma_ret
-index_encode(lzma_coder *coder,
+index_encode(struct lzma_coder_s *coder,
 		lzma_allocator *allocator lzma_attribute((__unused__)),
-		const uint8_t *restrict in lzma_attribute((__unused__)),
-		size_t *restrict in_pos lzma_attribute((__unused__)),
+		const uint8_t * in lzma_attribute((__unused__)),
+		size_t * in_pos lzma_attribute((__unused__)),
 		size_t in_size lzma_attribute((__unused__)),
-		uint8_t *restrict out, size_t *restrict out_pos,
+		uint8_t * out, size_t * out_pos,
 		size_t out_size,
 		lzma_action action lzma_attribute((__unused__)))
 {
@@ -159,7 +159,7 @@
 
 
 static void
-index_encoder_end(lzma_coder *coder, lzma_allocator *allocator)
+index_encoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_free(coder, allocator);
 	return;
@@ -167,7 +167,7 @@
 
 
 static void
-index_encoder_reset(lzma_coder *coder, const lzma_index *i)
+index_encoder_reset(struct lzma_coder_s *coder, const lzma_index *i)
 {
 	lzma_index_iter_init(&coder->iter, i);
 
@@ -190,7 +190,7 @@
 		return LZMA_PROG_ERROR;
 
 	if (next->coder == NULL) {
-		next->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
 
@@ -220,6 +220,10 @@
 lzma_index_buffer_encode(const lzma_index *i,
 		uint8_t *out, size_t *out_pos, size_t out_size)
 {
+	struct lzma_coder_s coder;
+	size_t out_start;
+	lzma_ret ret;
+	
 	// Validate the arguments.
 	if (i == NULL || out == NULL || out_pos == NULL || *out_pos > out_size)
 		return LZMA_PROG_ERROR;
@@ -230,13 +234,12 @@
 
 	// The Index encoder needs just one small data structure so we can
 	// allocate it on stack.
-	lzma_coder coder;
 	index_encoder_reset(&coder, i);
 
 	// Do the actual encoding. This should never fail, but store
 	// the original *out_pos just in case.
-	const size_t out_start = *out_pos;
-	lzma_ret ret = index_encode(&coder, NULL, NULL, NULL, 0,
+	out_start = *out_pos;
+	ret = index_encode(&coder, NULL, NULL, NULL, 0,
 			out, out_pos, out_size, LZMA_RUN);
 
 	if (ret == LZMA_STREAM_END) {
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/index_hash.c src/liblzma/common/index_hash.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/index_hash.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/index_hash.c	2014-05-03 16:39:33.618579400 +0200
@@ -124,13 +124,14 @@
 hash_append(lzma_index_hash_info *info, lzma_vli unpadded_size,
 		lzma_vli uncompressed_size)
 {
+	const lzma_vli sizes[2] = { unpadded_size, uncompressed_size };
+	
 	info->blocks_size += vli_ceil4(unpadded_size);
 	info->uncompressed_size += uncompressed_size;
 	info->index_list_size += lzma_vli_size(unpadded_size)
 			+ lzma_vli_size(uncompressed_size);
 	++info->count;
 
-	const lzma_vli sizes[2] = { unpadded_size, uncompressed_size };
 	lzma_check_update(&info->check, LZMA_CHECK_BEST,
 			(const uint8_t *)(sizes), sizeof(sizes));
 
@@ -173,6 +174,9 @@
 lzma_index_hash_decode(lzma_index_hash *index_hash, const uint8_t *in,
 		size_t *in_pos, size_t in_size)
 {
+	size_t in_start;
+	lzma_ret ret = LZMA_OK;
+
 	// Catch zero input buffer here, because in contrast to Index encoder
 	// and decoder functions, applications call this function directly
 	// instead of via lzma_code(), which does the buffer checking.
@@ -182,8 +186,7 @@
 	// NOTE: This function has many similarities to index_encode() and
 	// index_decode() functions found from index_encoder.c and
 	// index_decoder.c. See the comments especially in index_encoder.c.
-	const size_t in_start = *in_pos;
-	lzma_ret ret = LZMA_OK;
+	in_start = *in_pos;
 
 	while (*in_pos < in_size)
 	switch (index_hash->sequence) {
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/stream_buffer_decoder.c src/liblzma/common/stream_buffer_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/stream_buffer_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/stream_buffer_decoder.c	2014-05-03 16:40:40.450084100 +0200
@@ -19,6 +19,9 @@
 		const uint8_t *in, size_t *in_pos, size_t in_size,
 		uint8_t *out, size_t *out_pos, size_t out_size)
 {
+	lzma_next_coder stream_decoder = LZMA_NEXT_CODER_INIT;
+	lzma_ret ret;
+	
 	// Sanity checks
 	if (in_pos == NULL || (in == NULL && *in_pos != in_size)
 			|| *in_pos > in_size || out_pos == NULL
@@ -33,8 +36,7 @@
 	// Initialize the Stream decoder.
 	// TODO: We need something to tell the decoder that it can use the
 	// output buffer as workspace, and thus save significant amount of RAM.
-	lzma_next_coder stream_decoder = LZMA_NEXT_CODER_INIT;
-	lzma_ret ret = lzma_stream_decoder_init(
+	ret = lzma_stream_decoder_init(
 			&stream_decoder, allocator, *memlimit, flags);
 
 	if (ret == LZMA_OK) {
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/stream_buffer_encoder.c src/liblzma/common/stream_buffer_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/stream_buffer_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/stream_buffer_encoder.c	2014-05-03 16:45:07.651103200 +0200
@@ -45,6 +45,10 @@
 		lzma_allocator *allocator, const uint8_t *in, size_t in_size,
 		uint8_t *out, size_t *out_pos_ptr, size_t out_size)
 {
+	size_t out_pos;
+	lzma_stream_flags stream_flags;
+	lzma_block block;
+	
 	// Sanity checks
 	if (filters == NULL || (unsigned int)(check) > LZMA_CHECK_ID_MAX
 			|| (in == NULL && in_size != 0) || out == NULL
@@ -61,7 +65,7 @@
 
 	// Use a local copy. We update *out_pos_ptr only if everything
 	// succeeds.
-	size_t out_pos = *out_pos_ptr;
+	out_pos = *out_pos_ptr;
 
 	// Check that there's enough space for both Stream Header and
 	// Stream Footer.
@@ -73,10 +77,9 @@
 	out_size -= LZMA_STREAM_HEADER_SIZE;
 
 	// Encode the Stream Header.
-	lzma_stream_flags stream_flags = {
-		.version = 0,
-		.check = check,
-	};
+	memset(&stream_flags, 0, sizeof(lzma_stream_flags));
+	stream_flags.version = 0;
+	stream_flags.check = check;
 
 	if (lzma_stream_header_encode(&stream_flags, out + out_pos)
 			!= LZMA_OK)
@@ -85,11 +88,10 @@
 	out_pos += LZMA_STREAM_HEADER_SIZE;
 
 	// Encode a Block but only if there is at least one byte of input.
-	lzma_block block = {
-		.version = 0,
-		.check = check,
-		.filters = filters,
-	};
+	memset(&block, 0, sizeof(lzma_block));
+	block.version = 0;
+	block.check = check;
+	block.filters = filters;
 
 	if (in_size > 0)
 		return_if_error(lzma_block_buffer_encode(&block, allocator,
@@ -101,11 +103,11 @@
 		// at least one byte of input to encode. Otherwise the
 		// Index will be empty.
 		lzma_index *i = lzma_index_init(allocator);
+		lzma_ret ret = LZMA_OK;
+
 		if (i == NULL)
 			return LZMA_MEM_ERROR;
 
-		lzma_ret ret = LZMA_OK;
-
 		if (in_size > 0)
 			ret = lzma_index_append(i, allocator,
 					lzma_block_unpadded_size(&block),
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/stream_decoder.c src/liblzma/common/stream_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/stream_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/stream_decoder.c	2014-05-03 16:48:40.661852500 +0200
@@ -80,7 +80,7 @@
 
 
 static lzma_ret
-stream_decoder_reset(lzma_coder *coder, lzma_allocator *allocator)
+stream_decoder_reset(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	// Initialize the Index hash used to verify the Index.
 	coder->index_hash = lzma_index_hash_init(coder->index_hash, allocator);
@@ -96,16 +96,18 @@
 
 
 static lzma_ret
-stream_decode(lzma_coder *coder, lzma_allocator *allocator,
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size, lzma_action action)
+stream_decode(struct lzma_coder_s *coder, lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size, lzma_action action)
 {
 	// When decoding the actual Block, it may be able to produce more
 	// output even if we don't give it any new input.
 	while (true)
 	switch (coder->sequence) {
 	case SEQ_STREAM_HEADER: {
+		lzma_ret ret;
+		
 		// Copy the Stream Header to the internal buffer.
 		lzma_bufcpy(in, in_pos, in_size, coder->buffer, &coder->pos,
 				LZMA_STREAM_HEADER_SIZE);
@@ -117,7 +119,7 @@
 		coder->pos = 0;
 
 		// Decode the Stream Header.
-		const lzma_ret ret = lzma_stream_header_decode(
+		ret = lzma_stream_header_decode(
 				&coder->stream_flags, coder->buffer);
 		if (ret != LZMA_OK)
 			return ret == LZMA_FORMAT_ERROR && !coder->first_stream
@@ -154,6 +156,11 @@
 	// Fall through
 
 	case SEQ_BLOCK_HEADER: {
+		lzma_filter filters[LZMA_FILTERS_MAX + 1];
+		uint64_t memusage;
+		lzma_ret ret;
+		size_t i;
+		
 		if (*in_pos >= in_size)
 			return LZMA_OK;
 
@@ -188,7 +195,6 @@
 		// Set up a buffer to hold the filter chain. Block Header
 		// decoder will initialize all members of this array so
 		// we don't need to do it here.
-		lzma_filter filters[LZMA_FILTERS_MAX + 1];
 		coder->block_options.filters = filters;
 
 		// Decode the Block Header.
@@ -196,8 +202,7 @@
 				allocator, coder->buffer));
 
 		// Check the memory usage limit.
-		const uint64_t memusage = lzma_raw_decoder_memusage(filters);
-		lzma_ret ret;
+		memusage = lzma_raw_decoder_memusage(filters);
 
 		if (memusage == UINT64_MAX) {
 			// One or more unknown Filter IDs.
@@ -224,7 +229,7 @@
 
 		// Free the allocated filter options since they are needed
 		// only to initialize the Block decoder.
-		for (size_t i = 0; i < LZMA_FILTERS_MAX; ++i)
+		for (i = 0; i < LZMA_FILTERS_MAX; ++i)
 			lzma_free(filters[i].options, allocator);
 
 		coder->block_options.filters = NULL;
@@ -260,6 +265,8 @@
 	}
 
 	case SEQ_INDEX: {
+		lzma_ret ret;
+
 		// If we don't have any input, don't call
 		// lzma_index_hash_decode() since it would return
 		// LZMA_BUF_ERROR, which we must not do here.
@@ -268,7 +275,7 @@
 
 		// Decode the Index and compare it to the hash calculated
 		// from the sizes of the Blocks (if any).
-		const lzma_ret ret = lzma_index_hash_decode(coder->index_hash,
+		ret = lzma_index_hash_decode(coder->index_hash,
 				in, in_pos, in_size);
 		if (ret != LZMA_STREAM_END)
 			return ret;
@@ -279,6 +286,9 @@
 	// Fall through
 
 	case SEQ_STREAM_FOOTER: {
+		lzma_stream_flags footer_flags;
+		lzma_ret ret;
+		
 		// Copy the Stream Footer to the internal buffer.
 		lzma_bufcpy(in, in_pos, in_size, coder->buffer, &coder->pos,
 				LZMA_STREAM_HEADER_SIZE);
@@ -292,8 +302,7 @@
 		// Decode the Stream Footer. The decoder gives
 		// LZMA_FORMAT_ERROR if the magic bytes don't match,
 		// so convert that return code to LZMA_DATA_ERROR.
-		lzma_stream_flags footer_flags;
-		const lzma_ret ret = lzma_stream_footer_decode(
+		ret = lzma_stream_footer_decode(
 				&footer_flags, coder->buffer);
 		if (ret != LZMA_OK)
 			return ret == LZMA_FORMAT_ERROR
@@ -366,7 +375,7 @@
 
 
 static void
-stream_decoder_end(lzma_coder *coder, lzma_allocator *allocator)
+stream_decoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_next_end(&coder->block_decoder, allocator);
 	lzma_index_hash_end(coder->index_hash, allocator);
@@ -376,14 +385,14 @@
 
 
 static lzma_check
-stream_decoder_get_check(const lzma_coder *coder)
+stream_decoder_get_check(const struct lzma_coder_s *coder)
 {
 	return coder->stream_flags.check;
 }
 
 
 static lzma_ret
-stream_decoder_memconfig(lzma_coder *coder, uint64_t *memusage,
+stream_decoder_memconfig(struct lzma_coder_s *coder, uint64_t *memusage,
 		uint64_t *old_memlimit, uint64_t new_memlimit)
 {
 	*memusage = coder->memusage;
@@ -413,7 +422,9 @@
 		return LZMA_OPTIONS_ERROR;
 
 	if (next->coder == NULL) {
-		next->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
 
@@ -422,7 +433,7 @@
 		next->get_check = &stream_decoder_get_check;
 		next->memconfig = &stream_decoder_memconfig;
 
-		next->coder->block_decoder = LZMA_NEXT_CODER_INIT;
+		next->coder->block_decoder = v;
 		next->coder->index_hash = NULL;
 	}
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/stream_encoder.c src/liblzma/common/stream_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/stream_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/stream_encoder.c	2014-05-03 19:19:35.574103600 +0200
@@ -60,7 +60,7 @@
 
 
 static lzma_ret
-block_encoder_init(lzma_coder *coder, lzma_allocator *allocator)
+block_encoder_init(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	// Prepare the Block options. Even though Block encoder doesn't need
 	// compressed_size, uncompressed_size, and header_size to be
@@ -79,10 +79,10 @@
 
 
 static lzma_ret
-stream_encode(lzma_coder *coder, lzma_allocator *allocator,
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size, lzma_action action)
+stream_encode(struct lzma_coder_s *coder, lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size, lzma_action action)
 {
 	// Main loop
 	while (*out_pos < out_size)
@@ -147,6 +147,8 @@
 	}
 
 	case SEQ_BLOCK_ENCODE: {
+		lzma_vli unpadded_size;
+
 		static const lzma_action convert[4] = {
 			LZMA_RUN,
 			LZMA_SYNC_FLUSH,
@@ -162,7 +164,7 @@
 			return ret;
 
 		// Add a new Index Record.
-		const lzma_vli unpadded_size = lzma_block_unpadded_size(
+		unpadded_size = lzma_block_unpadded_size(
 				&coder->block_options);
 		assert(unpadded_size != 0);
 		return_if_error(lzma_index_append(coder->index, allocator,
@@ -174,21 +176,23 @@
 	}
 
 	case SEQ_INDEX_ENCODE: {
+		lzma_stream_flags stream_flags;
+		
 		// Call the Index encoder. It doesn't take any input, so
 		// those pointers can be NULL.
 		const lzma_ret ret = coder->index_encoder.code(
 				coder->index_encoder.coder, allocator,
 				NULL, NULL, 0,
 				out, out_pos, out_size, LZMA_RUN);
-		if (ret != LZMA_STREAM_END)
-			return ret;
 
 		// Encode the Stream Footer into coder->buffer.
-		const lzma_stream_flags stream_flags = {
-			.version = 0,
-			.backward_size = lzma_index_size(coder->index),
-			.check = coder->block_options.check,
-		};
+		memset(&stream_flags, 0, sizeof(lzma_stream_flags));
+		stream_flags.version = 0;
+		stream_flags.backward_size = lzma_index_size(coder->index);
+		stream_flags.check = coder->block_options.check;
+
+		if (ret != LZMA_STREAM_END)
+			return ret;
 
 		if (lzma_stream_footer_encode(&stream_flags, coder->buffer)
 				!= LZMA_OK)
@@ -209,13 +213,15 @@
 
 
 static void
-stream_encoder_end(lzma_coder *coder, lzma_allocator *allocator)
+stream_encoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
+	size_t i;
+	
 	lzma_next_end(&coder->block_encoder, allocator);
 	lzma_next_end(&coder->index_encoder, allocator);
 	lzma_index_end(coder->index, allocator);
 
-	for (size_t i = 0; coder->filters[i].id != LZMA_VLI_UNKNOWN; ++i)
+	for (i = 0; coder->filters[i].id != LZMA_VLI_UNKNOWN; ++i)
 		lzma_free(coder->filters[i].options, allocator);
 
 	lzma_free(coder, allocator);
@@ -224,18 +230,22 @@
 
 
 static lzma_ret
-stream_encoder_update(lzma_coder *coder, lzma_allocator *allocator,
+stream_encoder_update(struct lzma_coder_s *coder, lzma_allocator *allocator,
 		const lzma_filter *filters,
 		const lzma_filter *reversed_filters)
 {
+	size_t i;
+	
 	if (coder->sequence <= SEQ_BLOCK_INIT) {
+		lzma_ret ret;
+		
 		// There is no incomplete Block waiting to be finished,
 		// thus we can change the whole filter chain. Start by
 		// trying to initialize the Block encoder with the new
 		// chain. This way we detect if the chain is valid.
 		coder->block_encoder_is_initialized = false;
 		coder->block_options.filters = (lzma_filter *)(filters);
-		const lzma_ret ret = block_encoder_init(coder, allocator);
+		ret = block_encoder_init(coder, allocator);
 		coder->block_options.filters = coder->filters;
 		if (ret != LZMA_OK)
 			return ret;
@@ -255,7 +265,7 @@
 	}
 
 	// Free the copy of the old chain and make a copy of the new chain.
-	for (size_t i = 0; coder->filters[i].id != LZMA_VLI_UNKNOWN; ++i)
+	for (i = 0; coder->filters[i].id != LZMA_VLI_UNKNOWN; ++i)
 		lzma_free(coder->filters[i].options, allocator);
 
 	return lzma_filters_copy(filters, coder->filters, allocator);
@@ -272,7 +282,9 @@
 		return LZMA_PROG_ERROR;
 
 	if (next->coder == NULL) {
-		next->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
 
@@ -281,8 +293,8 @@
 		next->update = &stream_encoder_update;
 
 		next->coder->filters[0].id = LZMA_VLI_UNKNOWN;
-		next->coder->block_encoder = LZMA_NEXT_CODER_INIT;
-		next->coder->index_encoder = LZMA_NEXT_CODER_INIT;
+		next->coder->block_encoder = v;
+		next->coder->index_encoder = v;
 		next->coder->index = NULL;
 	}
 
@@ -298,13 +310,16 @@
 		return LZMA_MEM_ERROR;
 
 	// Encode the Stream Header
-	lzma_stream_flags stream_flags = {
-		.version = 0,
-		.check = check,
-	};
-	return_if_error(lzma_stream_header_encode(
-			&stream_flags, next->coder->buffer));
+	{
+		lzma_stream_flags stream_flags;
+		
+		memset(&stream_flags, 0, sizeof(lzma_stream_flags));
+		stream_flags.version = 0;
+		stream_flags.check = check;
 
+		return_if_error(lzma_stream_header_encode(
+			&stream_flags, next->coder->buffer));
+	}
 	next->coder->buffer_pos = 0;
 	next->coder->buffer_size = LZMA_STREAM_HEADER_SIZE;
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/stream_flags_common.h src/liblzma/common/stream_flags_common.h
--- ..\..\Library\xz-5.0.5\src/liblzma/common/stream_flags_common.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/stream_flags_common.h	2013-12-01 14:59:20.048936000 +0100
@@ -22,7 +22,7 @@
 extern const uint8_t lzma_footer_magic[2];
 
 
-static inline bool
+static __inline bool
 is_backward_size_valid(const lzma_stream_flags *options)
 {
 	return options->backward_size >= LZMA_BACKWARD_SIZE_MIN
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/stream_flags_decoder.c src/liblzma/common/stream_flags_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/stream_flags_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/stream_flags_decoder.c	2013-12-01 17:31:01.485135600 +0100
@@ -30,13 +30,15 @@
 extern LZMA_API(lzma_ret)
 lzma_stream_header_decode(lzma_stream_flags *options, const uint8_t *in)
 {
+	uint32_t crc;
+
 	// Magic
 	if (memcmp(in, lzma_header_magic, sizeof(lzma_header_magic)) != 0)
 		return LZMA_FORMAT_ERROR;
 
 	// Verify the CRC32 so we can distinguish between corrupt
 	// and unsupported files.
-	const uint32_t crc = lzma_crc32(in + sizeof(lzma_header_magic),
+	crc = lzma_crc32(in + sizeof(lzma_header_magic),
 			LZMA_STREAM_FLAGS_SIZE, 0);
 	if (crc != unaligned_read32le(in + sizeof(lzma_header_magic)
 			+ LZMA_STREAM_FLAGS_SIZE))
@@ -59,13 +61,15 @@
 extern LZMA_API(lzma_ret)
 lzma_stream_footer_decode(lzma_stream_flags *options, const uint8_t *in)
 {
+	uint32_t crc;
+
 	// Magic
 	if (memcmp(in + sizeof(uint32_t) * 2 + LZMA_STREAM_FLAGS_SIZE,
 			lzma_footer_magic, sizeof(lzma_footer_magic)) != 0)
 		return LZMA_FORMAT_ERROR;
 
 	// CRC32
-	const uint32_t crc = lzma_crc32(in + sizeof(uint32_t),
+	crc = lzma_crc32(in + sizeof(uint32_t),
 			sizeof(uint32_t) + LZMA_STREAM_FLAGS_SIZE, 0);
 	if (crc != unaligned_read32le(in))
 		return LZMA_DATA_ERROR;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/stream_flags_encoder.c src/liblzma/common/stream_flags_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/stream_flags_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/stream_flags_encoder.c	2013-12-01 17:31:01.516387200 +0100
@@ -29,6 +29,8 @@
 extern LZMA_API(lzma_ret)
 lzma_stream_header_encode(const lzma_stream_flags *options, uint8_t *out)
 {
+	uint32_t crc;
+
 	assert(sizeof(lzma_header_magic) + LZMA_STREAM_FLAGS_SIZE
 			+ 4 == LZMA_STREAM_HEADER_SIZE);
 
@@ -43,7 +45,7 @@
 		return LZMA_PROG_ERROR;
 
 	// CRC32 of the Stream Header
-	const uint32_t crc = lzma_crc32(out + sizeof(lzma_header_magic),
+	crc = lzma_crc32(out + sizeof(lzma_header_magic),
 			LZMA_STREAM_FLAGS_SIZE, 0);
 
 	unaligned_write32le(out + sizeof(lzma_header_magic)
@@ -56,6 +58,8 @@
 extern LZMA_API(lzma_ret)
 lzma_stream_footer_encode(const lzma_stream_flags *options, uint8_t *out)
 {
+	uint32_t crc;
+
 	assert(2 * 4 + LZMA_STREAM_FLAGS_SIZE + sizeof(lzma_footer_magic)
 			== LZMA_STREAM_HEADER_SIZE);
 
@@ -73,7 +77,7 @@
 		return LZMA_PROG_ERROR;
 
 	// CRC32
-	const uint32_t crc = lzma_crc32(
+	crc = lzma_crc32(
 			out + 4, 4 + LZMA_STREAM_FLAGS_SIZE, 0);
 
 	unaligned_write32le(out, crc);
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/vli_decoder.c src/liblzma/common/vli_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/vli_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/vli_decoder.c	2013-12-01 16:43:19.099744900 +0100
@@ -14,8 +14,8 @@
 
 
 extern LZMA_API(lzma_ret)
-lzma_vli_decode(lzma_vli *restrict vli, size_t *vli_pos,
-		const uint8_t *restrict in, size_t *restrict in_pos,
+lzma_vli_decode(lzma_vli * vli, size_t *vli_pos,
+		const uint8_t * in, size_t * in_pos,
 		size_t in_size)
 {
 	// If we haven't been given vli_pos, work in single-call mode.
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/vli_encoder.c src/liblzma/common/vli_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/vli_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/vli_encoder.c	2013-12-01 16:43:19.084138100 +0100
@@ -15,7 +15,7 @@
 
 extern LZMA_API(lzma_ret)
 lzma_vli_encode(lzma_vli vli, size_t *vli_pos,
-		uint8_t *restrict out, size_t *restrict out_pos,
+		uint8_t * out, size_t * out_pos,
 		size_t out_size)
 {
 	// If we haven't been given vli_pos, work in single-call mode.
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/common/vli_size.c src/liblzma/common/vli_size.c
--- ..\..\Library\xz-5.0.5\src/liblzma/common/vli_size.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/common/vli_size.c	2013-12-01 17:16:56.313055600 +0100
@@ -16,10 +16,12 @@
 extern LZMA_API(uint32_t)
 lzma_vli_size(lzma_vli vli)
 {
+	uint32_t i;
+
 	if (vli > LZMA_VLI_MAX)
 		return 0;
 
-	uint32_t i = 0;
+	i = 0;
 	do {
 		vli >>= 7;
 		++i;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/delta/delta_common.c src/liblzma/delta/delta_common.c
--- ..\..\Library\xz-5.0.5\src/liblzma/delta/delta_common.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/delta/delta_common.c	2014-05-03 17:03:51.348518600 +0200
@@ -15,7 +15,7 @@
 
 
 static void
-delta_coder_end(lzma_coder *coder, lzma_allocator *allocator)
+delta_coder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_next_end(&coder->next, allocator);
 	lzma_free(coder, allocator);
@@ -27,15 +27,19 @@
 lzma_delta_coder_init(lzma_next_coder *next, lzma_allocator *allocator,
 		const lzma_filter_info *filters)
 {
+	lzma_options_delta *opt;
+
 	// Allocate memory for the decoder if needed.
 	if (next->coder == NULL) {
-		next->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
 
 		// End function is the same for encoder and decoder.
 		next->end = &delta_coder_end;
-		next->coder->next = LZMA_NEXT_CODER_INIT;
+		next->coder->next = v;
 	}
 
 	// Validate the options.
@@ -43,7 +47,7 @@
 		return LZMA_OPTIONS_ERROR;
 
 	// Set the delta distance.
-	const lzma_options_delta *opt = filters[0].options;
+	opt = filters[0].options;
 	next->coder->distance = opt->dist;
 
 	// Initialize the rest of the variables.
@@ -66,5 +70,5 @@
 			|| opt->dist > LZMA_DELTA_DIST_MAX)
 		return UINT64_MAX;
 
-	return sizeof(lzma_coder);
+	return sizeof(struct lzma_coder_s);
 }
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/delta/delta_decoder.c src/liblzma/delta/delta_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/delta/delta_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/delta/delta_decoder.c	2014-05-03 17:04:52.507838100 +0200
@@ -15,11 +15,12 @@
 
 
 static void
-decode_buffer(lzma_coder *coder, uint8_t *buffer, size_t size)
+decode_buffer(struct lzma_coder_s *coder, uint8_t *buffer, size_t size)
 {
 	const size_t distance = coder->distance;
+	size_t i;
 
-	for (size_t i = 0; i < size; ++i) {
+	for (i = 0; i < size; ++i) {
 		buffer[i] += coder->history[(distance + coder->pos) & 0xFF];
 		coder->history[coder->pos-- & 0xFF] = buffer[i];
 	}
@@ -27,16 +28,18 @@
 
 
 static lzma_ret
-delta_decode(lzma_coder *coder, lzma_allocator *allocator,
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size, lzma_action action)
+delta_decode(struct lzma_coder_s *coder, lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size, lzma_action action)
 {
+	size_t out_start;
+	lzma_ret ret;
+	
 	assert(coder->next.code != NULL);
 
-	const size_t out_start = *out_pos;
-
-	const lzma_ret ret = coder->next.code(coder->next.coder, allocator,
+	out_start = *out_pos;
+	ret = coder->next.code(coder->next.coder, allocator,
 			in, in_pos, in_size, out, out_pos, out_size,
 			action);
 
@@ -59,11 +62,12 @@
 lzma_delta_props_decode(void **options, lzma_allocator *allocator,
 		const uint8_t *props, size_t props_size)
 {
+	lzma_options_delta *opt;
+
 	if (props_size != 1)
 		return LZMA_OPTIONS_ERROR;
 
-	lzma_options_delta *opt
-			= lzma_alloc(sizeof(lzma_options_delta), allocator);
+	opt = lzma_alloc(sizeof(lzma_options_delta), allocator);
 	if (opt == NULL)
 		return LZMA_MEM_ERROR;
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/delta/delta_encoder.c src/liblzma/delta/delta_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/delta/delta_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/delta/delta_encoder.c	2014-05-03 17:05:35.838156300 +0200
@@ -18,12 +18,13 @@
 /// is the first filter in the chain (and thus the last filter in the
 /// encoder's filter stack).
 static void
-copy_and_encode(lzma_coder *coder,
-		const uint8_t *restrict in, uint8_t *restrict out, size_t size)
+copy_and_encode(struct lzma_coder_s *coder,
+		const uint8_t * in, uint8_t * out, size_t size)
 {
 	const size_t distance = coder->distance;
+	size_t i;
 
-	for (size_t i = 0; i < size; ++i) {
+	for (i = 0; i < size; ++i) {
 		const uint8_t tmp = coder->history[
 				(distance + coder->pos) & 0xFF];
 		coder->history[coder->pos-- & 0xFF] = in[i];
@@ -35,11 +36,12 @@
 /// Encodes the data in place. This is used when we are the last filter
 /// in the chain (and thus non-last filter in the encoder's filter stack).
 static void
-encode_in_place(lzma_coder *coder, uint8_t *buffer, size_t size)
+encode_in_place(struct lzma_coder_s *coder, uint8_t *buffer, size_t size)
 {
 	const size_t distance = coder->distance;
+	size_t i;
 
-	for (size_t i = 0; i < size; ++i) {
+	for (i = 0; i < size; ++i) {
 		const uint8_t tmp = coder->history[
 				(distance + coder->pos) & 0xFF];
 		coder->history[coder->pos-- & 0xFF] = buffer[i];
@@ -49,10 +51,10 @@
 
 
 static lzma_ret
-delta_encode(lzma_coder *coder, lzma_allocator *allocator,
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size, lzma_action action)
+delta_encode(struct lzma_coder_s *coder, lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size, lzma_action action)
 {
 	lzma_ret ret;
 
@@ -84,7 +86,7 @@
 
 
 static lzma_ret
-delta_encoder_update(lzma_coder *coder, lzma_allocator *allocator,
+delta_encoder_update(struct lzma_coder_s *coder, lzma_allocator *allocator,
 		const lzma_filter *filters_null lzma_attribute((__unused__)),
 		const lzma_filter *reversed_filters)
 {
@@ -109,12 +111,14 @@
 extern lzma_ret
 lzma_delta_props_encode(const void *options, uint8_t *out)
 {
+	lzma_options_delta *opt;
+
 	// The caller must have already validated the options, so it's
 	// LZMA_PROG_ERROR if they are invalid.
 	if (lzma_delta_coder_memusage(options) == UINT64_MAX)
 		return LZMA_PROG_ERROR;
 
-	const lzma_options_delta *opt = options;
+	opt = options;
 	out[0] = opt->dist - LZMA_DELTA_DIST_MIN;
 
 	return LZMA_OK;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lz/lz_decoder.c src/liblzma/lz/lz_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/lz/lz_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lz/lz_decoder.c	2014-05-03 17:12:20.514858900 +0200
@@ -52,7 +52,7 @@
 
 
 static void
-lz_decoder_reset(lzma_coder *coder)
+lz_decoder_reset(struct lzma_coder_s *coder)
 {
 	coder->dict.pos = 0;
 	coder->dict.full = 0;
@@ -63,19 +63,23 @@
 
 
 static lzma_ret
-decode_buffer(lzma_coder *coder,
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size)
+decode_buffer(struct lzma_coder_s *coder,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size)
 {
 	while (true) {
+		size_t dict_start;
+		size_t copy_size;
+		lzma_ret ret;
+
 		// Wrap the dictionary if needed.
 		if (coder->dict.pos == coder->dict.size)
 			coder->dict.pos = 0;
 
 		// Store the current dictionary position. It is needed to know
 		// where to start copying to the out[] buffer.
-		const size_t dict_start = coder->dict.pos;
+		dict_start = coder->dict.pos;
 
 		// Calculate how much we allow coder->lz.code() to decode.
 		// It must not decode past the end of the dictionary
@@ -86,13 +90,13 @@
 					coder->dict.size - coder->dict.pos);
 
 		// Call the coder->lz.code() to do the actual decoding.
-		const lzma_ret ret = coder->lz.code(
+		ret = coder->lz.code(
 				coder->lz.coder, &coder->dict,
 				in, in_pos, in_size);
 
 		// Copy the decoded data from the dictionary to the out[]
 		// buffer.
-		const size_t copy_size = coder->dict.pos - dict_start;
+		copy_size = coder->dict.pos - dict_start;
 		assert(copy_size <= out_size - *out_pos);
 		memcpy(out + *out_pos, coder->dict.buf + dict_start,
 				copy_size);
@@ -125,11 +129,11 @@
 
 
 static lzma_ret
-lz_decode(lzma_coder *coder,
+lz_decode(struct lzma_coder_s *coder,
 		lzma_allocator *allocator lzma_attribute((__unused__)),
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size,
 		lzma_action action)
 {
 	if (coder->next.code == NULL)
@@ -139,13 +143,15 @@
 	// We aren't the last coder in the chain, we need to decode
 	// our input to a temporary buffer.
 	while (*out_pos < out_size) {
+		lzma_ret ret;
+		
 		// Fill the temporary buffer if it is empty.
 		if (!coder->next_finished
 				&& coder->temp.pos == coder->temp.size) {
 			coder->temp.pos = 0;
 			coder->temp.size = 0;
 
-			const lzma_ret ret = coder->next.code(
+			ret = coder->next.code(
 					coder->next.coder,
 					allocator, in, in_pos, in_size,
 					coder->temp.buffer, &coder->temp.size,
@@ -167,7 +173,7 @@
 			return LZMA_OK;
 		}
 
-		const lzma_ret ret = decode_buffer(coder, coder->temp.buffer,
+		ret = decode_buffer(coder, coder->temp.buffer,
 				&coder->temp.pos, coder->temp.size,
 				out, out_pos, out_size);
 
@@ -184,7 +190,7 @@
 
 
 static void
-lz_decoder_end(lzma_coder *coder, lzma_allocator *allocator)
+lz_decoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_next_end(&coder->next, allocator);
 	lzma_free(coder->dict.buf, allocator);
@@ -206,9 +212,14 @@
 			lzma_allocator *allocator, const void *options,
 			lzma_lz_options *lz_options))
 {
+	lzma_lz_options lz_options;
+	
 	// Allocate the base structure if it isn't already allocated.
 	if (next->coder == NULL) {
-		next->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		lzma_lz_decoder v1 = LZMA_LZ_DECODER_INIT;
+		
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
 
@@ -217,13 +228,12 @@
 
 		next->coder->dict.buf = NULL;
 		next->coder->dict.size = 0;
-		next->coder->lz = LZMA_LZ_DECODER_INIT;
-		next->coder->next = LZMA_NEXT_CODER_INIT;
+		next->coder->lz = v1;
+		next->coder->next = v;
 	}
 
 	// Allocate and initialize the LZ-based decoder. It will also give
 	// us the dictionary size.
-	lzma_lz_options lz_options;
 	return_if_error(lz_init(&next->coder->lz, allocator,
 			filters[0].options, &lz_options));
 
@@ -289,12 +299,12 @@
 extern uint64_t
 lzma_lz_decoder_memusage(size_t dictionary_size)
 {
-	return sizeof(lzma_coder) + (uint64_t)(dictionary_size);
+	return sizeof(struct lzma_coder_s) + (uint64_t)(dictionary_size);
 }
 
 
 extern void
-lzma_lz_decoder_uncompressed(lzma_coder *coder, lzma_vli uncompressed_size)
+lzma_lz_decoder_uncompressed(struct lzma_coder_s *coder, lzma_vli uncompressed_size)
 {
 	coder->lz.set_uncompressed(coder->lz.coder, uncompressed_size);
 }
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lz/lz_decoder.h src/liblzma/lz/lz_decoder.h
--- ..\..\Library\xz-5.0.5\src/liblzma/lz/lz_decoder.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lz/lz_decoder.h	2014-05-03 17:11:00.042040500 +0200
@@ -53,36 +53,36 @@
 
 typedef struct {
 	/// Data specific to the LZ-based decoder
-	lzma_coder *coder;
+	struct lzma_coder_s *coder;
 
 	/// Function to decode from in[] to *dict
-	lzma_ret (*code)(lzma_coder *restrict coder,
-			lzma_dict *restrict dict, const uint8_t *restrict in,
-			size_t *restrict in_pos, size_t in_size);
+	lzma_ret(*code)(struct lzma_coder_s * coder,
+			lzma_dict * dict, const uint8_t * in,
+			size_t * in_pos, size_t in_size);
 
-	void (*reset)(lzma_coder *coder, const void *options);
+	void (*reset)(struct lzma_coder_s *coder, const void *options);
 
 	/// Set the uncompressed size
-	void (*set_uncompressed)(lzma_coder *coder,
+	void(*set_uncompressed)(struct lzma_coder_s *coder,
 			lzma_vli uncompressed_size);
 
 	/// Free allocated resources
-	void (*end)(lzma_coder *coder, lzma_allocator *allocator);
+	void(*end)(struct lzma_coder_s *coder, lzma_allocator *allocator);
 
 } lzma_lz_decoder;
 
 
 #define LZMA_LZ_DECODER_INIT \
-	(lzma_lz_decoder){ \
-		.coder = NULL, \
-		.code = NULL, \
-		.reset = NULL, \
-		.set_uncompressed = NULL, \
-		.end = NULL, \
+	{ \
+		NULL, \
+		NULL, \
+		NULL, \
+		NULL, \
+		NULL \
 	}
 
 
-extern lzma_ret lzma_lz_decoder_init(lzma_next_coder *next,
+extern lzma_ret lzma_lz_decoder_init(struct lzma_next_coder_s *next,
 		lzma_allocator *allocator, const lzma_filter_info *filters,
 		lzma_ret (*lz_init)(lzma_lz_decoder *lz,
 			lzma_allocator *allocator, const void *options,
@@ -91,7 +91,7 @@
 extern uint64_t lzma_lz_decoder_memusage(size_t dictionary_size);
 
 extern void lzma_lz_decoder_uncompressed(
-		lzma_coder *coder, lzma_vli uncompressed_size);
+		struct lzma_coder_s *coder, lzma_vli uncompressed_size);
 
 
 //////////////////////
@@ -99,7 +99,7 @@
 //////////////////////
 
 /// Get a byte from the history buffer.
-static inline uint8_t
+static __inline uint8_t
 dict_get(const lzma_dict *const dict, const uint32_t distance)
 {
 	return dict->buf[dict->pos - distance - 1
@@ -108,7 +108,7 @@
 
 
 /// Test if dictionary is empty.
-static inline bool
+static __inline bool
 dict_is_empty(const lzma_dict *const dict)
 {
 	return dict->full == 0;
@@ -116,7 +116,7 @@
 
 
 /// Validate the match distance
-static inline bool
+static __inline bool
 dict_is_distance_valid(const lzma_dict *const dict, const size_t distance)
 {
 	return dict->full > distance;
@@ -124,7 +124,7 @@
 
 
 /// Repeat *len bytes at distance.
-static inline bool
+static __inline bool
 dict_repeat(lzma_dict *dict, uint32_t distance, uint32_t *len)
 {
 	// Don't write past the end of the dictionary.
@@ -151,13 +151,15 @@
 		dict->pos += left;
 
 	} else {
+		uint32_t copy_pos;
+		uint32_t copy_size;
+		
 		// The bigger the dictionary, the more rare this
 		// case occurs. We need to "wrap" the dict, thus
 		// we might need two memcpy() to copy all the data.
 		assert(dict->full == dict->size);
-		const uint32_t copy_pos
-				= dict->pos - distance - 1 + dict->size;
-		uint32_t copy_size = dict->size - copy_pos;
+		copy_pos = dict->pos - distance - 1 + dict->size;
+		copy_size = dict->size - copy_pos;
 
 		if (copy_size < left) {
 			memmove(dict->buf + dict->pos, dict->buf + copy_pos,
@@ -183,7 +185,7 @@
 
 /// Puts one byte into the dictionary. Returns true if the dictionary was
 /// already full and the byte couldn't be added.
-static inline bool
+static __inline bool
 dict_put(lzma_dict *dict, uint8_t byte)
 {
 	if (unlikely(dict->pos == dict->limit))
@@ -199,10 +201,10 @@
 
 
 /// Copies arbitrary amount of data into the dictionary.
-static inline void
-dict_write(lzma_dict *restrict dict, const uint8_t *restrict in,
-		size_t *restrict in_pos, size_t in_size,
-		size_t *restrict left)
+static __inline void
+dict_write(lzma_dict * dict, const uint8_t * in,
+		size_t * in_pos, size_t in_size,
+		size_t * left)
 {
 	// NOTE: If we are being given more data than the size of the
 	// dictionary, it could be possible to optimize the LZ decoder
@@ -224,7 +226,7 @@
 }
 
 
-static inline void
+static __inline void
 dict_reset(lzma_dict *dict)
 {
 	dict->need_reset = true;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lz/lz_encoder.c src/liblzma/lz/lz_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/lz/lz_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lz/lz_encoder.c	2014-05-03 17:18:52.809662300 +0200
@@ -43,16 +43,18 @@
 static void
 move_window(lzma_mf *mf)
 {
+	uint32_t move_offset;
+	size_t move_size;
+	
 	// Align the move to a multiple of 16 bytes. Some LZ-based encoders
 	// like LZMA use the lowest bits of mf->read_pos to know the
 	// alignment of the uncompressed data. We also get better speed
 	// for memmove() with aligned buffers.
 	assert(mf->read_pos > mf->keep_size_before);
-	const uint32_t move_offset
-		= (mf->read_pos - mf->keep_size_before) & ~UINT32_C(15);
+	move_offset = (mf->read_pos - mf->keep_size_before) & ~UINT32_C(15);
 
 	assert(mf->write_pos > move_offset);
-	const size_t move_size = mf->write_pos - move_offset;
+	move_size = mf->write_pos - move_offset;
 
 	assert(move_offset + move_size <= mf->size);
 
@@ -76,9 +78,12 @@
 /// This function must not be called once it has returned LZMA_STREAM_END.
 ///
 static lzma_ret
-fill_window(lzma_coder *coder, lzma_allocator *allocator, const uint8_t *in,
+fill_window(struct lzma_coder_s *coder, lzma_allocator *allocator, const uint8_t *in,
 		size_t *in_pos, size_t in_size, lzma_action action)
 {
+	size_t write_pos;
+	lzma_ret ret;
+
 	assert(coder->mf.read_pos <= coder->mf.write_pos);
 
 	// Move the sliding window if needed.
@@ -88,8 +93,7 @@
 	// Maybe this is ugly, but lzma_mf uses uint32_t for most things
 	// (which I find cleanest), but we need size_t here when filling
 	// the history window.
-	size_t write_pos = coder->mf.write_pos;
-	lzma_ret ret;
+	write_pos = coder->mf.write_pos;
 	if (coder->next.code == NULL) {
 		// Not using a filter, simply memcpy() as much as possible.
 		lzma_bufcpy(in, in_pos, in_size, coder->mf.buffer,
@@ -148,14 +152,16 @@
 
 
 static lzma_ret
-lz_encode(lzma_coder *coder, lzma_allocator *allocator,
-		const uint8_t *restrict in, size_t *restrict in_pos,
+lz_encode(struct lzma_coder_s *coder, lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
 		size_t in_size,
-		uint8_t *restrict out, size_t *restrict out_pos,
+		uint8_t * out, size_t * out_pos,
 		size_t out_size, lzma_action action)
 {
 	while (*out_pos < out_size
 			&& (*in_pos < in_size || action != LZMA_RUN)) {
+		lzma_ret ret;
+		
 		// Read more data to coder->mf.buffer if needed.
 		if (coder->mf.action == LZMA_RUN && coder->mf.read_pos
 				>= coder->mf.read_limit)
@@ -163,7 +169,7 @@
 					in, in_pos, in_size, action));
 
 		// Encode
-		const lzma_ret ret = coder->lz.code(coder->lz.coder,
+		ret = coder->lz.code(coder->lz.coder,
 				&coder->mf, out, out_pos, out_size);
 		if (ret != LZMA_OK) {
 			// Setting this to LZMA_RUN for cases when we are
@@ -182,6 +188,14 @@
 lz_encoder_prepare(lzma_mf *mf, lzma_allocator *allocator,
 		const lzma_lz_options *lz_options)
 {
+	bool is_bt;
+	uint32_t new_count;
+	uint32_t reserve;
+	uint32_t old_size;
+	uint32_t hash_bytes;
+	uint32_t hs;
+	uint32_t old_count;
+	
 	// For now, the dictionary size is limited to 1.5 GiB. This may grow
 	// in the future if needed, but it needs a little more work than just
 	// changing this check.
@@ -207,14 +221,14 @@
 	//     to size_t.
 	//   - Memory usage calculation needs something too, e.g. use uint64_t
 	//     for mf->size.
-	uint32_t reserve = lz_options->dict_size / 2;
+	reserve = lz_options->dict_size / 2;
 	if (reserve > (UINT32_C(1) << 30))
 		reserve /= 2;
 
 	reserve += (lz_options->before_size + lz_options->match_len_max
 			+ lz_options->after_size) / 2 + (UINT32_C(1) << 19);
 
-	const uint32_t old_size = mf->size;
+	old_size = mf->size;
 	mf->size = mf->keep_size_before + reserve + mf->keep_size_after;
 
 	// Deallocate the old history buffer if it exists but has different
@@ -284,12 +298,11 @@
 
 	// Calculate the sizes of mf->hash and mf->son and check that
 	// nice_len is big enough for the selected match finder.
-	const uint32_t hash_bytes = lz_options->match_finder & 0x0F;
+	hash_bytes = lz_options->match_finder & 0x0F;
 	if (hash_bytes > mf->nice_len)
 		return true;
 
-	const bool is_bt = (lz_options->match_finder & 0x10) != 0;
-	uint32_t hs;
+	is_bt = (lz_options->match_finder & 0x10) != 0;
 
 	if (hash_bytes == 2) {
 		hs = 0xFFFF;
@@ -331,13 +344,13 @@
 	// hash_size_sum + sons_count cannot overflow.
 	assert(hs < UINT32_MAX / 5);
 
-	const uint32_t old_count = mf->hash_size_sum + mf->sons_count;
+	old_count = mf->hash_size_sum + mf->sons_count;
 	mf->hash_size_sum = hs;
 	mf->sons_count = mf->cyclic_size;
 	if (is_bt)
 		mf->sons_count *= 2;
 
-	const uint32_t new_count = mf->hash_size_sum + mf->sons_count;
+	new_count = mf->hash_size_sum + mf->sons_count;
 
 	// Deallocate the old hash array if it exists and has different size
 	// than what is needed now.
@@ -363,6 +376,8 @@
 lz_encoder_init(lzma_mf *mf, lzma_allocator *allocator,
 		const lzma_lz_options *lz_options)
 {
+	size_t alloc_count;
+	
 	// Allocate the history buffer.
 	if (mf->buffer == NULL) {
 		mf->buffer = lzma_alloc(mf->size, allocator);
@@ -382,7 +397,7 @@
 	mf->pending = 0;
 
 	// Allocate match finder's hash array.
-	const size_t alloc_count = mf->hash_size_sum + mf->sons_count;
+	alloc_count = mf->hash_size_sum + mf->sons_count;
 
 #if UINT32_MAX >= SIZE_MAX / 4
 	// Check for integer overflow. (Huge dictionaries are not
@@ -442,12 +457,9 @@
 lzma_lz_encoder_memusage(const lzma_lz_options *lz_options)
 {
 	// Old buffers must not exist when calling lz_encoder_prepare().
-	lzma_mf mf = {
-		.buffer = NULL,
-		.hash = NULL,
-		.hash_size_sum = 0,
-		.sons_count = 0,
-	};
+	lzma_mf mf;
+	
+	memset(&mf, 0, sizeof(lzma_mf));
 
 	// Setup the size information into mf.
 	if (lz_encoder_prepare(&mf, NULL, lz_options))
@@ -456,12 +468,12 @@
 	// Calculate the memory usage.
 	return (uint64_t)(mf.hash_size_sum + mf.sons_count)
 				* sizeof(uint32_t)
-			+ (uint64_t)(mf.size) + sizeof(lzma_coder);
+			+ (uint64_t)(mf.size) + sizeof(struct lzma_coder_s);
 }
 
 
 static void
-lz_encoder_end(lzma_coder *coder, lzma_allocator *allocator)
+lz_encoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_next_end(&coder->next, allocator);
 
@@ -479,7 +491,7 @@
 
 
 static lzma_ret
-lz_encoder_update(lzma_coder *coder, lzma_allocator *allocator,
+lz_encoder_update(struct lzma_coder_s *coder, lzma_allocator *allocator,
 		const lzma_filter *filters_null lzma_attribute((__unused__)),
 		const lzma_filter *reversed_filters)
 {
@@ -501,6 +513,8 @@
 			lzma_allocator *allocator, const void *options,
 			lzma_lz_options *lz_options))
 {
+	lzma_lz_options lz_options;
+	
 #ifdef HAVE_SMALL
 	// We need that the CRC32 table has been initialized.
 	lzma_crc32_init();
@@ -508,7 +522,9 @@
 
 	// Allocate and initialize the base data structure.
 	if (next->coder == NULL) {
-		next->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
 
@@ -525,11 +541,10 @@
 		next->coder->mf.hash_size_sum = 0;
 		next->coder->mf.sons_count = 0;
 
-		next->coder->next = LZMA_NEXT_CODER_INIT;
+		next->coder->next = v;
 	}
 
 	// Initialize the LZ-based encoder.
-	lzma_lz_options lz_options;
 	return_if_error(lz_init(&next->coder->lz, allocator,
 			filters[0].options, &lz_options));
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lz/lz_encoder.h src/liblzma/lz/lz_encoder.h
--- ..\..\Library\xz-5.0.5\src/liblzma/lz/lz_encoder.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lz/lz_encoder.h	2013-12-01 16:46:51.548303900 +0100
@@ -191,18 +191,18 @@
 
 typedef struct {
 	/// Data specific to the LZ-based encoder
-	lzma_coder *coder;
+	struct lzma_coder_s *coder;
 
 	/// Function to encode from *dict to out[]
-	lzma_ret (*code)(lzma_coder *restrict coder,
-			lzma_mf *restrict mf, uint8_t *restrict out,
-			size_t *restrict out_pos, size_t out_size);
+	lzma_ret (*code)(struct lzma_coder_s * coder,
+			lzma_mf * mf, uint8_t * out,
+			size_t * out_pos, size_t out_size);
 
 	/// Free allocated resources
-	void (*end)(lzma_coder *coder, lzma_allocator *allocator);
+	void (*end)(struct lzma_coder_s *coder, lzma_allocator *allocator);
 
 	/// Update the options in the middle of the encoding.
-	lzma_ret (*options_update)(lzma_coder *coder,
+	lzma_ret (*options_update)(struct lzma_coder_s *coder,
 			const lzma_filter *filter);
 
 } lzma_lz_encoder;
@@ -218,7 +218,7 @@
 
 
 /// Get pointer to the first byte not ran through the match finder
-static inline const uint8_t *
+static __inline const uint8_t *
 mf_ptr(const lzma_mf *mf)
 {
 	return mf->buffer + mf->read_pos;
@@ -226,7 +226,7 @@
 
 
 /// Get the number of bytes that haven't been ran through the match finder yet.
-static inline uint32_t
+static __inline uint32_t
 mf_avail(const lzma_mf *mf)
 {
 	return mf->write_pos - mf->read_pos;
@@ -235,7 +235,7 @@
 
 /// Get the number of bytes that haven't been encoded yet (some of these
 /// bytes may have been ran through the match finder though).
-static inline uint32_t
+static __inline uint32_t
 mf_unencoded(const lzma_mf *mf)
 {
 	return mf->write_pos - mf->read_pos + mf->read_ahead;
@@ -249,7 +249,7 @@
 /// NOTE: When moving the input window, we need to do it so that the lowest
 /// bits of dict->read_pos are not modified to keep this macro working
 /// as intended.
-static inline uint32_t
+static __inline uint32_t
 mf_position(const lzma_mf *mf)
 {
 	return mf->read_pos - mf->read_ahead;
@@ -264,7 +264,7 @@
 /// For example, if mf_find() finds a match of 200 bytes long, the first byte
 /// of that match was already consumed by mf_find(), and the rest 199 bytes
 /// have to be skipped with mf_skip(mf, 199).
-static inline void
+static __inline void
 mf_skip(lzma_mf *mf, uint32_t amount)
 {
 	if (amount != 0) {
@@ -276,7 +276,7 @@
 
 /// Copies at most *left number of bytes from the history buffer
 /// to out[]. This is needed by LZMA2 to encode uncompressed chunks.
-static inline void
+static __inline void
 mf_read(lzma_mf *mf, uint8_t *out, size_t *out_pos, size_t out_size,
 		size_t *left)
 {
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lz/lz_encoder_mf.c src/liblzma/lz/lz_encoder_mf.c
--- ..\..\Library\xz-5.0.5\src/liblzma/lz/lz_encoder_mf.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lz/lz_encoder_mf.c	2014-05-03 17:46:40.876384600 +0200
@@ -29,11 +29,12 @@
 	// Length of the longest match; assume that no matches were found
 	// and thus the maximum length is zero.
 	uint32_t len_best = 0;
+	uint32_t i;
 
 	if (count > 0) {
 #ifndef NDEBUG
 		// Validate the matches.
-		for (uint32_t i = 0; i < count; ++i) {
+		for (i = 0; i < count; ++i) {
 			assert(matches[i].len <= mf->nice_len);
 			assert(matches[i].dist < mf->read_pos);
 			assert(memcmp(mf_ptr(mf) - 1,
@@ -49,21 +50,26 @@
 		// If a match of maximum search length was found, try to
 		// extend the match to maximum possible length.
 		if (len_best == mf->nice_len) {
+			uint8_t *p1;
+
 			// The limit for the match length is either the
 			// maximum match length supported by the LZ-based
 			// encoder or the number of bytes left in the
 			// dictionary, whichever is smaller.
 			uint32_t limit = mf_avail(mf) + 1;
+			
+			uint8_t *p2;
+			
 			if (limit > mf->match_len_max)
 				limit = mf->match_len_max;
 
 			// Pointer to the byte we just ran through
 			// the match finder.
-			const uint8_t *p1 = mf_ptr(mf) - 1;
+			p1 = mf_ptr(mf) - 1;
 
 			// Pointer to the beginning of the match. We need -1
 			// here because the match distances are zero based.
-			const uint8_t *p2 = p1 - matches[count - 1].dist - 1;
+			p2 = p1 - matches[count - 1].dist - 1;
 
 			while (len_best < limit
 					&& p1[len_best] == p2[len_best])
@@ -108,18 +114,22 @@
 static void
 normalize(lzma_mf *mf)
 {
+	uint32_t subvalue;
+	uint32_t count;
+	uint32_t *hash;
+	uint32_t i;
+	
 	assert(mf->read_pos + mf->offset == MUST_NORMALIZE_POS);
 
 	// In future we may not want to touch the lowest bits, because there
 	// may be match finders that use larger resolution than one byte.
-	const uint32_t subvalue
-			= (MUST_NORMALIZE_POS - mf->cyclic_size);
+	subvalue = (MUST_NORMALIZE_POS - mf->cyclic_size);
 				// & (~(UINT32_C(1) << 10) - 1);
 
-	const uint32_t count = mf->hash_size_sum + mf->sons_count;
-	uint32_t *hash = mf->hash;
+	count = mf->hash_size_sum + mf->sons_count;
+	hash = mf->hash;
 
-	for (uint32_t i = 0; i < count; ++i) {
+	for (i = 0; i < count; ++i) {
 		// If the distance is greater than the dictionary size,
 		// we can simply mark the hash element as empty.
 		//
@@ -188,6 +198,8 @@
 /// in them.
 #define header(is_bt, len_min, ret_op) \
 	uint32_t len_limit = mf_avail(mf); \
+	uint8_t *cur; \
+	uint32_t pos;\
 	if (mf->nice_len <= len_limit) { \
 		len_limit = mf->nice_len; \
 	} else if (len_limit < (len_min) \
@@ -196,15 +208,15 @@
 		move_pending(mf); \
 		ret_op; \
 	} \
-	const uint8_t *cur = mf_ptr(mf); \
-	const uint32_t pos = mf->read_pos + mf->offset
+	cur = mf_ptr(mf); \
+	pos = mf->read_pos + mf->offset
 
 
 /// Header for find functions. "return 0" indicates that zero matches
 /// were found.
 #define header_find(is_bt, len_min) \
-	header(is_bt, len_min, return 0); \
-	uint32_t matches_count = 0
+	uint32_t matches_count = 0; \
+	header(is_bt, len_min, return 0)
 
 
 /// Header for a loop in a skip function. "continue" tells to skip the rest
@@ -260,16 +272,19 @@
 	son[cyclic_pos] = cur_match;
 
 	while (true) {
+		uint8_t *pb;
 		const uint32_t delta = pos - cur_match;
+
 		if (depth-- == 0 || delta >= cyclic_size)
 			return matches;
 
-		const uint8_t *const pb = cur - delta;
+		pb = cur - delta;
 		cur_match = son[cyclic_pos - delta
 				+ (delta > cyclic_pos ? cyclic_size : 0)];
 
 		if (pb[len_best] == cur[len_best] && pb[0] == cur[0]) {
 			uint32_t len = 0;
+
 			while (++len != len_limit)
 				if (pb[len] != cur[len])
 					break;
@@ -305,59 +320,69 @@
 extern uint32_t
 lzma_mf_hc3_find(lzma_mf *mf, lzma_match *matches)
 {
+	uint32_t delta2;
+	uint32_t cur_match;
+	uint32_t len_best;
+	
 	header_find(false, 3);
 
-	hash_3_calc();
-
-	const uint32_t delta2 = pos - mf->hash[hash_2_value];
-	const uint32_t cur_match = mf->hash[FIX_3_HASH_SIZE + hash_value];
+	{
+		hash_3_calc();
 
-	mf->hash[hash_2_value] = pos;
-	mf->hash[FIX_3_HASH_SIZE + hash_value] = pos;
+		delta2 = pos - mf->hash[hash_2_value];
+		cur_match = mf->hash[FIX_3_HASH_SIZE + hash_value];
 
-	uint32_t len_best = 2;
+		mf->hash[hash_2_value] = pos;
+		mf->hash[FIX_3_HASH_SIZE + hash_value] = pos;
 
-	if (delta2 < mf->cyclic_size && *(cur - delta2) == *cur) {
-		for ( ; len_best != len_limit; ++len_best)
-			if (*(cur + len_best - delta2) != cur[len_best])
-				break;
+		len_best = 2;
 
-		matches[0].len = len_best;
-		matches[0].dist = delta2 - 1;
-		matches_count = 1;
+		if (delta2 < mf->cyclic_size && *(cur - delta2) == *cur) {
+			for ( ; len_best != len_limit; ++len_best)
+				if (*(cur + len_best - delta2) != cur[len_best])
+					break;
 
-		if (len_best == len_limit) {
-			hc_skip();
-			return 1; // matches_count
+			matches[0].len = len_best;
+			matches[0].dist = delta2 - 1;
+			matches_count = 1;
+
+			if (len_best == len_limit) {
+				hc_skip();
+				return 1; // matches_count
+			}
 		}
-	}
 
-	hc_find(len_best);
+		hc_find(len_best);
+	}
 }
 
 
 extern void
 lzma_mf_hc3_skip(lzma_mf *mf, uint32_t amount)
 {
+	uint8_t *cur;
+	uint32_t pos;
+	uint32_t cur_match;
+	
 	do {
 		if (mf_avail(mf) < 3) {
 			move_pending(mf);
 			continue;
 		}
 
-		const uint8_t *cur = mf_ptr(mf);
-		const uint32_t pos = mf->read_pos + mf->offset;
-
-		hash_3_calc();
+		cur = mf_ptr(mf);
+		pos = mf->read_pos + mf->offset;
 
-		const uint32_t cur_match
-				= mf->hash[FIX_3_HASH_SIZE + hash_value];
+		{
+			hash_3_calc();
 
-		mf->hash[hash_2_value] = pos;
-		mf->hash[FIX_3_HASH_SIZE + hash_value] = pos;
+			cur_match = mf->hash[FIX_3_HASH_SIZE + hash_value];
 
-		hc_skip();
+			mf->hash[hash_2_value] = pos;
+			mf->hash[FIX_3_HASH_SIZE + hash_value] = pos;
 
+			hc_skip();
+		}
 	} while (--amount != 0);
 }
 #endif
@@ -367,78 +392,88 @@
 extern uint32_t
 lzma_mf_hc4_find(lzma_mf *mf, lzma_match *matches)
 {
+	uint32_t delta2;
+	uint32_t delta3;
+	uint32_t cur_match;
+	uint32_t len_best;
+	
 	header_find(false, 4);
 
-	hash_4_calc();
+	{
+		hash_4_calc();
 
-	uint32_t delta2 = pos - mf->hash[hash_2_value];
-	const uint32_t delta3
-			= pos - mf->hash[FIX_3_HASH_SIZE + hash_3_value];
-	const uint32_t cur_match = mf->hash[FIX_4_HASH_SIZE + hash_value];
+		delta2 = pos - mf->hash[hash_2_value];
+		delta3 = pos - mf->hash[FIX_3_HASH_SIZE + hash_3_value];
+		cur_match = mf->hash[FIX_4_HASH_SIZE + hash_value];
 
-	mf->hash[hash_2_value ] = pos;
-	mf->hash[FIX_3_HASH_SIZE + hash_3_value] = pos;
-	mf->hash[FIX_4_HASH_SIZE + hash_value] = pos;
+		mf->hash[hash_2_value ] = pos;
+		mf->hash[FIX_3_HASH_SIZE + hash_3_value] = pos;
+		mf->hash[FIX_4_HASH_SIZE + hash_value] = pos;
 
-	uint32_t len_best = 1;
+		len_best = 1;
 
-	if (delta2 < mf->cyclic_size && *(cur - delta2) == *cur) {
-		len_best = 2;
-		matches[0].len = 2;
-		matches[0].dist = delta2 - 1;
-		matches_count = 1;
-	}
+		if (delta2 < mf->cyclic_size && *(cur - delta2) == *cur) {
+			len_best = 2;
+			matches[0].len = 2;
+			matches[0].dist = delta2 - 1;
+			matches_count = 1;
+		}
 
-	if (delta2 != delta3 && delta3 < mf->cyclic_size
-			&& *(cur - delta3) == *cur) {
-		len_best = 3;
-		matches[matches_count++].dist = delta3 - 1;
-		delta2 = delta3;
-	}
+		if (delta2 != delta3 && delta3 < mf->cyclic_size
+				&& *(cur - delta3) == *cur) {
+			len_best = 3;
+			matches[matches_count++].dist = delta3 - 1;
+			delta2 = delta3;
+		}
 
-	if (matches_count != 0) {
-		for ( ; len_best != len_limit; ++len_best)
-			if (*(cur + len_best - delta2) != cur[len_best])
-				break;
+		if (matches_count != 0) {
+			for ( ; len_best != len_limit; ++len_best)
+				if (*(cur + len_best - delta2) != cur[len_best])
+					break;
 
-		matches[matches_count - 1].len = len_best;
+			matches[matches_count - 1].len = len_best;
 
-		if (len_best == len_limit) {
-			hc_skip();
-			return matches_count;
+			if (len_best == len_limit) {
+				hc_skip();
+				return matches_count;
+			}
 		}
-	}
 
-	if (len_best < 3)
-		len_best = 3;
+		if (len_best < 3)
+			len_best = 3;
 
-	hc_find(len_best);
+		hc_find(len_best);
+	}
 }
 
 
 extern void
 lzma_mf_hc4_skip(lzma_mf *mf, uint32_t amount)
 {
+	uint8_t *cur;
+	uint32_t pos;
+	uint32_t cur_match;
+	
 	do {
 		if (mf_avail(mf) < 4) {
 			move_pending(mf);
 			continue;
 		}
 
-		const uint8_t *cur = mf_ptr(mf);
-		const uint32_t pos = mf->read_pos + mf->offset;
+		cur = mf_ptr(mf);
+		pos = mf->read_pos + mf->offset;
 
-		hash_4_calc();
+		{
+			hash_4_calc();
 
-		const uint32_t cur_match
-				= mf->hash[FIX_4_HASH_SIZE + hash_value];
+			cur_match = mf->hash[FIX_4_HASH_SIZE + hash_value];
 
-		mf->hash[hash_2_value] = pos;
-		mf->hash[FIX_3_HASH_SIZE + hash_3_value] = pos;
-		mf->hash[FIX_4_HASH_SIZE + hash_value] = pos;
-
-		hc_skip();
+			mf->hash[hash_2_value] = pos;
+			mf->hash[FIX_3_HASH_SIZE + hash_3_value] = pos;
+			mf->hash[FIX_4_HASH_SIZE + hash_value] = pos;
 
+			hc_skip();
+		}
 	} while (--amount != 0);
 }
 #endif
@@ -470,18 +505,22 @@
 
 	while (true) {
 		const uint32_t delta = pos - cur_match;
+		uint32_t *pair;
+		uint8_t *pb;
+		uint32_t len;
+		
 		if (depth-- == 0 || delta >= cyclic_size) {
 			*ptr0 = EMPTY_HASH_VALUE;
 			*ptr1 = EMPTY_HASH_VALUE;
 			return matches;
 		}
 
-		uint32_t *const pair = son + ((cyclic_pos - delta
+		pair = son + ((cyclic_pos - delta
 				+ (delta > cyclic_pos ? cyclic_size : 0))
 				<< 1);
 
-		const uint8_t *const pb = cur - delta;
-		uint32_t len = my_min(len0, len1);
+		pb = cur - delta;
+		len = my_min(len0, len1);
 
 		if (pb[len] == cur[len]) {
 			while (++len != len_limit)
@@ -536,17 +575,21 @@
 
 	while (true) {
 		const uint32_t delta = pos - cur_match;
+		uint32_t *pair;
+		uint8_t *pb;
+		uint32_t len;
+		
 		if (depth-- == 0 || delta >= cyclic_size) {
 			*ptr0 = EMPTY_HASH_VALUE;
 			*ptr1 = EMPTY_HASH_VALUE;
 			return;
 		}
 
-		uint32_t *pair = son + ((cyclic_pos - delta
+		pair = son + ((cyclic_pos - delta
 				+ (delta > cyclic_pos ? cyclic_size : 0))
 				<< 1);
-		const uint8_t *pb = cur - delta;
-		uint32_t len = my_min(len0, len1);
+		pb = cur - delta;
+		len = my_min(len0, len1);
 
 		if (pb[len] == cur[len]) {
 			while (++len != len_limit)
@@ -593,30 +636,37 @@
 extern uint32_t
 lzma_mf_bt2_find(lzma_mf *mf, lzma_match *matches)
 {
+	uint32_t cur_match;
+	
 	header_find(true, 2);
 
-	hash_2_calc();
+	{
+		hash_2_calc();
 
-	const uint32_t cur_match = mf->hash[hash_value];
-	mf->hash[hash_value] = pos;
+		cur_match = mf->hash[hash_value];
+		mf->hash[hash_value] = pos;
 
-	bt_find(1);
+		bt_find(1);
+	}
 }
 
 
 extern void
 lzma_mf_bt2_skip(lzma_mf *mf, uint32_t amount)
 {
+	uint32_t cur_match;
+	
 	do {
 		header_skip(true, 2);
 
-		hash_2_calc();
-
-		const uint32_t cur_match = mf->hash[hash_value];
-		mf->hash[hash_value] = pos;
+		{
+			hash_2_calc();
 
-		bt_skip();
+			cur_match = mf->hash[hash_value];
+			mf->hash[hash_value] = pos;
 
+			bt_skip();
+		}
 	} while (--amount != 0);
 }
 #endif
@@ -625,54 +675,61 @@
 #ifdef HAVE_MF_BT3
 extern uint32_t
 lzma_mf_bt3_find(lzma_mf *mf, lzma_match *matches)
-{
+{	
+	uint32_t delta2;
+	uint32_t cur_match;
+	uint32_t len_best;
+	
 	header_find(true, 3);
+	{
+		hash_3_calc();
 
-	hash_3_calc();
-
-	const uint32_t delta2 = pos - mf->hash[hash_2_value];
-	const uint32_t cur_match = mf->hash[FIX_3_HASH_SIZE + hash_value];
-
-	mf->hash[hash_2_value] = pos;
-	mf->hash[FIX_3_HASH_SIZE + hash_value] = pos;
+		delta2 = pos - mf->hash[hash_2_value];
+		cur_match = mf->hash[FIX_3_HASH_SIZE + hash_value];
 
-	uint32_t len_best = 2;
+		mf->hash[hash_2_value] = pos;
+		mf->hash[FIX_3_HASH_SIZE + hash_value] = pos;
 
-	if (delta2 < mf->cyclic_size && *(cur - delta2) == *cur) {
-		for ( ; len_best != len_limit; ++len_best)
-			if (*(cur + len_best - delta2) != cur[len_best])
-				break;
+		len_best = 2;
 
-		matches[0].len = len_best;
-		matches[0].dist = delta2 - 1;
-		matches_count = 1;
+		if (delta2 < mf->cyclic_size && *(cur - delta2) == *cur) {
+			for ( ; len_best != len_limit; ++len_best)
+				if (*(cur + len_best - delta2) != cur[len_best])
+					break;
 
-		if (len_best == len_limit) {
-			bt_skip();
-			return 1; // matches_count
+			matches[0].len = len_best;
+			matches[0].dist = delta2 - 1;
+			matches_count = 1;
+
+			if (len_best == len_limit) {
+				bt_skip();
+				return 1; // matches_count
+			}
 		}
-	}
 
-	bt_find(len_best);
+		bt_find(len_best);
+	}
 }
 
 
 extern void
 lzma_mf_bt3_skip(lzma_mf *mf, uint32_t amount)
 {
+	uint32_t cur_match;
+	
 	do {
 		header_skip(true, 3);
 
-		hash_3_calc();
+		{
+			hash_3_calc();
 
-		const uint32_t cur_match
-				= mf->hash[FIX_3_HASH_SIZE + hash_value];
+			cur_match = mf->hash[FIX_3_HASH_SIZE + hash_value];
 
-		mf->hash[hash_2_value] = pos;
-		mf->hash[FIX_3_HASH_SIZE + hash_value] = pos;
-
-		bt_skip();
+			mf->hash[hash_2_value] = pos;
+			mf->hash[FIX_3_HASH_SIZE + hash_value] = pos;
 
+			bt_skip();
+		}
 	} while (--amount != 0);
 }
 #endif
@@ -682,72 +739,80 @@
 extern uint32_t
 lzma_mf_bt4_find(lzma_mf *mf, lzma_match *matches)
 {
+	uint32_t delta2;
+	uint32_t delta3;
+	uint32_t cur_match;
+	uint32_t len_best;
+	
 	header_find(true, 4);
 
-	hash_4_calc();
+	{
+		hash_4_calc();
 
-	uint32_t delta2 = pos - mf->hash[hash_2_value];
-	const uint32_t delta3
-			= pos - mf->hash[FIX_3_HASH_SIZE + hash_3_value];
-	const uint32_t cur_match = mf->hash[FIX_4_HASH_SIZE + hash_value];
+		delta2 = pos - mf->hash[hash_2_value];
+		delta3 = pos - mf->hash[FIX_3_HASH_SIZE + hash_3_value];
+		cur_match = mf->hash[FIX_4_HASH_SIZE + hash_value];
 
-	mf->hash[hash_2_value] = pos;
-	mf->hash[FIX_3_HASH_SIZE + hash_3_value] = pos;
-	mf->hash[FIX_4_HASH_SIZE + hash_value] = pos;
+		mf->hash[hash_2_value] = pos;
+		mf->hash[FIX_3_HASH_SIZE + hash_3_value] = pos;
+		mf->hash[FIX_4_HASH_SIZE + hash_value] = pos;
 
-	uint32_t len_best = 1;
+		len_best = 1;
 
-	if (delta2 < mf->cyclic_size && *(cur - delta2) == *cur) {
-		len_best = 2;
-		matches[0].len = 2;
-		matches[0].dist = delta2 - 1;
-		matches_count = 1;
-	}
+		if (delta2 < mf->cyclic_size && *(cur - delta2) == *cur) {
+			len_best = 2;
+			matches[0].len = 2;
+			matches[0].dist = delta2 - 1;
+			matches_count = 1;
+		}
 
-	if (delta2 != delta3 && delta3 < mf->cyclic_size
-			&& *(cur - delta3) == *cur) {
-		len_best = 3;
-		matches[matches_count++].dist = delta3 - 1;
-		delta2 = delta3;
-	}
+		if (delta2 != delta3 && delta3 < mf->cyclic_size
+				&& *(cur - delta3) == *cur) {
+			len_best = 3;
+			matches[matches_count++].dist = delta3 - 1;
+			delta2 = delta3;
+		}
 
-	if (matches_count != 0) {
-		for ( ; len_best != len_limit; ++len_best)
-			if (*(cur + len_best - delta2) != cur[len_best])
-				break;
+		if (matches_count != 0) {
+			for ( ; len_best != len_limit; ++len_best)
+				if (*(cur + len_best - delta2) != cur[len_best])
+					break;
 
-		matches[matches_count - 1].len = len_best;
+			matches[matches_count - 1].len = len_best;
 
-		if (len_best == len_limit) {
-			bt_skip();
-			return matches_count;
+			if (len_best == len_limit) {
+				bt_skip();
+				return matches_count;
+			}
 		}
-	}
 
-	if (len_best < 3)
-		len_best = 3;
+		if (len_best < 3)
+			len_best = 3;
 
-	bt_find(len_best);
+		bt_find(len_best);
+	}
 }
 
 
 extern void
 lzma_mf_bt4_skip(lzma_mf *mf, uint32_t amount)
 {
+	uint32_t cur_match;
+	
 	do {
 		header_skip(true, 4);
 
-		hash_4_calc();
-
-		const uint32_t cur_match
-				= mf->hash[FIX_4_HASH_SIZE + hash_value];
+		{
+			hash_4_calc();
 
-		mf->hash[hash_2_value] = pos;
-		mf->hash[FIX_3_HASH_SIZE + hash_3_value] = pos;
-		mf->hash[FIX_4_HASH_SIZE + hash_value] = pos;
+			cur_match = mf->hash[FIX_4_HASH_SIZE + hash_value];
 
-		bt_skip();
+			mf->hash[hash_2_value] = pos;
+			mf->hash[FIX_3_HASH_SIZE + hash_3_value] = pos;
+			mf->hash[FIX_4_HASH_SIZE + hash_value] = pos;
 
+			bt_skip();
+		}
 	} while (--amount != 0);
 }
 #endif
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lzma/fastpos.h src/liblzma/lzma/fastpos.h
--- ..\..\Library\xz-5.0.5\src/liblzma/lzma/fastpos.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lzma/fastpos.h	2013-12-01 16:46:51.517052600 +0100
@@ -78,7 +78,7 @@
 #ifdef HAVE_SMALL
 #	define get_pos_slot(pos) ((pos) <= 4 ? (pos) : get_pos_slot_2(pos))
 
-static inline uint32_t
+static __inline uint32_t
 get_pos_slot_2(uint32_t pos)
 {
 	const uint32_t i = bsr32(pos);
@@ -104,7 +104,7 @@
 			+ 2 * fastpos_shift(extra, n)
 
 
-static inline uint32_t
+static __inline uint32_t
 get_pos_slot(uint32_t pos)
 {
 	// If it is small enough, we can pick the result directly from
@@ -120,7 +120,7 @@
 
 
 #ifdef FULL_DISTANCES_BITS
-static inline uint32_t
+static __inline uint32_t
 get_pos_slot_2(uint32_t pos)
 {
 	assert(pos >= FULL_DISTANCES);
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_common.h src/liblzma/lzma/lzma_common.h
--- ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_common.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lzma/lzma_common.h	2014-05-03 17:52:13.902658600 +0200
@@ -29,7 +29,7 @@
 
 
 /// Validates lc, lp, and pb.
-static inline bool
+static __inline bool
 is_lclppb_valid(const lzma_options_lzma *options)
 {
 	return options->lc <= LZMA_LCLP_MAX && options->lp <= LZMA_LCLP_MAX
@@ -125,16 +125,20 @@
 	((probs)[(((pos) & lp_mask) << lc) + ((prev_byte) >> (8 - lc))])
 
 
-static inline void
+static __inline void
 literal_init(probability (*probs)[LITERAL_CODER_SIZE],
 		uint32_t lc, uint32_t lp)
 {
+	uint32_t coders;
+	uint32_t i;
+	uint32_t j;
+	
 	assert(lc + lp <= LZMA_LCLP_MAX);
 
-	const uint32_t coders = 1U << (lc + lp);
+	coders = 1U << (lc + lp);
 
-	for (uint32_t i = 0; i < coders; ++i)
-		for (uint32_t j = 0; j < LITERAL_CODER_SIZE; ++j)
+	for (i = 0; i < coders; ++i)
+		for (j = 0; j < LITERAL_CODER_SIZE; ++j)
 			bit_reset(probs[i][j]);
 
 	return;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_decoder.c src/liblzma/lzma/lzma_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lzma/lzma_decoder.c	2014-05-04 09:51:59.784102000 +0200
@@ -281,10 +281,47 @@
 
 
 static lzma_ret
-lzma_decode(lzma_coder *restrict coder, lzma_dict *restrict dictptr,
-		const uint8_t *restrict in,
-		size_t *restrict in_pos, size_t in_size)
-{
+lzma_decode(struct lzma_coder_s * coder, lzma_dict * dictptr,
+		const uint8_t * in,
+		size_t * in_pos, size_t in_size)
+{
+	static const lzma_lzma_state next_state[] = {
+		STATE_LIT_LIT,
+		STATE_LIT_LIT,
+		STATE_LIT_LIT,
+		STATE_LIT_LIT,
+		STATE_MATCH_LIT_LIT,
+		STATE_REP_LIT_LIT,
+		STATE_SHORTREP_LIT_LIT,
+		STATE_MATCH_LIT,
+		STATE_REP_LIT,
+		STATE_SHORTREP_LIT,
+		STATE_MATCH_LIT,
+		STATE_REP_LIT
+	};
+	lzma_dict dict;
+	size_t dict_start;
+	uint32_t state;
+	uint32_t rep0;
+	uint32_t rep1;
+	uint32_t rep2;
+	uint32_t rep3;
+	uint32_t pos_mask;
+	probability *probs;
+	uint32_t symbol;
+	uint32_t limit;
+	uint32_t offset;
+	uint32_t len;
+	uint32_t literal_pos_mask;
+	uint32_t literal_context_bits;
+	uint32_t pos_state;
+	uint32_t match_bit;
+	uint32_t subcoder_index;
+	lzma_ret ret;
+	bool no_eopm;
+	// Range decoder
+	rc_to_local_types(coder->rc, *in_pos);
+
 	////////////////////
 	// Initialization //
 	////////////////////
@@ -299,41 +336,40 @@
 	// Making local copies of often-used variables improves both
 	// speed and readability.
 
-	lzma_dict dict = *dictptr;
-
-	const size_t dict_start = dict.pos;
+	dict = *dictptr;
 
-	// Range decoder
-	rc_to_local(coder->rc, *in_pos);
+	dict_start = dict.pos;
 
+	rc_to_local_assign(coder->rc, *in_pos);
+	
 	// State
-	uint32_t state = coder->state;
-	uint32_t rep0 = coder->rep0;
-	uint32_t rep1 = coder->rep1;
-	uint32_t rep2 = coder->rep2;
-	uint32_t rep3 = coder->rep3;
+	state = coder->state;
+	rep0 = coder->rep0;
+	rep1 = coder->rep1;
+	rep2 = coder->rep2;
+	rep3 = coder->rep3;
 
-	const uint32_t pos_mask = coder->pos_mask;
+	pos_mask = coder->pos_mask;
 
 	// These variables are actually needed only if we last time ran
 	// out of input in the middle of the decoder loop.
-	probability *probs = coder->probs;
-	uint32_t symbol = coder->symbol;
-	uint32_t limit = coder->limit;
-	uint32_t offset = coder->offset;
-	uint32_t len = coder->len;
+	probs = coder->probs;
+	symbol = coder->symbol;
+	limit = coder->limit;
+	offset = coder->offset;
+	len = coder->len;
 
-	const uint32_t literal_pos_mask = coder->literal_pos_mask;
-	const uint32_t literal_context_bits = coder->literal_context_bits;
+	literal_pos_mask = coder->literal_pos_mask;
+	literal_context_bits = coder->literal_context_bits;
 
 	// Temporary variables
-	uint32_t pos_state = dict.pos & pos_mask;
+	pos_state = dict.pos & pos_mask;
 
-	lzma_ret ret = LZMA_OK;
+	ret = LZMA_OK;
 
 	// If uncompressed size is known, there must be no end of payload
 	// marker.
-	const bool no_eopm = coder->uncompressed_size
+	no_eopm = coder->uncompressed_size
 			!= LZMA_VLI_UNKNOWN;
 	if (no_eopm && coder->uncompressed_size < dict.limit - dict.pos)
 		dict.limit = dict.pos + (size_t)(coder->uncompressed_size);
@@ -397,11 +433,8 @@
 #ifdef HAVE_SMALL
 	case SEQ_LITERAL_MATCHED:
 				do {
-					const uint32_t match_bit
-							= len & offset;
-					const uint32_t subcoder_index
-							= offset + match_bit
-							+ symbol;
+					match_bit = len & offset;
+					subcoder_index = offset + match_bit + symbol;
 
 					rc_bit(probs[subcoder_index],
 							offset &= ~match_bit,
@@ -418,8 +451,6 @@
 				} while (symbol < (1 << 8));
 #else
 				// Unroll the loop.
-				uint32_t match_bit;
-				uint32_t subcoder_index;
 
 #	define d(seq) \
 		case seq: \
@@ -453,20 +484,6 @@
 			// Use a lookup table to update to literal state,
 			// since compared to other state updates, this would
 			// need two branches.
-			static const lzma_lzma_state next_state[] = {
-				STATE_LIT_LIT,
-				STATE_LIT_LIT,
-				STATE_LIT_LIT,
-				STATE_LIT_LIT,
-				STATE_MATCH_LIT_LIT,
-				STATE_REP_LIT_LIT,
-				STATE_SHORTREP_LIT_LIT,
-				STATE_MATCH_LIT,
-				STATE_REP_LIT,
-				STATE_SHORTREP_LIT,
-				STATE_MATCH_LIT,
-				STATE_REP_LIT
-			};
 			state = next_state[state];
 
 	case SEQ_LITERAL_WRITE:
@@ -725,9 +742,11 @@
 				// is stored to rep0 and rep1, rep2 and rep3
 				// are updated accordingly.
 				rc_if_0(coder->is_rep1[state], SEQ_IS_REP1) {
+					uint32_t distance;
+					
 					rc_update_0(coder->is_rep1[state]);
 
-					const uint32_t distance = rep1;
+					distance = rep1;
 					rep1 = rep0;
 					rep0 = distance;
 
@@ -736,19 +755,23 @@
 	case SEQ_IS_REP2:
 					rc_if_0(coder->is_rep2[state],
 							SEQ_IS_REP2) {
+						uint32_t distance;
+						
 						rc_update_0(coder->is_rep2[
 								state]);
 
-						const uint32_t distance = rep2;
+						distance = rep2;
 						rep2 = rep1;
 						rep1 = rep0;
 						rep0 = distance;
 
 					} else {
+						uint32_t distance;
+						
 						rc_update_1(coder->is_rep2[
 								state]);
 
-						const uint32_t distance = rep3;
+						distance = rep3;
 						rep3 = rep2;
 						rep2 = rep1;
 						rep1 = rep0;
@@ -836,7 +859,7 @@
 
 
 static void
-lzma_decoder_uncompressed(lzma_coder *coder, lzma_vli uncompressed_size)
+lzma_decoder_uncompressed(struct lzma_coder_s *coder, lzma_vli uncompressed_size)
 {
 	coder->uncompressed_size = uncompressed_size;
 }
@@ -846,15 +869,19 @@
 lzma_lzma_decoder_uncompressed(void *coder_ptr, lzma_vli uncompressed_size)
 {
 	// This is hack.
-	(*(lzma_coder **)(coder))->uncompressed_size = uncompressed_size;
+	(*(struct lzma_coder_s **)(coder))->uncompressed_size = uncompressed_size;
 }
 */
 
 static void
-lzma_decoder_reset(lzma_coder *coder, const void *opt)
+lzma_decoder_reset(struct lzma_coder_s *coder, const void *opt)
 {
 	const lzma_options_lzma *options = opt;
-
+	uint32_t i;
+	uint32_t j; 
+	uint32_t num_pos_states;
+	uint32_t pos_state;
+	
 	// NOTE: We assume that lc/lp/pb are valid since they were
 	// successfully decoded with lzma_lzma_decode_properties().
 
@@ -879,8 +906,8 @@
 	rc_reset(coder->rc);
 
 	// Bit and bittree decoders
-	for (uint32_t i = 0; i < STATES; ++i) {
-		for (uint32_t j = 0; j <= coder->pos_mask; ++j) {
+	for (i = 0; i < STATES; ++i) {
+		for (j = 0; j <= coder->pos_mask; ++j) {
 			bit_reset(coder->is_match[i][j]);
 			bit_reset(coder->is_rep0_long[i][j]);
 		}
@@ -891,22 +918,22 @@
 		bit_reset(coder->is_rep2[i]);
 	}
 
-	for (uint32_t i = 0; i < LEN_TO_POS_STATES; ++i)
+	for (i = 0; i < LEN_TO_POS_STATES; ++i)
 		bittree_reset(coder->pos_slot[i], POS_SLOT_BITS);
 
-	for (uint32_t i = 0; i < FULL_DISTANCES - END_POS_MODEL_INDEX; ++i)
+	for (i = 0; i < FULL_DISTANCES - END_POS_MODEL_INDEX; ++i)
 		bit_reset(coder->pos_special[i]);
 
 	bittree_reset(coder->pos_align, ALIGN_BITS);
 
 	// Len decoders (also bit/bittree)
-	const uint32_t num_pos_states = 1U << options->pb;
+	num_pos_states = 1U << options->pb;
 	bit_reset(coder->match_len_decoder.choice);
 	bit_reset(coder->match_len_decoder.choice2);
 	bit_reset(coder->rep_len_decoder.choice);
 	bit_reset(coder->rep_len_decoder.choice2);
 
-	for (uint32_t pos_state = 0; pos_state < num_pos_states; ++pos_state) {
+	for (pos_state = 0; pos_state < num_pos_states; ++pos_state) {
 		bittree_reset(coder->match_len_decoder.low[pos_state],
 				LEN_LOW_BITS);
 		bittree_reset(coder->match_len_decoder.mid[pos_state],
@@ -936,8 +963,10 @@
 lzma_lzma_decoder_create(lzma_lz_decoder *lz, lzma_allocator *allocator,
 		const void *opt, lzma_lz_options *lz_options)
 {
+	lzma_options_lzma *options;
+	
 	if (lz->coder == NULL) {
-		lz->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lz->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (lz->coder == NULL)
 			return LZMA_MEM_ERROR;
 
@@ -948,7 +977,7 @@
 
 	// All dictionary sizes are OK here. LZ decoder will take care of
 	// the special cases.
-	const lzma_options_lzma *options = opt;
+	options = opt;
 	lz_options->dict_size = options->dict_size;
 	lz_options->preset_dict = options->preset_dict;
 	lz_options->preset_dict_size = options->preset_dict_size;
@@ -1010,7 +1039,7 @@
 lzma_lzma_decoder_memusage_nocheck(const void *options)
 {
 	const lzma_options_lzma *const opt = options;
-	return sizeof(lzma_coder) + lzma_lz_decoder_memusage(opt->dict_size);
+	return sizeof(struct lzma_coder_s) + lzma_lz_decoder_memusage(opt->dict_size);
 }
 
 
@@ -1028,11 +1057,12 @@
 lzma_lzma_props_decode(void **options, lzma_allocator *allocator,
 		const uint8_t *props, size_t props_size)
 {
+	lzma_options_lzma *opt;
+
 	if (props_size != 5)
 		return LZMA_OPTIONS_ERROR;
 
-	lzma_options_lzma *opt
-			= lzma_alloc(sizeof(lzma_options_lzma), allocator);
+	opt = lzma_alloc(sizeof(lzma_options_lzma), allocator);
 	if (opt == NULL)
 		return LZMA_MEM_ERROR;
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_encoder.c src/liblzma/lzma/lzma_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lzma/lzma_encoder.c	2014-05-03 18:31:12.416031600 +0200
@@ -20,19 +20,22 @@
 // Literal //
 /////////////
 
-static inline void
+static __inline void
 literal_matched(lzma_range_encoder *rc, probability *subcoder,
 		uint32_t match_byte, uint32_t symbol)
 {
 	uint32_t offset = 0x100;
+	uint32_t match_bit;
+	uint32_t subcoder_index;
+	uint32_t bit;
+	
 	symbol += UINT32_C(1) << 8;
 
 	do {
 		match_byte <<= 1;
-		const uint32_t match_bit = match_byte & offset;
-		const uint32_t subcoder_index
-				= offset + match_bit + (symbol >> 8);
-		const uint32_t bit = (symbol >> 7) & 1;
+		match_bit = match_byte & offset;
+		subcoder_index = offset + match_bit + (symbol >> 8);
+		bit = (symbol >> 7) & 1;
 		rc_bit(rc, &subcoder[subcoder_index], bit);
 
 		symbol <<= 1;
@@ -42,8 +45,8 @@
 }
 
 
-static inline void
-literal(lzma_coder *coder, lzma_mf *mf, uint32_t position)
+static __inline void
+literal(struct lzma_coder_s *coder, lzma_mf *mf, uint32_t position)
 {
 	// Locate the literal byte to be encoded and the subcoder.
 	const uint8_t cur_byte = mf->buffer[
@@ -78,15 +81,21 @@
 length_update_prices(lzma_length_encoder *lc, const uint32_t pos_state)
 {
 	const uint32_t table_size = lc->table_size;
+	uint32_t a0;
+	uint32_t a1;
+	uint32_t b0;
+	uint32_t b1;
+	uint32_t *prices;
+	uint32_t i;
+	
 	lc->counters[pos_state] = table_size;
 
-	const uint32_t a0 = rc_bit_0_price(lc->choice);
-	const uint32_t a1 = rc_bit_1_price(lc->choice);
-	const uint32_t b0 = a1 + rc_bit_0_price(lc->choice2);
-	const uint32_t b1 = a1 + rc_bit_1_price(lc->choice2);
-	uint32_t *const prices = lc->prices[pos_state];
+	a0 = rc_bit_0_price(lc->choice);
+	a1 = rc_bit_1_price(lc->choice);
+	b0 = a1 + rc_bit_0_price(lc->choice2);
+	b1 = a1 + rc_bit_1_price(lc->choice2);
+	prices = lc->prices[pos_state];
 
-	uint32_t i;
 	for (i = 0; i < table_size && i < LEN_LOW_SYMBOLS; ++i)
 		prices[i] = a0 + rc_bittree_price(lc->low[pos_state],
 				LEN_LOW_BITS, i);
@@ -103,7 +112,7 @@
 }
 
 
-static inline void
+static __inline void
 length(lzma_range_encoder *rc, lzma_length_encoder *lc,
 		const uint32_t pos_state, uint32_t len, const bool fast_mode)
 {
@@ -139,17 +148,20 @@
 // Match //
 ///////////
 
-static inline void
-match(lzma_coder *coder, const uint32_t pos_state,
+static __inline void
+match(struct lzma_coder_s *coder, const uint32_t pos_state,
 		const uint32_t distance, const uint32_t len)
 {
+	uint32_t pos_slot;
+	uint32_t len_to_pos_state;
+	
 	update_match(coder->state);
 
 	length(&coder->rc, &coder->match_len_encoder, pos_state, len,
 			coder->fast_mode);
 
-	const uint32_t pos_slot = get_pos_slot(distance);
-	const uint32_t len_to_pos_state = get_len_to_pos_state(len);
+	pos_slot = get_pos_slot(distance);
+	len_to_pos_state = get_len_to_pos_state(len);
 	rc_bittree(&coder->rc, coder->pos_slot[len_to_pos_state],
 			POS_SLOT_BITS, pos_slot);
 
@@ -186,8 +198,8 @@
 // Repeated match //
 ////////////////////
 
-static inline void
-rep_match(lzma_coder *coder, const uint32_t pos_state,
+static __inline void
+rep_match(struct lzma_coder_s *coder, const uint32_t pos_state,
 		const uint32_t rep, const uint32_t len)
 {
 	if (rep == 0) {
@@ -231,7 +243,7 @@
 //////////
 
 static void
-encode_symbol(lzma_coder *coder, lzma_mf *mf,
+encode_symbol(struct lzma_coder_s *coder, lzma_mf *mf,
 		uint32_t back, uint32_t len, uint32_t position)
 {
 	const uint32_t pos_state = position & coder->pos_mask;
@@ -265,7 +277,7 @@
 
 
 static bool
-encode_init(lzma_coder *coder, lzma_mf *mf)
+encode_init(struct lzma_coder_s *coder, lzma_mf *mf)
 {
 	assert(mf_position(mf) == 0);
 
@@ -293,7 +305,7 @@
 
 
 static void
-encode_eopm(lzma_coder *coder, uint32_t position)
+encode_eopm(struct lzma_coder_s *coder, uint32_t position)
 {
 	const uint32_t pos_state = position & coder->pos_mask;
 	rc_bit(&coder->rc, &coder->is_match[coder->state][pos_state], 1);
@@ -309,18 +321,23 @@
 
 
 extern lzma_ret
-lzma_lzma_encode(lzma_coder *restrict coder, lzma_mf *restrict mf,
-		uint8_t *restrict out, size_t *restrict out_pos,
+lzma_lzma_encode(struct lzma_coder_s * coder, lzma_mf * mf,
+		uint8_t * out, size_t * out_pos,
 		size_t out_size, uint32_t limit)
 {
+	uint32_t position;
+
 	// Initialize the stream if no data has been encoded yet.
 	if (!coder->is_initialized && !encode_init(coder, mf))
 		return LZMA_OK;
 
 	// Get the lowest bits of the uncompressed offset from the LZ layer.
-	uint32_t position = mf_position(mf);
+	position = mf_position(mf);
 
 	while (true) {
+		uint32_t len;
+		uint32_t back;
+		
 		// Encode pending bits, if any. Calling this before encoding
 		// the next symbol is needed only with plain LZMA, since
 		// LZMA2 always provides big enough buffer to flush
@@ -359,8 +376,6 @@
 		//   - UINT32_MAX: not a match but a literal
 		// Value ranges for len:
 		//   - [MATCH_LEN_MIN, MATCH_LEN_MAX]
-		uint32_t len;
-		uint32_t back;
 
 		if (coder->fast_mode)
 			lzma_lzma_optimum_fast(coder, mf, &back, &len);
@@ -402,8 +417,8 @@
 
 
 static lzma_ret
-lzma_encode(lzma_coder *restrict coder, lzma_mf *restrict mf,
-		uint8_t *restrict out, size_t *restrict out_pos,
+lzma_encode(struct lzma_coder_s * coder, lzma_mf * mf,
+		uint8_t * out, size_t * out_pos,
 		size_t out_size)
 {
 	// Plain LZMA has no support for sync-flushing.
@@ -453,10 +468,12 @@
 length_encoder_reset(lzma_length_encoder *lencoder,
 		const uint32_t num_pos_states, const bool fast_mode)
 {
+	size_t pos_state;
+
 	bit_reset(lencoder->choice);
 	bit_reset(lencoder->choice2);
 
-	for (size_t pos_state = 0; pos_state < num_pos_states; ++pos_state) {
+	for (pos_state = 0; pos_state < num_pos_states; ++pos_state) {
 		bittree_reset(lencoder->low[pos_state], LEN_LOW_BITS);
 		bittree_reset(lencoder->mid[pos_state], LEN_MID_BITS);
 	}
@@ -464,7 +481,7 @@
 	bittree_reset(lencoder->high, LEN_HIGH_BITS);
 
 	if (!fast_mode)
-		for (size_t pos_state = 0; pos_state < num_pos_states;
+		for (pos_state = 0; pos_state < num_pos_states;
 				++pos_state)
 			length_update_prices(lencoder, pos_state);
 
@@ -473,8 +490,11 @@
 
 
 extern lzma_ret
-lzma_lzma_encoder_reset(lzma_coder *coder, const lzma_options_lzma *options)
+lzma_lzma_encoder_reset(struct lzma_coder_s *coder, const lzma_options_lzma *options)
 {
+	size_t i;
+	size_t j;
+	
 	if (!is_options_valid(options))
 		return LZMA_OPTIONS_ERROR;
 
@@ -487,14 +507,14 @@
 
 	// State
 	coder->state = STATE_LIT_LIT;
-	for (size_t i = 0; i < REP_DISTANCES; ++i)
+	for (i = 0; i < REP_DISTANCES; ++i)
 		coder->reps[i] = 0;
 
 	literal_init(coder->literal, options->lc, options->lp);
 
 	// Bit encoders
-	for (size_t i = 0; i < STATES; ++i) {
-		for (size_t j = 0; j <= coder->pos_mask; ++j) {
+	for (i = 0; i < STATES; ++i) {
+		for (j = 0; j <= coder->pos_mask; ++j) {
 			bit_reset(coder->is_match[i][j]);
 			bit_reset(coder->is_rep0_long[i][j]);
 		}
@@ -505,11 +525,11 @@
 		bit_reset(coder->is_rep2[i]);
 	}
 
-	for (size_t i = 0; i < FULL_DISTANCES - END_POS_MODEL_INDEX; ++i)
+	for (i = 0; i < FULL_DISTANCES - END_POS_MODEL_INDEX; ++i)
 		bit_reset(coder->pos_special[i]);
 
 	// Bit tree encoders
-	for (size_t i = 0; i < LEN_TO_POS_STATES; ++i)
+	for (i = 0; i < LEN_TO_POS_STATES; ++i)
 		bittree_reset(coder->pos_slot[i], POS_SLOT_BITS);
 
 	bittree_reset(coder->pos_align, ALIGN_BITS);
@@ -545,17 +565,19 @@
 
 
 extern lzma_ret
-lzma_lzma_encoder_create(lzma_coder **coder_ptr, lzma_allocator *allocator,
+lzma_lzma_encoder_create(struct lzma_coder_s **coder_ptr, lzma_allocator *allocator,
 		const lzma_options_lzma *options, lzma_lz_options *lz_options)
 {
-	// Allocate lzma_coder if it wasn't already allocated.
+	struct lzma_coder_s *coder;
+	
+	// Allocate struct lzma_coder_s if it wasn't already allocated.
 	if (*coder_ptr == NULL) {
-		*coder_ptr = lzma_alloc(sizeof(lzma_coder), allocator);
+		*coder_ptr = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (*coder_ptr == NULL)
 			return LZMA_MEM_ERROR;
 	}
 
-	lzma_coder *coder = *coder_ptr;
+	coder = *coder_ptr;
 
 	// Set compression mode. We haven't validates the options yet,
 	// but it's OK here, since nothing bad happens with invalid
@@ -567,11 +589,12 @@
 			break;
 
 		case LZMA_MODE_NORMAL: {
+			uint32_t log_size = 0;
+			
 			coder->fast_mode = false;
 
 			// Set dist_table_size.
 			// Round the dictionary size up to next 2^n.
-			uint32_t log_size = 0;
 			while ((UINT32_C(1) << log_size) < options->dict_size)
 				++log_size;
 
@@ -625,17 +648,19 @@
 extern uint64_t
 lzma_lzma_encoder_memusage(const void *options)
 {
+	lzma_lz_options lz_options;
+	uint64_t lz_memusage;
+	
 	if (!is_options_valid(options))
 		return UINT64_MAX;
 
-	lzma_lz_options lz_options;
 	set_lz_options(&lz_options, options);
 
-	const uint64_t lz_memusage = lzma_lz_encoder_memusage(&lz_options);
+	lz_memusage = lzma_lz_encoder_memusage(&lz_options);
 	if (lz_memusage == UINT64_MAX)
 		return UINT64_MAX;
 
-	return (uint64_t)(sizeof(lzma_coder)) + lz_memusage;
+	return (uint64_t)(sizeof(struct lzma_coder_s)) + lz_memusage;
 }
 
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_encoder.h src/liblzma/lzma/lzma_encoder.h
--- ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_encoder.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lzma/lzma_encoder.h	2013-12-01 16:43:19.209125900 +0100
@@ -35,18 +35,18 @@
 
 /// Initializes raw LZMA encoder; this is used by LZMA2.
 extern lzma_ret lzma_lzma_encoder_create(
-		lzma_coder **coder_ptr, lzma_allocator *allocator,
+		struct lzma_coder_s **coder_ptr, lzma_allocator *allocator,
 		const lzma_options_lzma *options, lzma_lz_options *lz_options);
 
 
 /// Resets an already initialized LZMA encoder; this is used by LZMA2.
 extern lzma_ret lzma_lzma_encoder_reset(
-		lzma_coder *coder, const lzma_options_lzma *options);
+		struct lzma_coder_s *coder, const lzma_options_lzma *options);
 
 
-extern lzma_ret lzma_lzma_encode(lzma_coder *restrict coder,
-		lzma_mf *restrict mf, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size,
+extern lzma_ret lzma_lzma_encode(struct lzma_coder_s * coder,
+		lzma_mf * mf, uint8_t * out,
+		size_t * out_pos, size_t out_size,
 		uint32_t read_limit);
 
 #endif
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_encoder_optimum_fast.c src/liblzma/lzma/lzma_encoder_optimum_fast.c
--- ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_encoder_optimum_fast.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lzma/lzma_encoder_optimum_fast.c	2014-05-03 18:35:12.803169300 +0200
@@ -17,13 +17,20 @@
 
 
 extern void
-lzma_lzma_optimum_fast(lzma_coder *restrict coder, lzma_mf *restrict mf,
-		uint32_t *restrict back_res, uint32_t *restrict len_res)
+lzma_lzma_optimum_fast(struct lzma_coder_s * coder, lzma_mf * mf,
+		uint32_t * back_res, uint32_t * len_res)
 {
 	const uint32_t nice_len = mf->nice_len;
-
 	uint32_t len_main;
 	uint32_t matches_count;
+	uint8_t *buf;
+	uint32_t buf_avail;
+	uint32_t rep_len = 0;
+	uint32_t rep_index = 0;
+	uint32_t i;
+	uint32_t back_main = 0;
+	uint32_t limit;	
+	
 	if (mf->read_ahead == 0) {
 		len_main = mf_find(mf, &matches_count, coder->matches);
 	} else {
@@ -32,8 +39,8 @@
 		matches_count = coder->matches_count;
 	}
 
-	const uint8_t *buf = mf_ptr(mf) - 1;
-	const uint32_t buf_avail = my_min(mf_avail(mf) + 1, MATCH_LEN_MAX);
+	buf = mf_ptr(mf) - 1;
+	buf_avail = my_min(mf_avail(mf) + 1, MATCH_LEN_MAX);
 
 	if (buf_avail < 2) {
 		// There's not enough input left to encode a match.
@@ -43,12 +50,11 @@
 	}
 
 	// Look for repeated matches; scan the previous four match distances
-	uint32_t rep_len = 0;
-	uint32_t rep_index = 0;
 
-	for (uint32_t i = 0; i < REP_DISTANCES; ++i) {
+	for (i = 0; i < REP_DISTANCES; ++i) {
 		// Pointer to the beginning of the match candidate
 		const uint8_t *const buf_back = buf - coder->reps[i] - 1;
+		uint32_t len;
 
 		// If the first two bytes (2 == MATCH_LEN_MIN) do not match,
 		// this rep is not useful.
@@ -57,7 +63,6 @@
 
 		// The first two bytes matched.
 		// Calculate the length of the match.
-		uint32_t len;
 		for (len = 2; len < buf_avail
 				&& buf[len] == buf_back[len]; ++len) ;
 
@@ -86,7 +91,6 @@
 		return;
 	}
 
-	uint32_t back_main = 0;
 	if (len_main >= 2) {
 		back_main = coder->matches[matches_count - 1].dist;
 
@@ -153,15 +157,15 @@
 	// the old buf pointer instead of recalculating it with mf_ptr().
 	++buf;
 
-	const uint32_t limit = len_main - 1;
+	limit = len_main - 1;
 
-	for (uint32_t i = 0; i < REP_DISTANCES; ++i) {
+	for (i = 0; i < REP_DISTANCES; ++i) {
 		const uint8_t *const buf_back = buf - coder->reps[i] - 1;
+		uint32_t len;
 
 		if (not_equal_16(buf, buf_back))
 			continue;
 
-		uint32_t len;
 		for (len = 2; len < limit
 				&& buf[len] == buf_back[len]; ++len) ;
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_encoder_optimum_normal.c src/liblzma/lzma/lzma_encoder_optimum_normal.c
--- ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_encoder_optimum_normal.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lzma/lzma_encoder_optimum_normal.c	2014-05-03 19:08:42.345045400 +0200
@@ -18,7 +18,7 @@
 ////////////
 
 static uint32_t
-get_literal_price(const lzma_coder *const coder, const uint32_t pos,
+get_literal_price(const struct lzma_coder_s *const coder, const uint32_t pos,
 		const uint32_t prev_byte, const bool match_mode,
 		uint32_t match_byte, uint32_t symbol)
 {
@@ -35,12 +35,15 @@
 		symbol += UINT32_C(1) << 8;
 
 		do {
+			uint32_t match_bit;
+			uint32_t subcoder_index;
+			uint32_t bit;
+			
 			match_byte <<= 1;
 
-			const uint32_t match_bit = match_byte & offset;
-			const uint32_t subcoder_index
-					= offset + match_bit + (symbol >> 8);
-			const uint32_t bit = (symbol >> 7) & 1;
+			match_bit = match_byte & offset;
+			subcoder_index = offset + match_bit + (symbol >> 8);
+			bit = (symbol >> 7) & 1;
 			price += rc_bit_price(subcoder[subcoder_index], bit);
 
 			symbol <<= 1;
@@ -53,7 +56,7 @@
 }
 
 
-static inline uint32_t
+static __inline uint32_t
 get_len_price(const lzma_length_encoder *const lencoder,
 		const uint32_t len, const uint32_t pos_state)
 {
@@ -63,8 +66,8 @@
 }
 
 
-static inline uint32_t
-get_short_rep_price(const lzma_coder *const coder,
+static __inline uint32_t
+get_short_rep_price(const struct lzma_coder_s *const coder,
 		const lzma_lzma_state state, const uint32_t pos_state)
 {
 	return rc_bit_0_price(coder->is_rep0[state])
@@ -72,8 +75,8 @@
 }
 
 
-static inline uint32_t
-get_pure_rep_price(const lzma_coder *const coder, const uint32_t rep_index,
+static __inline uint32_t
+get_pure_rep_price(const struct lzma_coder_s *const coder, const uint32_t rep_index,
 		const lzma_lzma_state state, uint32_t pos_state)
 {
 	uint32_t price;
@@ -97,8 +100,8 @@
 }
 
 
-static inline uint32_t
-get_rep_price(const lzma_coder *const coder, const uint32_t rep_index,
+static __inline uint32_t
+get_rep_price(const struct lzma_coder_s *const coder, const uint32_t rep_index,
 		const uint32_t len, const lzma_lzma_state state,
 		const uint32_t pos_state)
 {
@@ -107,8 +110,8 @@
 }
 
 
-static inline uint32_t
-get_pos_len_price(const lzma_coder *const coder, const uint32_t pos,
+static __inline uint32_t
+get_pos_len_price(const struct lzma_coder_s *const coder, const uint32_t pos,
 		const uint32_t len, const uint32_t pos_state)
 {
 	const uint32_t len_to_pos_state = get_len_to_pos_state(len);
@@ -129,17 +132,21 @@
 
 
 static void
-fill_distances_prices(lzma_coder *coder)
+fill_distances_prices(struct lzma_coder_s *coder)
 {
-	for (uint32_t len_to_pos_state = 0;
+	uint32_t len_to_pos_state;
+	uint32_t i;
+	
+	for (len_to_pos_state = 0;
 			len_to_pos_state < LEN_TO_POS_STATES;
 			++len_to_pos_state) {
 
 		uint32_t *const pos_slot_prices
 				= coder->pos_slot_prices[len_to_pos_state];
-
+		uint32_t pos_slot;
+		
 		// Price to encode the pos_slot.
-		for (uint32_t pos_slot = 0;
+		for (pos_slot = 0;
 				pos_slot < coder->dist_table_size; ++pos_slot)
 			pos_slot_prices[pos_slot] = rc_bittree_price(
 					coder->pos_slot[len_to_pos_state],
@@ -148,7 +155,7 @@
 		// For matches with distance >= FULL_DISTANCES, add the price
 		// of the direct bits part of the match distance. (Align bits
 		// are handled by fill_align_prices()).
-		for (uint32_t pos_slot = END_POS_MODEL_INDEX;
+		for (pos_slot = END_POS_MODEL_INDEX;
 				pos_slot < coder->dist_table_size; ++pos_slot)
 			pos_slot_prices[pos_slot] += rc_direct_price(
 					((pos_slot >> 1) - 1) - ALIGN_BITS);
@@ -156,7 +163,7 @@
 		// Distances in the range [0, 3] are fully encoded with
 		// pos_slot, so they are used for coder->distances_prices
 		// as is.
-		for (uint32_t i = 0; i < START_POS_MODEL_INDEX; ++i)
+		for (i = 0; i < START_POS_MODEL_INDEX; ++i)
 			coder->distances_prices[len_to_pos_state][i]
 					= pos_slot_prices[i];
 	}
@@ -164,7 +171,7 @@
 	// Distances in the range [4, 127] depend on pos_slot and pos_special.
 	// We do this in a loop separate from the above loop to avoid
 	// redundant calls to get_pos_slot().
-	for (uint32_t i = START_POS_MODEL_INDEX; i < FULL_DISTANCES; ++i) {
+	for (i = START_POS_MODEL_INDEX; i < FULL_DISTANCES; ++i) {
 		const uint32_t pos_slot = get_pos_slot(i);
 		const uint32_t footer_bits = ((pos_slot >> 1) - 1);
 		const uint32_t base = (2 | (pos_slot & 1)) << footer_bits;
@@ -172,7 +179,7 @@
 				coder->pos_special + base - pos_slot - 1,
 				footer_bits, i - base);
 
-		for (uint32_t len_to_pos_state = 0;
+		for (len_to_pos_state = 0;
 				len_to_pos_state < LEN_TO_POS_STATES;
 				++len_to_pos_state)
 			coder->distances_prices[len_to_pos_state][i]
@@ -186,9 +193,11 @@
 
 
 static void
-fill_align_prices(lzma_coder *coder)
+fill_align_prices(struct lzma_coder_s *coder)
 {
-	for (uint32_t i = 0; i < ALIGN_TABLE_SIZE; ++i)
+	uint32_t i;
+	
+	for (i = 0; i < ALIGN_TABLE_SIZE; ++i)
 		coder->align_prices[i] = rc_bittree_reverse_price(
 				coder->pos_align, ALIGN_BITS, i);
 
@@ -201,7 +210,7 @@
 // Optimal //
 /////////////
 
-static inline void
+static __inline void
 make_literal(lzma_optimal *optimal)
 {
 	optimal->back_prev = UINT32_MAX;
@@ -209,7 +218,7 @@
 }
 
 
-static inline void
+static __inline void
 make_short_rep(lzma_optimal *optimal)
 {
 	optimal->back_prev = 0;
@@ -222,13 +231,18 @@
 
 
 static void
-backward(lzma_coder *restrict coder, uint32_t *restrict len_res,
-		uint32_t *restrict back_res, uint32_t cur)
+backward(struct lzma_coder_s * coder, uint32_t * len_res,
+		uint32_t * back_res, uint32_t cur)
 {
+	uint32_t pos_mem;
+	uint32_t back_mem;
+	uint32_t pos_prev;
+	uint32_t back_cur;
+	
 	coder->opts_end_index = cur;
 
-	uint32_t pos_mem = coder->opts[cur].pos_prev;
-	uint32_t back_mem = coder->opts[cur].back_prev;
+	pos_mem = coder->opts[cur].pos_prev;
+	back_mem = coder->opts[cur].back_prev;
 
 	do {
 		if (coder->opts[cur].prev_1_is_literal) {
@@ -245,8 +259,8 @@
 			}
 		}
 
-		const uint32_t pos_prev = pos_mem;
-		const uint32_t back_cur = back_mem;
+		pos_prev = pos_mem;
+		back_cur = back_mem;
 
 		back_mem = coder->opts[pos_prev].back_prev;
 		pos_mem = coder->opts[pos_prev].pos_prev;
@@ -269,16 +283,29 @@
 // Main //
 //////////
 
-static inline uint32_t
-helper1(lzma_coder *restrict coder, lzma_mf *restrict mf,
-		uint32_t *restrict back_res, uint32_t *restrict len_res,
+static __inline uint32_t
+helper1(struct lzma_coder_s * coder, lzma_mf * mf,
+		uint32_t * back_res, uint32_t * len_res,
 		uint32_t position)
 {
 	const uint32_t nice_len = mf->nice_len;
 
 	uint32_t len_main;
 	uint32_t matches_count;
-
+	uint32_t buf_avail;
+	uint8_t *buf;
+	uint32_t rep_lens[REP_DISTANCES];
+	uint32_t rep_max_index = 0;
+	uint32_t i;
+	uint8_t current_byte;
+	uint8_t match_byte;
+	uint32_t pos_state;
+	uint32_t match_price;
+	uint32_t rep_match_price;
+	uint32_t len_end;
+	uint32_t len;
+	uint32_t normal_match_price;
+	
 	if (mf->read_ahead == 0) {
 		len_main = mf_find(mf, &matches_count, coder->matches);
 	} else {
@@ -287,27 +314,24 @@
 		matches_count = coder->matches_count;
 	}
 
-	const uint32_t buf_avail = my_min(mf_avail(mf) + 1, MATCH_LEN_MAX);
+	buf_avail = my_min(mf_avail(mf) + 1, MATCH_LEN_MAX);
 	if (buf_avail < 2) {
 		*back_res = UINT32_MAX;
 		*len_res = 1;
 		return UINT32_MAX;
 	}
 
-	const uint8_t *const buf = mf_ptr(mf) - 1;
+	buf = mf_ptr(mf) - 1;
 
-	uint32_t rep_lens[REP_DISTANCES];
-	uint32_t rep_max_index = 0;
-
-	for (uint32_t i = 0; i < REP_DISTANCES; ++i) {
+	for (i = 0; i < REP_DISTANCES; ++i) {
 		const uint8_t *const buf_back = buf - coder->reps[i] - 1;
+		uint32_t len_test;
 
 		if (not_equal_16(buf, buf_back)) {
 			rep_lens[i] = 0;
 			continue;
 		}
 
-		uint32_t len_test;
 		for (len_test = 2; len_test < buf_avail
 				&& buf[len_test] == buf_back[len_test];
 				++len_test) ;
@@ -333,8 +357,8 @@
 		return UINT32_MAX;
 	}
 
-	const uint8_t current_byte = *buf;
-	const uint8_t match_byte = *(buf - coder->reps[0] - 1);
+	current_byte = *buf;
+	match_byte = *(buf - coder->reps[0] - 1);
 
 	if (len_main < 2 && current_byte != match_byte
 			&& rep_lens[rep_max_index] < 2) {
@@ -345,7 +369,7 @@
 
 	coder->opts[0].state = coder->state;
 
-	const uint32_t pos_state = position & coder->pos_mask;
+	pos_state = position & coder->pos_mask;
 
 	coder->opts[1].price = rc_bit_0_price(
 				coder->is_match[coder->state][pos_state])
@@ -355,9 +379,9 @@
 
 	make_literal(&coder->opts[1]);
 
-	const uint32_t match_price = rc_bit_1_price(
+	match_price = rc_bit_1_price(
 			coder->is_match[coder->state][pos_state]);
-	const uint32_t rep_match_price = match_price
+	rep_match_price = match_price
 			+ rc_bit_1_price(coder->is_rep[coder->state]);
 
 	if (match_byte == current_byte) {
@@ -371,7 +395,7 @@
 		}
 	}
 
-	const uint32_t len_end = my_max(len_main, rep_lens[rep_max_index]);
+	len_end = my_max(len_main, rep_lens[rep_max_index]);
 
 	if (len_end < 2) {
 		*back_res = coder->opts[1].back_prev;
@@ -381,21 +405,23 @@
 
 	coder->opts[1].pos_prev = 0;
 
-	for (uint32_t i = 0; i < REP_DISTANCES; ++i)
+	for (i = 0; i < REP_DISTANCES; ++i)
 		coder->opts[0].backs[i] = coder->reps[i];
 
-	uint32_t len = len_end;
+	len = len_end;
 	do {
 		coder->opts[len].price = RC_INFINITY_PRICE;
 	} while (--len >= 2);
 
 
-	for (uint32_t i = 0; i < REP_DISTANCES; ++i) {
+	for (i = 0; i < REP_DISTANCES; ++i) {
 		uint32_t rep_len = rep_lens[i];
+		uint32_t price;
+		
 		if (rep_len < 2)
 			continue;
 
-		const uint32_t price = rep_match_price + get_pure_rep_price(
+		price = rep_match_price + get_pure_rep_price(
 				coder, i, coder->state, pos_state);
 
 		do {
@@ -414,7 +440,7 @@
 	}
 
 
-	const uint32_t normal_match_price = match_price
+	normal_match_price = match_price
 			+ rc_bit_0_price(coder->is_rep[coder->state]);
 
 	len = rep_lens[0] >= 2 ? rep_lens[0] + 1 : 2;
@@ -447,8 +473,8 @@
 }
 
 
-static inline uint32_t
-helper2(lzma_coder *coder, uint32_t *reps, const uint8_t *buf,
+static __inline uint32_t
+helper2(struct lzma_coder_s *coder, uint32_t *reps, const uint8_t *buf,
 		uint32_t len_end, uint32_t position, const uint32_t cur,
 		const uint32_t nice_len, const uint32_t buf_avail_full)
 {
@@ -456,6 +482,18 @@
 	uint32_t new_len = coder->longest_match_length;
 	uint32_t pos_prev = coder->opts[cur].pos_prev;
 	lzma_lzma_state state;
+	uint32_t buf_avail;
+	uint32_t i;
+	uint32_t cur_price;
+	uint8_t current_byte;
+	uint8_t match_byte;
+	uint32_t pos_state;
+	uint32_t cur_and_1_price;
+	bool next_is_literal;
+	uint32_t match_price;
+	uint32_t rep_match_price;
+	uint32_t start_len;
+	uint32_t rep_index;
 
 	if (coder->opts[cur].prev_1_is_literal) {
 		--pos_prev;
@@ -485,6 +523,7 @@
 			update_literal(state);
 	} else {
 		uint32_t pos;
+		
 		if (coder->opts[cur].prev_1_is_literal
 				&& coder->opts[cur].prev_2) {
 			pos_prev = coder->opts[cur].pos_prev_2;
@@ -501,7 +540,6 @@
 		if (pos < REP_DISTANCES) {
 			reps[0] = coder->opts[pos_prev].backs[pos];
 
-			uint32_t i;
 			for (i = 1; i <= pos; ++i)
 				reps[i] = coder->opts[pos_prev].backs[i - 1];
 
@@ -511,29 +549,29 @@
 		} else {
 			reps[0] = pos - REP_DISTANCES;
 
-			for (uint32_t i = 1; i < REP_DISTANCES; ++i)
+			for (i = 1; i < REP_DISTANCES; ++i)
 				reps[i] = coder->opts[pos_prev].backs[i - 1];
 		}
 	}
 
 	coder->opts[cur].state = state;
 
-	for (uint32_t i = 0; i < REP_DISTANCES; ++i)
+	for (i = 0; i < REP_DISTANCES; ++i)
 		coder->opts[cur].backs[i] = reps[i];
+	
+	cur_price = coder->opts[cur].price;
 
-	const uint32_t cur_price = coder->opts[cur].price;
+	current_byte = *buf;
+	match_byte = *(buf - reps[0] - 1);
 
-	const uint8_t current_byte = *buf;
-	const uint8_t match_byte = *(buf - reps[0] - 1);
+	pos_state = position & coder->pos_mask;
 
-	const uint32_t pos_state = position & coder->pos_mask;
-
-	const uint32_t cur_and_1_price = cur_price
+	cur_and_1_price = cur_price
 			+ rc_bit_0_price(coder->is_match[state][pos_state])
 			+ get_literal_price(coder, position, buf[-1],
 			!is_literal_state(state), match_byte, current_byte);
 
-	bool next_is_literal = false;
+	next_is_literal = false;
 
 	if (cur_and_1_price < coder->opts[cur + 1].price) {
 		coder->opts[cur + 1].price = cur_and_1_price;
@@ -542,9 +580,9 @@
 		next_is_literal = true;
 	}
 
-	const uint32_t match_price = cur_price
+	match_price = cur_price
 			+ rc_bit_1_price(coder->is_match[state][pos_state]);
-	const uint32_t rep_match_price = match_price
+	rep_match_price = match_price
 			+ rc_bit_1_price(coder->is_rep[state]);
 
 	if (match_byte == current_byte
@@ -565,14 +603,14 @@
 	if (buf_avail_full < 2)
 		return len_end;
 
-	const uint32_t buf_avail = my_min(buf_avail_full, nice_len);
+	buf_avail = my_min(buf_avail_full, nice_len);
 
 	if (!next_is_literal && match_byte != current_byte) { // speed optimization
 		// try literal + rep0
 		const uint8_t *const buf_back = buf - reps[0] - 1;
 		const uint32_t limit = my_min(buf_avail_full, nice_len + 1);
-
 		uint32_t len_test = 1;
+		
 		while (len_test < limit && buf[len_test] == buf_back[len_test])
 			++len_test;
 
@@ -580,20 +618,25 @@
 
 		if (len_test >= 2) {
 			lzma_lzma_state state_2 = state;
+			uint32_t pos_state_next;
+			uint32_t next_rep_match_price;
+			uint32_t offset;
+			uint32_t cur_and_len_price;
+			
 			update_literal(state_2);
 
-			const uint32_t pos_state_next = (position + 1) & coder->pos_mask;
-			const uint32_t next_rep_match_price = cur_and_1_price
+			pos_state_next = (position + 1) & coder->pos_mask;
+			next_rep_match_price = cur_and_1_price
 					+ rc_bit_1_price(coder->is_match[state_2][pos_state_next])
 					+ rc_bit_1_price(coder->is_rep[state_2]);
 
 			//for (; len_test >= 2; --len_test) {
-			const uint32_t offset = cur + 1 + len_test;
+			offset = cur + 1 + len_test;
 
 			while (len_end < offset)
 				coder->opts[++len_end].price = RC_INFINITY_PRICE;
 
-			const uint32_t cur_and_len_price = next_rep_match_price
+			cur_and_len_price = next_rep_match_price
 					+ get_rep_price(coder, 0, len_test,
 						state_2, pos_state_next);
 
@@ -608,15 +651,19 @@
 		}
 	}
 
+	start_len = 2; // speed optimization
 
-	uint32_t start_len = 2; // speed optimization
-
-	for (uint32_t rep_index = 0; rep_index < REP_DISTANCES; ++rep_index) {
+	for (rep_index = 0; rep_index < REP_DISTANCES; ++rep_index) {
+		uint32_t len_test_2;
 		const uint8_t *const buf_back = buf - reps[rep_index] - 1;
+		uint32_t len_test;
+		uint32_t len_test_temp;
+		uint32_t price;
+		uint32_t limit;
+		
 		if (not_equal_16(buf, buf_back))
 			continue;
 
-		uint32_t len_test;
 		for (len_test = 2; len_test < buf_avail
 				&& buf[len_test] == buf_back[len_test];
 				++len_test) ;
@@ -624,8 +671,8 @@
 		while (len_end < cur + len_test)
 			coder->opts[++len_end].price = RC_INFINITY_PRICE;
 
-		const uint32_t len_test_temp = len_test;
-		const uint32_t price = rep_match_price + get_pure_rep_price(
+		len_test_temp = len_test;
+		price = rep_match_price + get_pure_rep_price(
 				coder, rep_index, state, pos_state);
 
 		do {
@@ -647,8 +694,8 @@
 			start_len = len_test + 1;
 
 
-		uint32_t len_test_2 = len_test + 1;
-		const uint32_t limit = my_min(buf_avail_full,
+		len_test_2 = len_test + 1;
+		limit = my_min(buf_avail_full,
 				len_test_2 + nice_len);
 		for (; len_test_2 < limit
 				&& buf[len_test_2] == buf_back[len_test_2];
@@ -658,11 +705,17 @@
 
 		if (len_test_2 >= 2) {
 			lzma_lzma_state state_2 = state;
+			uint32_t pos_state_next;
+			uint32_t cur_and_len_literal_price;
+			uint32_t next_rep_match_price;
+			uint32_t offset;
+			uint32_t cur_and_len_price;
+			
 			update_long_rep(state_2);
 
-			uint32_t pos_state_next = (position + len_test) & coder->pos_mask;
+			pos_state_next = (position + len_test) & coder->pos_mask;
 
-			const uint32_t cur_and_len_literal_price = price
+			cur_and_len_literal_price = price
 					+ get_len_price(&coder->rep_len_encoder,
 						len_test, pos_state)
 					+ rc_bit_0_price(coder->is_match[state_2][pos_state_next])
@@ -674,17 +727,17 @@
 
 			pos_state_next = (position + len_test + 1) & coder->pos_mask;
 
-			const uint32_t next_rep_match_price = cur_and_len_literal_price
+			next_rep_match_price = cur_and_len_literal_price
 					+ rc_bit_1_price(coder->is_match[state_2][pos_state_next])
 					+ rc_bit_1_price(coder->is_rep[state_2]);
 
 			//for(; len_test_2 >= 2; len_test_2--) {
-			const uint32_t offset = cur + len_test + 1 + len_test_2;
+			offset = cur + len_test + 1 + len_test_2;
 
 			while (len_end < offset)
 				coder->opts[++len_end].price = RC_INFINITY_PRICE;
 
-			const uint32_t cur_and_len_price = next_rep_match_price
+			cur_and_len_price = next_rep_match_price
 					+ get_rep_price(coder, 0, len_test_2,
 						state_2, pos_state_next);
 
@@ -717,15 +770,16 @@
 	if (new_len >= start_len) {
 		const uint32_t normal_match_price = match_price
 				+ rc_bit_0_price(coder->is_rep[state]);
+		uint32_t len_test;
 
 		while (len_end < cur + new_len)
 			coder->opts[++len_end].price = RC_INFINITY_PRICE;
 
-		uint32_t i = 0;
+		i = 0;
 		while (start_len > coder->matches[i].len)
 			++i;
 
-		for (uint32_t len_test = start_len; ; ++len_test) {
+		for (len_test = start_len; ; ++len_test) {
 			const uint32_t cur_back = coder->matches[i].dist;
 			uint32_t cur_and_len_price = normal_match_price
 					+ get_pos_len_price(coder,
@@ -754,11 +808,16 @@
 
 				if (len_test_2 >= 2) {
 					lzma_lzma_state state_2 = state;
+					uint32_t pos_state_next;
+					uint32_t cur_and_len_literal_price;
+					uint32_t next_rep_match_price;
+					uint32_t offset;
+					
 					update_match(state_2);
-					uint32_t pos_state_next
+					pos_state_next
 							= (position + len_test) & coder->pos_mask;
 
-					const uint32_t cur_and_len_literal_price = cur_and_len_price
+					cur_and_len_literal_price = cur_and_len_price
 							+ rc_bit_0_price(
 								coder->is_match[state_2][pos_state_next])
 							+ get_literal_price(coder,
@@ -771,14 +830,14 @@
 					update_literal(state_2);
 					pos_state_next = (pos_state_next + 1) & coder->pos_mask;
 
-					const uint32_t next_rep_match_price
+					next_rep_match_price
 							= cur_and_len_literal_price
 							+ rc_bit_1_price(
 								coder->is_match[state_2][pos_state_next])
 							+ rc_bit_1_price(coder->is_rep[state_2]);
 
 					// for(; len_test_2 >= 2; --len_test_2) {
-					const uint32_t offset = cur + len_test + 1 + len_test_2;
+					offset = cur + len_test + 1 + len_test_2;
 
 					while (len_end < offset)
 						coder->opts[++len_end].price = RC_INFINITY_PRICE;
@@ -811,10 +870,14 @@
 
 
 extern void
-lzma_lzma_optimum_normal(lzma_coder *restrict coder, lzma_mf *restrict mf,
-		uint32_t *restrict back_res, uint32_t *restrict len_res,
+lzma_lzma_optimum_normal(struct lzma_coder_s * coder, lzma_mf * mf,
+		uint32_t * back_res, uint32_t * len_res,
 		uint32_t position)
 {
+	uint32_t reps[REP_DISTANCES];
+	uint32_t len_end;
+	uint32_t cur;
+
 	// If we have symbols pending, return the next pending symbol.
 	if (coder->opts_end_index != coder->opts_current_index) {
 		assert(mf->read_ahead > 0);
@@ -841,14 +904,12 @@
 	// the original function into two pieces makes it at least a little
 	// more readable, since those two parts don't share many variables.
 
-	uint32_t len_end = helper1(coder, mf, back_res, len_res, position);
+	len_end = helper1(coder, mf, back_res, len_res, position);
 	if (len_end == UINT32_MAX)
 		return;
 
-	uint32_t reps[REP_DISTANCES];
 	memcpy(reps, coder->reps, sizeof(reps));
 
-	uint32_t cur;
 	for (cur = 1; cur < len_end; ++cur) {
 		assert(cur < OPTS);
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_encoder_presets.c src/liblzma/lzma/lzma_encoder_presets.c
--- ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_encoder_presets.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lzma/lzma_encoder_presets.c	2013-12-01 16:57:25.455074500 +0100
@@ -19,6 +19,7 @@
 	const uint32_t level = preset & LZMA_PRESET_LEVEL_MASK;
 	const uint32_t flags = preset & ~LZMA_PRESET_LEVEL_MASK;
 	const uint32_t supported_flags = LZMA_PRESET_EXTREME;
+	uint8_t values1[] = { 18, 20, 21, 22, 22, 23, 23, 24, 25, 26 };
 
 	if (level > 9 || (flags & ~supported_flags))
 		return true;
@@ -30,14 +31,15 @@
 	options->lp = LZMA_LP_DEFAULT;
 	options->pb = LZMA_PB_DEFAULT;
 
-	options->dict_size = UINT32_C(1) << (uint8_t []){
-			18, 20, 21, 22, 22, 23, 23, 24, 25, 26 }[level];
+	options->dict_size = UINT32_C(1) << values1[level];
 
 	if (level <= 3) {
+		uint8_t values2[] = { 4, 8, 24, 48 };
+
 		options->mode = LZMA_MODE_FAST;
 		options->mf = level == 0 ? LZMA_MF_HC3 : LZMA_MF_HC4;
 		options->nice_len = level <= 1 ? 128 : 273;
-		options->depth = (uint8_t []){ 4, 8, 24, 48 }[level];
+		options->depth = values2[level];
 	} else {
 		options->mode = LZMA_MODE_NORMAL;
 		options->mf = LZMA_MF_BT4;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_encoder_private.h src/liblzma/lzma/lzma_encoder_private.h
--- ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma_encoder_private.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lzma/lzma_encoder_private.h	2013-12-01 16:43:19.193499800 +0100
@@ -138,11 +138,11 @@
 
 
 extern void lzma_lzma_optimum_fast(
-		lzma_coder *restrict coder, lzma_mf *restrict mf,
-		uint32_t *restrict back_res, uint32_t *restrict len_res);
+		struct lzma_coder_s * coder, lzma_mf * mf,
+		uint32_t * back_res, uint32_t * len_res);
 
-extern void lzma_lzma_optimum_normal(lzma_coder *restrict coder,
-		lzma_mf *restrict mf, uint32_t *restrict back_res,
-		uint32_t *restrict len_res, uint32_t position);
+extern void lzma_lzma_optimum_normal(struct lzma_coder_s * coder,
+		lzma_mf * mf, uint32_t * back_res,
+		uint32_t * len_res, uint32_t position);
 
 #endif
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma2_decoder.c src/liblzma/lzma/lzma2_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma2_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lzma/lzma2_decoder.c	2014-05-03 17:49:20.071916500 +0200
@@ -54,8 +54,8 @@
 
 
 static lzma_ret
-lzma2_decode(lzma_coder *restrict coder, lzma_dict *restrict dict,
-		const uint8_t *restrict in, size_t *restrict in_pos,
+lzma2_decode(struct lzma_coder_s * coder, lzma_dict * dict,
+		const uint8_t * in, size_t * in_pos,
 		size_t in_size)
 {
 	// With SEQ_LZMA it is possible that no new input is needed to do
@@ -209,7 +209,7 @@
 
 
 static void
-lzma2_decoder_end(lzma_coder *coder, lzma_allocator *allocator)
+lzma2_decoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	assert(coder->lzma.end == NULL);
 	lzma_free(coder->lzma.coder, allocator);
@@ -224,18 +224,22 @@
 lzma2_decoder_init(lzma_lz_decoder *lz, lzma_allocator *allocator,
 		const void *opt, lzma_lz_options *lz_options)
 {
+	lzma_options_lzma *options;
+	
 	if (lz->coder == NULL) {
-		lz->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lzma_lz_decoder v1 = LZMA_LZ_DECODER_INIT;
+		
+		lz->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (lz->coder == NULL)
 			return LZMA_MEM_ERROR;
 
 		lz->code = &lzma2_decode;
 		lz->end = &lzma2_decoder_end;
 
-		lz->coder->lzma = LZMA_LZ_DECODER_INIT;
+		lz->coder->lzma = v1;
 	}
 
-	const lzma_options_lzma *options = opt;
+	options = opt;
 
 	lz->coder->sequence = SEQ_CONTROL;
 	lz->coder->need_properties = true;
@@ -263,7 +267,7 @@
 extern uint64_t
 lzma_lzma2_decoder_memusage(const void *options)
 {
-	return sizeof(lzma_coder)
+	return sizeof(struct lzma_coder_s)
 			+ lzma_lzma_decoder_memusage_nocheck(options);
 }
 
@@ -272,6 +276,8 @@
 lzma_lzma2_props_decode(void **options, lzma_allocator *allocator,
 		const uint8_t *props, size_t props_size)
 {
+	lzma_options_lzma *opt;
+
 	if (props_size != 1)
 		return LZMA_OPTIONS_ERROR;
 
@@ -283,7 +289,7 @@
 	if (props[0] > 40)
 		return LZMA_OPTIONS_ERROR;
 
-	lzma_options_lzma *opt = lzma_alloc(
+	opt = lzma_alloc(
 			sizeof(lzma_options_lzma), allocator);
 	if (opt == NULL)
 		return LZMA_MEM_ERROR;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma2_encoder.c src/liblzma/lzma/lzma2_encoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/lzma/lzma2_encoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/lzma/lzma2_encoder.c	2014-05-03 17:50:59.608203200 +0200
@@ -27,7 +27,7 @@
 	} sequence;
 
 	/// LZMA encoder
-	lzma_coder *lzma;
+	struct lzma_coder_s *lzma;
 
 	/// LZMA options currently in use.
 	lzma_options_lzma opt_cur;
@@ -52,15 +52,16 @@
 
 
 static void
-lzma2_header_lzma(lzma_coder *coder)
+lzma2_header_lzma(struct lzma_coder_s *coder)
 {
+	size_t pos;
+	size_t size;
+	
 	assert(coder->uncompressed_size > 0);
 	assert(coder->uncompressed_size <= LZMA2_UNCOMPRESSED_MAX);
 	assert(coder->compressed_size > 0);
 	assert(coder->compressed_size <= LZMA2_CHUNK_MAX);
 
-	size_t pos;
-
 	if (coder->need_properties) {
 		pos = 0;
 
@@ -81,7 +82,7 @@
 	coder->buf_pos = pos;
 
 	// Uncompressed size
-	size_t size = coder->uncompressed_size - 1;
+	size = coder->uncompressed_size - 1;
 	coder->buf[pos++] += size >> 16;
 	coder->buf[pos++] = (size >> 8) & 0xFF;
 	coder->buf[pos++] = size & 0xFF;
@@ -108,7 +109,7 @@
 
 
 static void
-lzma2_header_uncompressed(lzma_coder *coder)
+lzma2_header_uncompressed(struct lzma_coder_s *coder)
 {
 	assert(coder->uncompressed_size > 0);
 	assert(coder->uncompressed_size <= LZMA2_CHUNK_MAX);
@@ -133,8 +134,8 @@
 
 
 static lzma_ret
-lzma2_encode(lzma_coder *restrict coder, lzma_mf *restrict mf,
-		uint8_t *restrict out, size_t *restrict out_pos,
+lzma2_encode(struct lzma_coder_s * coder, lzma_mf * mf,
+		uint8_t * out, size_t * out_pos,
 		size_t out_size)
 {
 	while (*out_pos < out_size)
@@ -167,7 +168,9 @@
 		const uint32_t left = LZMA2_UNCOMPRESSED_MAX
 				- coder->uncompressed_size;
 		uint32_t limit;
-
+		uint32_t read_start;
+		lzma_ret ret;
+		
 		if (left < mf->match_len_max) {
 			// Must flush immediately since the next LZMA symbol
 			// could make the uncompressed size of the chunk too
@@ -182,10 +185,10 @@
 
 		// Save the start position so that we can update
 		// coder->uncompressed_size.
-		const uint32_t read_start = mf->read_pos - mf->read_ahead;
+		read_start = mf->read_pos - mf->read_ahead;
 
 		// Call the LZMA encoder until the chunk is finished.
-		const lzma_ret ret = lzma_lzma_encode(coder->lzma, mf,
+		ret = lzma_lzma_encode(coder->lzma, mf,
 				coder->buf + LZMA2_HEADER_MAX,
 				&coder->compressed_size,
 				LZMA2_CHUNK_MAX, limit);
@@ -262,7 +265,7 @@
 
 
 static void
-lzma2_encoder_end(lzma_coder *coder, lzma_allocator *allocator)
+lzma2_encoder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_free(coder->lzma, allocator);
 	lzma_free(coder, allocator);
@@ -271,8 +274,10 @@
 
 
 static lzma_ret
-lzma2_encoder_options_update(lzma_coder *coder, const lzma_filter *filter)
+lzma2_encoder_options_update(struct lzma_coder_s *coder, const lzma_filter *filter)
 {
+	const lzma_options_lzma *opt;
+
 	// New options can be set only when there is no incomplete chunk.
 	// This is the case at the beginning of the raw stream and right
 	// after LZMA_SYNC_FLUSH.
@@ -281,7 +286,7 @@
 
 	// Look if there are new options. At least for now,
 	// only lc/lp/pb can be changed.
-	const lzma_options_lzma *opt = filter->options;
+	opt = filter->options;
 	if (coder->opt_cur.lc != opt->lc || coder->opt_cur.lp != opt->lp
 			|| coder->opt_cur.pb != opt->pb) {
 		// Validate the options.
@@ -311,7 +316,7 @@
 		return LZMA_PROG_ERROR;
 
 	if (lz->coder == NULL) {
-		lz->coder = lzma_alloc(sizeof(lzma_coder), allocator);
+		lz->coder = lzma_alloc(sizeof(struct lzma_coder_s), allocator);
 		if (lz->coder == NULL)
 			return LZMA_MEM_ERROR;
 
@@ -364,7 +369,7 @@
 	if (lzma_mem == UINT64_MAX)
 		return UINT64_MAX;
 
-	return sizeof(lzma_coder) + lzma_mem;
+	return sizeof(struct lzma_coder_s) + lzma_mem;
 }
 
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/rangecoder/price.h src/liblzma/rangecoder/price.h
--- ..\..\Library\xz-5.0.5\src/liblzma/rangecoder/price.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/rangecoder/price.h	2013-12-01 16:46:51.517052600 +0100
@@ -21,11 +21,11 @@
 #define RC_INFINITY_PRICE (UINT32_C(1) << 30)
 
 
-/// Lookup table for the inline functions defined in this file.
+/// Lookup table for the __inline functions defined in this file.
 extern const uint8_t lzma_rc_prices[RC_PRICE_TABLE_SIZE];
 
 
-static inline uint32_t
+static __inline uint32_t
 rc_bit_price(const probability prob, const uint32_t bit)
 {
 	return lzma_rc_prices[(prob ^ ((UINT32_C(0) - bit)
@@ -33,14 +33,14 @@
 }
 
 
-static inline uint32_t
+static __inline uint32_t
 rc_bit_0_price(const probability prob)
 {
 	return lzma_rc_prices[prob >> RC_MOVE_REDUCING_BITS];
 }
 
 
-static inline uint32_t
+static __inline uint32_t
 rc_bit_1_price(const probability prob)
 {
 	return lzma_rc_prices[(prob ^ (RC_BIT_MODEL_TOTAL - 1))
@@ -48,7 +48,7 @@
 }
 
 
-static inline uint32_t
+static __inline uint32_t
 rc_bittree_price(const probability *const probs,
 		const uint32_t bit_levels, uint32_t symbol)
 {
@@ -65,7 +65,7 @@
 }
 
 
-static inline uint32_t
+static __inline uint32_t
 rc_bittree_reverse_price(const probability *const probs,
 		uint32_t bit_levels, uint32_t symbol)
 {
@@ -83,7 +83,7 @@
 }
 
 
-static inline uint32_t
+static __inline uint32_t
 rc_direct_price(const uint32_t bits)
 {
 	 return bits << RC_BIT_PRICE_SHIFT_BITS;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/rangecoder/range_common.h src/liblzma/rangecoder/range_common.h
--- ..\..\Library\xz-5.0.5\src/liblzma/rangecoder/range_common.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/rangecoder/range_common.h	2014-05-03 18:16:24.081270500 +0200
@@ -42,8 +42,9 @@
 // This does the same for a complete bit tree.
 // (A tree represented as an array.)
 #define bittree_reset(probs, bit_levels) \
-	for (uint32_t bt_i = 0; bt_i < (1 << (bit_levels)); ++bt_i) \
-		bit_reset((probs)[bt_i])
+	{ uint32_t bt_i; \
+	for (bt_i = 0; bt_i < (1 << (bit_levels)); ++bt_i) \
+		bit_reset((probs)[bt_i]); }
 
 
 //////////////////////
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/rangecoder/range_decoder.h src/liblzma/rangecoder/range_decoder.h
--- ..\..\Library\xz-5.0.5\src/liblzma/rangecoder/range_decoder.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/rangecoder/range_decoder.h	2014-05-04 09:50:03.356355600 +0200
@@ -25,9 +25,9 @@
 
 
 /// Reads the first five bytes to initialize the range decoder.
-static inline bool
-rc_read_init(lzma_range_decoder *rc, const uint8_t *restrict in,
-		size_t *restrict in_pos, size_t in_size)
+static __inline bool
+rc_read_init(lzma_range_decoder *rc, const uint8_t * in,
+		size_t * in_pos, size_t in_size)
 {
 	while (rc->init_bytes_left > 0) {
 		if (*in_pos == in_size)
@@ -45,10 +45,14 @@
 /// Makes local copies of range decoder and *in_pos variables. Doing this
 /// improves speed significantly. The range decoder macros expect also
 /// variables `in' and `in_size' to be defined.
-#define rc_to_local(range_decoder, in_pos) \
-	lzma_range_decoder rc = range_decoder; \
-	size_t rc_in_pos = (in_pos); \
+#define rc_to_local_types(range_decoder, in_pos) \
+	lzma_range_decoder rc; \
+	size_t rc_in_pos; \
 	uint32_t rc_bound
+	
+#define rc_to_local_assign(range_decoder, in_pos) \
+	rc = range_decoder; \
+	rc_in_pos = (in_pos)
 
 
 /// Stores the local copes back to the range decoder structure.
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/rangecoder/range_encoder.h src/liblzma/rangecoder/range_encoder.h
--- ..\..\Library\xz-5.0.5\src/liblzma/rangecoder/range_encoder.h	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/rangecoder/range_encoder.h	2014-05-03 18:18:53.370064300 +0200
@@ -51,7 +51,7 @@
 } lzma_range_encoder;
 
 
-static inline void
+static __inline void
 rc_reset(lzma_range_encoder *rc)
 {
 	rc->low = 0;
@@ -63,7 +63,7 @@
 }
 
 
-static inline void
+static __inline void
 rc_bit(lzma_range_encoder *rc, probability *prob, uint32_t bit)
 {
 	rc->symbols[rc->count] = bit;
@@ -72,7 +72,7 @@
 }
 
 
-static inline void
+static __inline void
 rc_bittree(lzma_range_encoder *rc, probability *probs,
 		uint32_t bit_count, uint32_t symbol)
 {
@@ -86,7 +86,7 @@
 }
 
 
-static inline void
+static __inline void
 rc_bittree_reverse(lzma_range_encoder *rc, probability *probs,
 		uint32_t bit_count, uint32_t symbol)
 {
@@ -101,7 +101,7 @@
 }
 
 
-static inline void
+static __inline void
 rc_direct(lzma_range_encoder *rc,
 		uint32_t value, uint32_t bit_count)
 {
@@ -112,15 +112,17 @@
 }
 
 
-static inline void
+static __inline void
 rc_flush(lzma_range_encoder *rc)
 {
-	for (size_t i = 0; i < 5; ++i)
+	size_t i;
+	
+	for (i = 0; i < 5; ++i)
 		rc->symbols[rc->count++] = RC_FLUSH;
 }
 
 
-static inline bool
+static __inline bool
 rc_shift_low(lzma_range_encoder *rc,
 		uint8_t *out, size_t *out_pos, size_t out_size)
 {
@@ -146,7 +148,7 @@
 }
 
 
-static inline bool
+static __inline bool
 rc_encode(lzma_range_encoder *rc,
 		uint8_t *out, size_t *out_pos, size_t out_size)
 {
@@ -222,7 +224,7 @@
 }
 
 
-static inline uint64_t
+static __inline uint64_t
 rc_pending(const lzma_range_encoder *rc)
 {
 	return rc->cache_size + 5 - 1;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/simple/simple_coder.c src/liblzma/simple/simple_coder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/simple/simple_coder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/simple/simple_coder.c	2014-05-03 19:12:24.989853800 +0200
@@ -18,10 +18,10 @@
 
 /// Copied or encodes/decodes more data to out[].
 static lzma_ret
-copy_or_code(lzma_coder *coder, lzma_allocator *allocator,
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size, lzma_action action)
+copy_or_code(struct lzma_coder_s *coder, lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size, lzma_action action)
 {
 	assert(!coder->end_was_reached);
 
@@ -55,7 +55,7 @@
 
 
 static size_t
-call_filter(lzma_coder *coder, uint8_t *buffer, size_t size)
+call_filter(struct lzma_coder_s *coder, uint8_t *buffer, size_t size)
 {
 	const size_t filtered = coder->filter(coder->simple,
 			coder->now_pos, coder->is_encoder,
@@ -66,11 +66,14 @@
 
 
 static lzma_ret
-simple_code(lzma_coder *coder, lzma_allocator *allocator,
-		const uint8_t *restrict in, size_t *restrict in_pos,
-		size_t in_size, uint8_t *restrict out,
-		size_t *restrict out_pos, size_t out_size, lzma_action action)
+simple_code(struct lzma_coder_s *coder, lzma_allocator *allocator,
+		const uint8_t * in, size_t * in_pos,
+		size_t in_size, uint8_t * out,
+		size_t * out_pos, size_t out_size, lzma_action action)
 {
+	size_t out_avail;
+	size_t buf_avail;
+	
 	// TODO: Add partial support for LZMA_SYNC_FLUSH. We can support it
 	// in cases when the filter is able to filter everything. With most
 	// simple filters it can be done at offset that is a multiple of 2,
@@ -105,13 +108,16 @@
 	// more data to out[] hopefully filling it completely. Then filter
 	// the data in out[]. This step is where most of the data gets
 	// filtered if the buffer sizes used by the application are reasonable.
-	const size_t out_avail = out_size - *out_pos;
-	const size_t buf_avail = coder->size - coder->pos;
+	out_avail = out_size - *out_pos;
+	buf_avail = coder->size - coder->pos;
 	if (out_avail > buf_avail || buf_avail == 0) {
 		// Store the old position so that we know from which byte
 		// to start filtering.
 		const size_t out_start = *out_pos;
-
+		size_t size;
+		size_t filtered;
+		size_t unfiltered;
+		
 		// Flush data from coder->buffer[] to out[], but don't reset
 		// coder->pos and coder->size yet. This way the coder can be
 		// restarted if the next filter in the chain returns e.g.
@@ -130,11 +136,11 @@
 		}
 
 		// Filter out[].
-		const size_t size = *out_pos - out_start;
-		const size_t filtered = call_filter(
+		size = *out_pos - out_start;
+		filtered = call_filter(
 				coder, out + out_start, size);
 
-		const size_t unfiltered = size - filtered;
+		unfiltered = size - filtered;
 		assert(unfiltered <= coder->allocated / 2);
 
 		// Now we can update coder->pos and coder->size, because
@@ -198,7 +204,7 @@
 
 
 static void
-simple_coder_end(lzma_coder *coder, lzma_allocator *allocator)
+simple_coder_end(struct lzma_coder_s *coder, lzma_allocator *allocator)
 {
 	lzma_next_end(&coder->next, allocator);
 	lzma_free(coder->simple, allocator);
@@ -208,7 +214,7 @@
 
 
 static lzma_ret
-simple_coder_update(lzma_coder *coder, lzma_allocator *allocator,
+simple_coder_update(struct lzma_coder_s *coder, lzma_allocator *allocator,
 		const lzma_filter *filters_null lzma_attribute((__unused__)),
 		const lzma_filter *reversed_filters)
 {
@@ -226,13 +232,15 @@
 		size_t simple_size, size_t unfiltered_max,
 		uint32_t alignment, bool is_encoder)
 {
-	// Allocate memory for the lzma_coder structure if needed.
+	// Allocate memory for the struct lzma_coder_s structure if needed.
 	if (next->coder == NULL) {
+		lzma_next_coder v = LZMA_NEXT_CODER_INIT;
+		
 		// Here we allocate space also for the temporary buffer. We
 		// need twice the size of unfiltered_max, because then it
 		// is always possible to filter at least unfiltered_max bytes
 		// more data in coder->buffer[] if it can be filled completely.
-		next->coder = lzma_alloc(sizeof(lzma_coder)
+		next->coder = lzma_alloc(sizeof(struct lzma_coder_s)
 				+ 2 * unfiltered_max, allocator);
 		if (next->coder == NULL)
 			return LZMA_MEM_ERROR;
@@ -241,7 +249,7 @@
 		next->end = &simple_coder_end;
 		next->update = &simple_coder_update;
 
-		next->coder->next = LZMA_NEXT_CODER_INIT;
+		next->coder->next = v;
 		next->coder->filter = filter;
 		next->coder->allocated = 2 * unfiltered_max;
 
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/simple/simple_decoder.c src/liblzma/simple/simple_decoder.c
--- ..\..\Library\xz-5.0.5\src/liblzma/simple/simple_decoder.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/simple/simple_decoder.c	2013-12-01 16:46:51.501429100 +0100
@@ -17,13 +17,15 @@
 lzma_simple_props_decode(void **options, lzma_allocator *allocator,
 		const uint8_t *props, size_t props_size)
 {
+	lzma_options_bcj *opt;
+
 	if (props_size == 0)
 		return LZMA_OK;
 
 	if (props_size != 4)
 		return LZMA_OPTIONS_ERROR;
 
-	lzma_options_bcj *opt = lzma_alloc(
+	opt = lzma_alloc(
 			sizeof(lzma_options_bcj), allocator);
 	if (opt == NULL)
 		return LZMA_MEM_ERROR;
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/simple/sparc.c src/liblzma/simple/sparc.c
--- ..\..\Library\xz-5.0.5\src/liblzma/simple/sparc.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/simple/sparc.c	2014-05-03 19:13:29.696233300 +0200
@@ -25,6 +25,7 @@
 		if ((buffer[i] == 0x40 && (buffer[i + 1] & 0xC0) == 0x00)
 				|| (buffer[i] == 0x7F
 				&& (buffer[i + 1] & 0xC0) == 0xC0)) {
+			uint32_t dest;
 
 			uint32_t src = ((uint32_t)buffer[i + 0] << 24)
 					| ((uint32_t)buffer[i + 1] << 16)
@@ -33,7 +34,6 @@
 
 			src <<= 2;
 
-			uint32_t dest;
 			if (is_encoder)
 				dest = now_pos + (uint32_t)(i) + src;
 			else
diff -ru ..\..\Library\xz-5.0.5\src/liblzma/simple/x86.c src/liblzma/simple/x86.c
--- ..\..\Library\xz-5.0.5\src/liblzma/simple/x86.c	2013-06-30 14:49:46.000000000 +0200
+++ src/liblzma/simple/x86.c	2014-05-03 19:15:26.233369700 +0200
@@ -36,30 +36,34 @@
 	uint32_t prev_mask = simple->prev_mask;
 	uint32_t prev_pos = simple->prev_pos;
 
+	const size_t limit = size - 5;
+	size_t buffer_pos = 0;
+
+	uint32_t i;
+	
 	if (size < 5)
 		return 0;
 
 	if (now_pos - prev_pos > 5)
 		prev_pos = now_pos - 5;
 
-	const size_t limit = size - 5;
-	size_t buffer_pos = 0;
-
 	while (buffer_pos <= limit) {
 		uint8_t b = buffer[buffer_pos];
+		uint32_t offset;
+		
 		if (b != 0xE8 && b != 0xE9) {
 			++buffer_pos;
 			continue;
 		}
 
-		const uint32_t offset = now_pos + (uint32_t)(buffer_pos)
+		offset = now_pos + (uint32_t)(buffer_pos)
 				- prev_pos;
 		prev_pos = now_pos + (uint32_t)(buffer_pos);
 
 		if (offset > 5) {
 			prev_mask = 0;
 		} else {
-			for (uint32_t i = 0; i < offset; ++i) {
+			for (i = 0; i < offset; ++i) {
 				prev_mask &= 0x77;
 				prev_mask <<= 1;
 			}
@@ -88,8 +92,7 @@
 				if (prev_mask == 0)
 					break;
 
-				const uint32_t i = MASK_TO_BIT_NUMBER[
-						prev_mask >> 1];
+				i = MASK_TO_BIT_NUMBER[prev_mask >> 1];
 
 				b = (uint8_t)(dest >> (24 - i * 8));
 
